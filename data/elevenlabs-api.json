{
  "name": "elevenlabs-api",
  "display_name": "ElevenLabs API",
  "version": "v1",
  "base_url": "https://elevenlabs.io/docs/api-reference",
  "sections": [
    {
      "title": "Agents Calculate",
      "path": "agents-calculate",
      "url": "https://elevenlabs.io/docs/api-reference/agents/calculate",
      "keywords": [
        "agents",
        "calculate",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to agents calculate",
        "How to list agents calculate"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Calculates expected number of LLM tokens needed for the specified agent.\n### Path parameters\nagent_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nprompt_lengthinteger or nullOptional\nLength of the prompt in characters.\nnumber_of_pagesinteger or nullOptional\nPages of content in pdf documents OR urls in agent's Knowledge Base.\nrag_enabledboolean or nullOptional\nWhether RAG is enabled.\n### Response\nSuccessful Response\nllm_priceslist of objects\nShow 2 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Get Link",
      "path": "agents-get-link",
      "url": "https://elevenlabs.io/docs/api-reference/agents/get-link",
      "keywords": [
        "agents",
        "errors",
        "get",
        "headers",
        "link",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to agents get link"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get the current link used to share the agent with others\n### Path parameters\nagent_idstringRequired\nThe id of an agent. This is returned on agent creation.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nagent_idstring\nThe ID of the agent\ntokenobject or null\nThe token data for the agent\nShow 6 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents List",
      "path": "agents-list",
      "url": "https://elevenlabs.io/docs/api-reference/agents/list",
      "keywords": [
        "agents",
        "endpoint",
        "errors",
        "false",
        "headers",
        "list",
        "parameters",
        "query",
        "response"
      ],
      "use_cases": [
        "How to agents list",
        "How to create agents list",
        "How to list agents list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Returns a list of your agents and their metadata.\n### Headers\nxi-api-keystringRequired\n### Query parameters\npage_sizeintegerOptional`1-100`Defaults to `30`\nHow many Agents to return at maximum. Can not exceed 100, defaults to 30.\nsearchstring or nullOptional\nSearch by agents name.\narchivedboolean or nullOptionalDefaults to `false`\nFilter agents by archived status\nshow_only_owned_agentsbooleanOptionalDefaults to `false`\nIf set to true, the endpoint will omit any agents that were shared with you by someone else and include only the ones you own\nsort_directionenumOptional\nThe direction to sort the results\nAllowed values:ascdesc\nsort_byenum or nullOptional\nThe field to sort the results by\nAllowed values:namecreated_at\ncursorstring or nullOptional\nUsed for fetching next page. Cursor is returned in the response.\n### Response\nSuccessful Response\nagentslist of objects\nA list of agents and their metadata\nShow 7 properties\nhas_moreboolean\nWhether there are more agents to paginate through\nnext_cursorstring or null\nThe next cursor to paginate through the agents\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Delete",
      "path": "agents-delete",
      "url": "https://elevenlabs.io/docs/api-reference/agents/delete",
      "keywords": [
        "agents",
        "delete",
        "errors",
        "headers",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to agents delete",
        "How to delete agents delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Delete an agent\n### Path parameters\nagent_idstringRequired\nThe id of an agent. This is returned on agent creation.\n### Headers\nxi-api-keystringRequired\n### Response\n200\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Duplicate",
      "path": "agents-duplicate",
      "url": "https://elevenlabs.io/docs/api-reference/agents/duplicate",
      "keywords": [
        "agents",
        "duplicate",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to agents duplicate",
        "How to create agents duplicate"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Create a new agent by duplicating an existing one\n### Path parameters\nagent_idstringRequired\nThe id of an agent. This is returned on agent creation.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnamestring or nullOptional\nA name to make the agent easier to find\n### Response\nSuccessful Response\nagent_idstring\nID of the created agent\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Simulate Conversation Stream",
      "path": "agents-simulate-conversation-stream",
      "url": "https://elevenlabs.io/docs/api-reference/agents/simulate-conversation-stream",
      "keywords": [
        "agents",
        "conversation",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "simulate"
      ],
      "use_cases": [
        "How to agents simulate conversation stream",
        "How to list agents simulate conversation stream",
        "How to stream agents simulate conversation stream"
      ],
      "tags": [
        "api-reference",
        "streaming"
      ],
      "priority": 5,
      "content": "Run a conversation between the agent and a simulated user and stream back the response. Response is streamed back as partial lists of messages that should be concatenated and once the conversation has complete a single final message with the conversation analysis will be sent.\n### Path parameters\nagent_idstringRequired\nThe id of an agent. This is returned on agent creation.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nsimulation_specificationobjectRequired\nA specification detailing how the conversation should be simulated\nShow 4 properties\nextra_evaluation_criterialist of objects or nullOptional\nA list of evaluation criteria to test\nShow 5 properties\nnew_turns_limitintegerOptionalDefaults to `10000`\nMaximum number of new turns to generate in the conversation simulation\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Create",
      "path": "agents-create",
      "url": "https://elevenlabs.io/docs/api-reference/agents/create",
      "keywords": [
        "agents",
        "create",
        "endpoint",
        "errors",
        "headers",
        "request",
        "response"
      ],
      "use_cases": [
        "How to agents create",
        "How to create agents create",
        "How to list agents create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Create an agent from a config object\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nconversation_configobjectRequired\nConversation configuration for an agent\nShow 7 properties\nplatform_settingsobject or nullOptional\nPlatform settings for the agent are all settings that aren't related to the conversation orchestration and content.\nShow 10 properties\nworkflowobjectOptional\nWorkflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\nShow 3 properties\nnamestring or nullOptional\nA name to make the agent easier to find\ntagslist of strings or nullOptional\nTags to help classify and filter the agent\n### Response\nSuccessful Response\nagent_idstring\nID of the created agent\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Update",
      "path": "agents-update",
      "url": "https://elevenlabs.io/docs/api-reference/agents/update",
      "keywords": [
        "agents",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "update"
      ],
      "use_cases": [
        "How to agents update",
        "How to list agents update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Patches an Agent settings\n### Path parameters\nagent_idstringRequired\nThe id of an agent. This is returned on agent creation.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nconversation_configobjectOptional\nConversation configuration for an agent\nShow 7 properties\nplatform_settingsobjectOptional\nPlatform settings for the agent are all settings that aren't related to the conversation orchestration and content.\nShow 10 properties\nworkflowobjectOptional\nWorkflow for the agent. This is used to define the flow of the conversation and how the agent interacts with tools.\nShow 3 properties\nnamestring or nullOptional\nA name to make the agent easier to find\ntagslist of strings or nullOptional\nTags to help classify and filter the agent\nversion_descriptionstring or nullOptional\nDescription for this version when publishing changes (only applicable for versioned agents)\n### Response\nSuccessful Response\nagent_idstring\nThe ID of the agent\nnamestring\nThe name of the agent\nconversation_configobject\nThe conversation configuration of the agent\nShow 7 properties\nmetadataobject\nThe metadata of the agent\nShow 2 properties\nplatform_settingsobject or null\nThe platform settings of the agent\nShow 11 properties\nphone_numberslist of objects or null\nThe phone numbers of the agent\nShow 2 variants\nwhatsapp_accountslist of objects or null\nWhatsApp accounts assigned to the agent\nShow 7 properties\nworkflowobject or null\nThe workflow of the agent\nShow 3 properties\naccess_infoobject or null\nThe access information of the agent for the user\nShow 4 properties\ntagslist of strings or null\nAgent tags used to categorize the agent\nversion_idstring or null\nThe ID of the version the agent is on\nbranch_idstring or null\nThe ID of the branch the agent is on\nmain_branch_idstring or null\nThe ID of the main branch for this agent\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Get",
      "path": "agents-get",
      "url": "https://elevenlabs.io/docs/api-reference/agents/get",
      "keywords": [
        "agents",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to agents get",
        "How to list agents get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Retrieve config for an agent\n### Path parameters\nagent_idstringRequired\nThe id of an agent. This is returned on agent creation.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nagent_idstring\nThe ID of the agent\nnamestring\nThe name of the agent\nconversation_configobject\nThe conversation configuration of the agent\nShow 7 properties\nmetadataobject\nThe metadata of the agent\nShow 2 properties\nplatform_settingsobject or null\nThe platform settings of the agent\nShow 11 properties\nphone_numberslist of objects or null\nThe phone numbers of the agent\nShow 2 variants\nwhatsapp_accountslist of objects or null\nWhatsApp accounts assigned to the agent\nShow 7 properties\nworkflowobject or null\nThe workflow of the agent\nShow 3 properties\naccess_infoobject or null\nThe access information of the agent for the user\nShow 4 properties\ntagslist of strings or null\nAgent tags used to categorize the agent\nversion_idstring or null\nThe ID of the version the agent is on\nbranch_idstring or null\nThe ID of the branch the agent is on\nmain_branch_idstring or null\nThe ID of the main branch for this agent\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Agents Simulate Conversation",
      "path": "agents-simulate-conversation",
      "url": "https://elevenlabs.io/docs/api-reference/agents/simulate-conversation",
      "keywords": [
        "agents",
        "conversation",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "simulate"
      ],
      "use_cases": [
        "How to agents simulate conversation",
        "How to list agents simulate conversation"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Run a conversation between the agent and a simulated user.\n### Path parameters\nagent_idstringRequired\nThe id of an agent. This is returned on agent creation.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nsimulation_specificationobjectRequired\nA specification detailing how the conversation should be simulated\nShow 4 properties\nextra_evaluation_criterialist of objects or nullOptional\nA list of evaluation criteria to test\nShow 5 properties\nnew_turns_limitintegerOptionalDefaults to `10000`\nMaximum number of new turns to generate in the conversation simulation\n### Response\nSuccessful Response\nsimulated_conversationlist of objects\nShow 15 properties\nanalysisobject\nShow 5 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Analytics Get",
      "path": "analytics-get",
      "url": "https://elevenlabs.io/docs/api-reference/analytics/get",
      "keywords": [
        "analytics",
        "errors",
        "get",
        "headers",
        "parameters",
        "query",
        "response"
      ],
      "use_cases": [
        "How to analytics get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get the live count of the ongoing conversations.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nagent_idstring or nullOptional\nThe id of an agent to restrict the analytics to.\n### Response\nSuccessful Response\ncountinteger\nThe number of active ongoing conversations.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Authentication",
      "path": "authentication",
      "url": "https://elevenlabs.io/docs/api-reference/authentication",
      "keywords": [
        "api",
        "authentication",
        "elevenlabs",
        "header",
        "keys",
        "making",
        "request",
        "requests",
        "single",
        "tokens"
      ],
      "use_cases": [
        "How to authentication",
        "How to create authentication"
      ],
      "tags": [
        "getting-started",
        "api-reference"
      ],
      "priority": 10,
      "content": "## API Keys\nThe ElevenLabs API uses API keys for authentication. Every request to the API must include your API key, used to authenticate your requests and track usage quota.\nEach API key can be scoped to one of the following:\n  1. **Scope restriction:** Set access restrictions by limiting which API endpoints the key can access.\n  2. **Credit quota:** Define custom credit limits to control usage.\n\n\n**Remember that your API key is a secret.** Do not share it with others or expose it in any client-side code (browsers, apps).\nAll API requests should include your API key in an `xi-api-key` HTTP header as follows:\n```\n\n\n$\n| xi-api-key: ELEVENLABS_API_KEY\n  \n---|---  \n\n```\n\n### Making requests\nYou can paste the command below into your terminal to run your first API request. Make sure to replace `$ELEVENLABS_API_KEY` with your secret API key.\n```\n\n\n\n$\n| curl 'https://api.elevenlabs.io/v1/models' \\\n  \n---|---  \n\n\n>\n|   -H 'Content-Type: application/json' \\\n  \n\n\n>\n|   -H 'xi-api-key: $ELEVENLABS_API_KEY'\n  \n\n\n\n```\n\nExample with the `elevenlabs` Python package:\n```\n\n\n\n1\n| from elevenlabs.client import ElevenLabs\n  \n---|---  \n\n\n2\n| \n  \n\n\n3\n| elevenlabs = ElevenLabs(\n  \n\n\n4\n|   api_key='YOUR_API_KEY',\n  \n\n\n5\n| )\n  \n\n\n\n```\n\nExample with the `elevenlabs` Node.js package:\n```\n\n\n\n1\n| import { ElevenLabsClient } from '@elevenlabs/elevenlabs-js';\n  \n---|---  \n\n\n2\n| \n  \n\n\n3\n| const elevenlabs = new ElevenLabsClient({\n  \n\n\n4\n|   apiKey: 'YOUR_API_KEY',\n  \n\n\n5\n| });\n  \n\n\n\n```\n\n### Single use tokens\nFor certain endpoints, you can use single use tokens to authenticate your requests. These tokens are valid for a limited time and can be used to connect to the API without exposing your API key, for example from the client side.\nSee the [Single use tokens](https://elevenlabs.io/docs/api-reference/tokens/create) documentation for more information.\n"
    },
    {
      "title": "Audio Native Get Settings",
      "path": "audio-native-get-settings",
      "url": "https://elevenlabs.io/docs/api-reference/audio-native/get-settings",
      "keywords": [
        "audio",
        "errors",
        "get",
        "headers",
        "native",
        "parameters",
        "path",
        "response",
        "settings"
      ],
      "use_cases": [
        "How to audio native get settings"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get player settings for the specific project.\n### Path parameters\nproject_idstringRequired\nThe ID of the Studio project.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nenabledboolean\nWhether the project is enabled.\nsnapshot_idstring or null\nThe ID of the latest snapshot of the project.\nsettingsobject or null\nThe settings of the project.\nShow 10 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Audio Native Update",
      "path": "audio-native-update",
      "url": "https://elevenlabs.io/docs/api-reference/audio-native/update",
      "keywords": [
        "audio",
        "body",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "native",
        "parameters",
        "path"
      ],
      "use_cases": [
        "How to audio native update",
        "How to list audio native update",
        "How to update audio native update",
        "How to convert audio native update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Updates content for the specific AudioNative Project.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing an optional file.\nfilefileOptional\nEither txt or HTML input file containing the article content. HTML should be formatted as follows ‘<html><body><div><p>Your content</p><h5>More of your content</h5><p>Some more of your content</p></div></body></html>’\nauto_convertbooleanOptionalDefaults to `false`\nWhether to auto convert the project to audio or not.\nauto_publishbooleanOptionalDefaults to `false`\nWhether to auto publish the new project snapshot after it's converted.\n### Response\nSuccessful Response\nproject_idstring\nThe ID of the project.\nconvertingboolean\nWhether the project is currently being converted.\npublishingboolean\nWhether the project is currently being published.\nhtml_snippetstring\nThe HTML snippet to embed the Audio Native player.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Audio Isolation Stream",
      "path": "audio-isolation-stream",
      "url": "https://elevenlabs.io/docs/api-reference/audio-isolation/stream",
      "keywords": [
        "audio",
        "endpoint",
        "errors",
        "headers",
        "isolation",
        "other",
        "pcm_s16le_16",
        "request",
        "stream"
      ],
      "use_cases": [
        "How to audio isolation stream"
      ],
      "tags": [
        "api-reference",
        "streaming"
      ],
      "priority": 5,
      "content": "Removes background noise from audio.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing a file.\naudiofileRequired\nThe audio file from which vocals/speech will be isolated from.\nfile_formatenum or nullOptionalDefaults to `other`\nThe format of input audio. Options are ‘pcm_s16le_16’ or ‘other’ For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\nAllowed values:pcm_s16le_16other\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Audio Isolation Convert",
      "path": "audio-isolation-convert",
      "url": "https://elevenlabs.io/docs/api-reference/audio-isolation/convert",
      "keywords": [
        "audio",
        "convert",
        "endpoint",
        "errors",
        "headers",
        "isolation",
        "other",
        "pcm_s16le_16",
        "request",
        "response"
      ],
      "use_cases": [
        "How to audio isolation convert"
      ],
      "tags": [
        "api-reference",
        "conversion"
      ],
      "priority": 5,
      "content": "Removes background noise from audio.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing a file.\naudiofileRequired\nThe audio file from which vocals/speech will be isolated from.\nfile_formatenum or nullOptionalDefaults to `other`\nThe format of input audio. Options are ‘pcm_s16le_16’ or ‘other’ For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\nAllowed values:pcm_s16le_16other\npreview_b64string or nullOptional\nOptional preview image base64 for tracking this generation.\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Batch Calling Cancel",
      "path": "batch-calling-cancel",
      "url": "https://elevenlabs.io/docs/api-reference/batch-calling/cancel",
      "keywords": [
        "batch",
        "calling",
        "cancel",
        "errors",
        "headers",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to batch calling cancel",
        "How to create batch calling cancel",
        "How to update batch calling cancel"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Cancel a running batch call and set all recipients to cancelled status.\n### Path parameters\nbatch_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nphone_number_idstring or null\nphone_providerenum or null\nAllowed values:twiliosip_trunk\nwhatsapp_paramsobject or null\nShow 3 properties\nnamestring\nagent_idstring\ncreated_at_unixinteger\nscheduled_time_unixinteger\ntimezonestring or null\ntotal_calls_dispatchedintegerDefaults to `0`\ntotal_calls_scheduledintegerDefaults to `0`\ntotal_calls_finishedintegerDefaults to `0`\nlast_updated_at_unixinteger\nstatusenum\nAllowed values:pendingin_progresscompletedfailedcancelled\nretry_countintegerDefaults to `0`\nagent_namestring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Batch Calling Get",
      "path": "batch-calling-get",
      "url": "https://elevenlabs.io/docs/api-reference/batch-calling/get",
      "keywords": [
        "batch",
        "calling",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to batch calling get",
        "How to create batch calling get",
        "How to list batch calling get",
        "How to update batch calling get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get detailed information about a batch call including all recipients.\n### Path parameters\nbatch_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nphone_number_idstring or null\nphone_providerenum or null\nAllowed values:twiliosip_trunk\nwhatsapp_paramsobject or null\nShow 3 properties\nnamestring\nagent_idstring\ncreated_at_unixinteger\nscheduled_time_unixinteger\ntimezonestring or null\ntotal_calls_dispatchedintegerDefaults to `0`\ntotal_calls_scheduledintegerDefaults to `0`\ntotal_calls_finishedintegerDefaults to `0`\nlast_updated_at_unixinteger\nstatusenum\nAllowed values:pendingin_progresscompletedfailedcancelled\nretry_countintegerDefaults to `0`\nagent_namestring\nrecipientslist of objects\nShow 8 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Batch Calling Create",
      "path": "batch-calling-create",
      "url": "https://elevenlabs.io/docs/api-reference/batch-calling/create",
      "keywords": [
        "batch",
        "calling",
        "create",
        "endpoint",
        "errors",
        "headers",
        "request",
        "response"
      ],
      "use_cases": [
        "How to batch calling create",
        "How to create batch calling create",
        "How to list batch calling create",
        "How to update batch calling create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Submit a batch call request to schedule calls for multiple recipients.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\ncall_namestringRequired\nagent_idstringRequired\nrecipientslist of objectsRequired\nShow 4 properties\nscheduled_time_unixinteger or nullOptional\nagent_phone_number_idstring or nullOptional\nwhatsapp_paramsobject or nullOptional\nShow 3 properties\ntimezonestring or nullOptional\n### Response\nSuccessful Response\nidstring\nphone_number_idstring or null\nphone_providerenum or null\nAllowed values:twiliosip_trunk\nwhatsapp_paramsobject or null\nShow 3 properties\nnamestring\nagent_idstring\ncreated_at_unixinteger\nscheduled_time_unixinteger\ntimezonestring or null\ntotal_calls_dispatchedintegerDefaults to `0`\ntotal_calls_scheduledintegerDefaults to `0`\ntotal_calls_finishedintegerDefaults to `0`\nlast_updated_at_unixinteger\nstatusenum\nAllowed values:pendingin_progresscompletedfailedcancelled\nretry_countintegerDefaults to `0`\nagent_namestring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Audio Native Create",
      "path": "audio-native-create",
      "url": "https://elevenlabs.io/docs/api-reference/audio-native/create",
      "keywords": [
        "audio",
        "body",
        "create",
        "endpoint",
        "errors",
        "false",
        "headers",
        "native",
        "parameter",
        "request"
      ],
      "use_cases": [
        "How to audio native create",
        "How to create audio native create",
        "How to list audio native create",
        "How to convert audio native create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Creates Audio Native enabled project, optionally starts conversion and returns project ID and embeddable HTML snippet.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing an optional file.\nnamestringRequired\nProject name.\nimagestring or nullOptionalDeprecated\n(Deprecated) Image URL used in the player. If not provided, default image set in the Player settings is used.\nauthorstring or nullOptional\nAuthor used in the player and inserted at the start of the uploaded article. If not provided, the default author set in the Player settings is used.\ntitlestring or nullOptional\nTitle used in the player and inserted at the top of the uploaded article. If not provided, the default title set in the Player settings is used.\nsmallbooleanOptionalDefaults to `false`Deprecated\n(Deprecated) Whether to use small player or not. If not provided, default value set in the Player settings is used.\ntext_colorstring or nullOptional\nText color used in the player. If not provided, default text color set in the Player settings is used.\nbackground_colorstring or nullOptional\nBackground color used in the player. If not provided, default background color set in the Player settings is used.\nsessionizationintegerOptionalDefaults to `0`Deprecated\n(Deprecated) Specifies for how many minutes to persist the session across page reloads. If not provided, default sessionization set in the Player settings is used.\nvoice_idstring or nullOptional\nVoice ID used to voice the content. If not provided, default voice ID set in the Player settings is used.\nmodel_idstring or nullOptional\nTTS Model ID used in the player. If not provided, default model ID set in the Player settings is used.\nfilefileOptional\nEither txt or HTML input file containing the article content. HTML should be formatted as follows ‘<html><body><div><p>Your content</p><h3>More of your content</h3><p>Some more of your content</p></div></body></html>’\nauto_convertbooleanOptionalDefaults to `false`\nWhether to auto convert the project to audio or not.\napply_text_normalizationenum or nullOptional\nThis parameter controls text normalization with four modes: ‘auto’, ‘on’, ‘apply_english’ and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. ‘apply_english’ is the same as ‘on’ but will assume that text is in English.\nAllowed values:autoonoffapply_english\npronunciation_dictionary_locatorslist of stringsOptional\nA list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple —form lines in your curl, such as —form ‘pronunciation_dictionary_locators=”{“pronunciation_dictionary_id”:“Vmd4Zor6fplcA7WrINey”,“version_id”:“hRPaxjlTdR7wFMhV4w0b”}”’ —form ‘pronunciation_dictionary_locators=”{“pronunciation_dictionary_id”:“JzWtcGQMJ6bnlWwyMo7e”,“version_id”:“lbmwxiLu4q6txYxgdZqn”}”’.\n### Response\nSuccessful Response\nproject_idstring\nThe ID of the created Audio Native project.\nconvertingboolean\nWhether the project is currently being converted.\nhtml_snippetstring\nThe HTML snippet to embed the Audio Native player.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Batch Calling List",
      "path": "batch-calling-list",
      "url": "https://elevenlabs.io/docs/api-reference/batch-calling/list",
      "keywords": [
        "batch",
        "calling",
        "errors",
        "false",
        "get",
        "headers",
        "list",
        "parameters",
        "query",
        "response"
      ],
      "use_cases": [
        "How to batch calling list",
        "How to list batch calling list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get all batch calls for the current workspace.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nlimitintegerOptionalDefaults to `100`\nlast_docstring or nullOptional\n### Response\nSuccessful Response\nbatch_callslist of objects\nShow 16 properties\nnext_docstring or null\nThe next document, used to paginate through the batch calls\nhas_moreboolean or nullDefaults to `false`\nWhether there are more batch calls to paginate through\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Get",
      "path": "dubbing-get",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/get",
      "keywords": [
        "dubbing",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to dubbing get",
        "How to create dubbing get",
        "How to list dubbing get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns metadata about a dubbing project, including whether it's still in progress or not\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\ndubbing_idstring\nThe ID of the dubbing project.\nnamestring\nThe name of the dubbing project.\nstatusstring\nThe state this dub is in.\nsource_languagestring or null\nOnce dubbing has completed, the ISO-639-1 code of the original media’s source language.\ntarget_languageslist of strings\nThe ISO-639-1 code of the languages this media has been dubbed into.\ncreated_atstring`format: \"date-time\"`\nTimestamp this dub was created.\neditableboolean or nullDefaults to `false`\nWhether this dubbing project is editable in Dubbing Studio.\nmedia_metadataobject or null\nMetadata, such as the length in seconds and content type, of the dubbed content.\nShow 2 properties\nerrorstring or null\nError message indicate, if this dub has failed, what happened.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Batch Calling Retry",
      "path": "batch-calling-retry",
      "url": "https://elevenlabs.io/docs/api-reference/batch-calling/retry",
      "keywords": [
        "batch",
        "calling",
        "errors",
        "headers",
        "parameters",
        "path",
        "response",
        "retry"
      ],
      "use_cases": [
        "How to batch calling retry",
        "How to create batch calling retry",
        "How to update batch calling retry"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Retry a batch call, calling failed and no-response recipients again.\n### Path parameters\nbatch_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nphone_number_idstring or null\nphone_providerenum or null\nAllowed values:twiliosip_trunk\nwhatsapp_paramsobject or null\nShow 3 properties\nnamestring\nagent_idstring\ncreated_at_unixinteger\nscheduled_time_unixinteger\ntimezonestring or null\ntotal_calls_dispatchedintegerDefaults to `0`\ntotal_calls_scheduledintegerDefaults to `0`\ntotal_calls_finishedintegerDefaults to `0`\nlast_updated_at_unixinteger\nstatusenum\nAllowed values:pendingin_progresscompletedfailedcancelled\nretry_countintegerDefaults to `0`\nagent_namestring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Audio Get",
      "path": "dubbing-audio-get",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/audio/get",
      "keywords": [
        "audio",
        "dubbing",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to dubbing audio get",
        "How to stream dubbing audio get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns dub as a streamed MP3 or MP4 file. If this dub has been edited using Dubbing Studio you need to use the resource render endpoint as this endpoint only returns the original automatic dub result.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nlanguage_codestringRequired\nID of the language.\n### Headers\nxi-api-keystringRequired\n### Response\nThe dubbed audio or video file\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Add Language",
      "path": "dubbing-resources-add-language",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/add-language",
      "keywords": [
        "add",
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "language",
        "parameters",
        "path",
        "request",
        "resources"
      ],
      "use_cases": [
        "How to dubbing resources add language"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Adds the given ElevenLab Turbo V2/V2.5 language code to the resource. Does not automatically generate transcripts/translations/audio.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nlanguagestring or nullRequired\nThe Target language.\n### Response\nSuccessful Response\nversioninteger\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Dub Segment",
      "path": "dubbing-resources-dub-segment",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/dub-segment",
      "keywords": [
        "dub",
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "resources",
        "response"
      ],
      "use_cases": [
        "How to dubbing resources dub segment",
        "How to list dubbing resources dub segment"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Regenerate the dubs for either the entire resource or the specified segments/languages. Will automatically transcribe and translate any missing transcriptions and translations.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nsegmentslist of stringsRequired\nDub only this list of segments.\nlanguageslist of strings or nullRequired\nDub only these languages for each segment.\n### Response\nSuccessful Response\nversioninteger\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Delete",
      "path": "dubbing-delete",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/delete",
      "keywords": [
        "delete",
        "dubbing",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to dubbing delete",
        "How to delete dubbing delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Deletes a dubbing project.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the dubbing project. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Delete Segment",
      "path": "dubbing-resources-delete-segment",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/delete-segment",
      "keywords": [
        "delete",
        "dubbing",
        "errors",
        "headers",
        "parameters",
        "path",
        "resources",
        "response",
        "segment"
      ],
      "use_cases": [
        "How to dubbing resources delete segment",
        "How to delete dubbing resources delete segment"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Deletes a single segment from the dubbing.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nsegment_idstringRequired\nID of the segment\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nversioninteger\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Create Segment",
      "path": "dubbing-resources-create-segment",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/create-segment",
      "keywords": [
        "create",
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "resources",
        "response"
      ],
      "use_cases": [
        "How to dubbing resources create segment",
        "How to create dubbing resources create segment"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Creates a new segment in dubbing resource with a start and end time for the speaker in every available language. Does not automatically generate transcripts/translations/audio.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nspeaker_idstringRequired\nID of the speaker.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nstart_timedoubleRequired\nend_timedoubleRequired\ntextstring or nullOptional\ntranslationsmap from strings to strings or nullOptional\n### Response\nSuccessful Response\nversioninteger\nnew_segmentstring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Create Speaker",
      "path": "dubbing-resources-create-speaker",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/create-speaker",
      "keywords": [
        "create",
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "resources",
        "response"
      ],
      "use_cases": [
        "How to dubbing resources create speaker"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nspeaker_namestring or nullOptional\nName to attribute to this speaker.\nvoice_idstring or nullOptional\nEither the identifier of a voice from the ElevenLabs voice library, or one of [‘track-clone’, ‘clip-clone’].\nvoice_stabilitydouble or nullOptional\nFor models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\nvoice_similaritydouble or nullOptional\nFor models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\nvoice_styledouble or nullOptional\nFor models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\n### Response\nSuccessful Response\nversioninteger\nspeaker_idstring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Get Resource",
      "path": "dubbing-resources-get-resource",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/get-resource",
      "keywords": [
        "dubbing",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "resource",
        "resources",
        "response"
      ],
      "use_cases": [
        "How to dubbing resources get resource",
        "How to list dubbing resources get resource"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Given a dubbing ID generated from the ‘/v1/dubbing’ endpoint with studio enabled, returns the dubbing resource.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nversioninteger\nsource_languagestring\ntarget_languageslist of strings\ninputobject\nShow 7 properties\nbackgroundobject or null\nShow 7 properties\nforegroundobject or null\nShow 7 properties\nspeaker_tracksmap from strings to objects\nShow 5 properties\nspeaker_segmentsmap from strings to objects\nShow 6 properties\nrendersmap from strings to objects\nShow 6 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Forced Alignment Create",
      "path": "forced-alignment-create",
      "url": "https://elevenlabs.io/docs/api-reference/forced-alignment/create",
      "keywords": [
        "alignment",
        "create",
        "endpoint",
        "errors",
        "false",
        "forced",
        "get",
        "headers",
        "request",
        "response"
      ],
      "use_cases": [
        "How to forced alignment create",
        "How to list forced alignment create",
        "How to stream forced alignment create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Force align an audio file to text. Use this endpoint to get the timing information for each character and word in an audio file based on a provided text transcript.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing a file.\nfilefileRequired\nThe file to align. All major audio formats are supported. The file size must be less than 1GB.\ntextstringRequired\nThe text to align with the audio. The input text can be in any format, however diarization is not supported at this time.\nenabled_spooled_filebooleanOptionalDefaults to `false`\nIf true, the file will be streamed to the server and processed in chunks. This is useful for large files that cannot be loaded into memory. The default is false.\n### Response\nSuccessful Response\ncharacterslist of objects\nList of characters with their timing information.\nShow 3 properties\nwordslist of objects\nList of words with their timing information.\nShow 4 properties\nlossdouble\nThe average alignment loss/confidence score for the entire transcript, calculated from all characters.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Transcribe Segment",
      "path": "dubbing-resources-transcribe-segment",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/transcribe-segment",
      "keywords": [
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "resources",
        "response",
        "segment"
      ],
      "use_cases": [
        "How to dubbing resources transcribe segment",
        "How to list dubbing resources transcribe segment"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Regenerate the transcriptions for the specified segments. Does not automatically regenerate translations or dubs.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nsegmentslist of stringsRequired\nTranscribe this specific list of segments.\n### Response\nSuccessful Response\nversioninteger\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Transcripts Get",
      "path": "dubbing-transcripts-get",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/transcripts/get",
      "keywords": [
        "dubbing",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "transcripts"
      ],
      "use_cases": [
        "How to dubbing transcripts get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Fetch the transcript for one of the languages in a dub.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nlanguage_codestringRequired\nISO-693 language code to retrieve the transcript for. Use ‘source’ to fetch the transcript of the original media.\nformat_typeenumRequired\nFormat to return transcript in. For subtitles use either 'srt' or 'webvtt', and for a full transcript use 'json'. The 'json' format is not yet supported for Dubbing Studio.\nAllowed values:srtwebvttjson\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\ntranscript_formatenum\nAllowed values:srtwebvttjson\nsrtstring or null\nwebvttstring or null\njsonobject or null\nShow 2 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Translate Segment",
      "path": "dubbing-resources-translate-segment",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/translate-segment",
      "keywords": [
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "resources",
        "response",
        "segment"
      ],
      "use_cases": [
        "How to dubbing resources translate segment",
        "How to list dubbing resources translate segment"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Regenerate the translations for either the entire resource or the specified segments/languages. Will automatically transcribe missing transcriptions. Will not automatically regenerate the dubs.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nsegmentslist of stringsRequired\nTranslate only this list of segments.\nlanguageslist of strings or nullRequired\nTranslate only these languages for each segment.\n### Response\nSuccessful Response\nversioninteger\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "History Delete",
      "path": "history-delete",
      "url": "https://elevenlabs.io/docs/api-reference/history/delete",
      "keywords": [
        "delete",
        "endpoint",
        "errors",
        "get",
        "headers",
        "history",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to history delete",
        "How to delete history delete",
        "How to list history delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 7,
      "content": "Delete a history item by its ID\n### Path parameters\nhistory_item_idstringRequired\nID of the history item to be used. You can use the [Get generated items](https://elevenlabs.io/docs/api-reference/history/list) endpoint to retrieve a list of history items.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the deletion request. If the request was successful, the status will be 'ok'. Otherwise an error message with http code 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Update Segment",
      "path": "dubbing-resources-update-segment",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/update-segment",
      "keywords": [
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "resources",
        "response",
        "segment"
      ],
      "use_cases": [
        "How to dubbing resources update segment",
        "How to update dubbing resources update segment"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Modifies a single segment with new text and/or start/end times. Will update the values for only a specific language of a segment. Does not automatically regenerate the dub.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nsegment_idstringRequired\nID of the segment\nlanguagestringRequired\nID of the language.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nstart_timedouble or nullOptional\nend_timedouble or nullOptional\ntextstring or nullOptional\n### Response\nSuccessful Response\nversioninteger\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Get Similar Voices",
      "path": "dubbing-resources-get-similar-voices",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/get-similar-voices",
      "keywords": [
        "dubbing",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "resources",
        "response",
        "similar",
        "voices"
      ],
      "use_cases": [
        "How to dubbing resources get similar voices",
        "How to list dubbing resources get similar voices"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Fetch the top 10 similar voices to a speaker, including the voice IDs, names, descriptions, and, where possible, a sample audio recording.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nspeaker_idstringRequired\nID of the speaker.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nvoiceslist of objects\nShow 5 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Render Project",
      "path": "dubbing-resources-render-project",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/render-project",
      "keywords": [
        "dubbing",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "project",
        "render"
      ],
      "use_cases": [
        "How to dubbing resources render project"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Regenerate the output media for a language using the latest Studio state. Please ensure all segments have been dubbed before rendering, otherwise they will be omitted. Renders are generated asynchronously, and to check the status of all renders please use the 'Get Dubbing Resource' endpoint.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nlanguagestringRequired\nThe target language code to render, eg. 'es'. To render the source track use 'original'.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nrender_typeenumRequired\nThe type of the render. One of [‘mp4’, ‘aac’, ‘mp3’, ‘wav’, ‘aaf’, ‘tracks_zip’, ‘clips_zip’]\nShow 7 enum values\nnormalize_volumeboolean or nullOptionalDefaults to `false`\nWhether to normalize the volume of the rendered audio.\n### Response\nSuccessful Response\nversioninteger\nrender_idstring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Dubbing Resources Update Speaker",
      "path": "dubbing-resources-update-speaker",
      "url": "https://elevenlabs.io/docs/api-reference/dubbing/resources/update-speaker",
      "keywords": [
        "dubbing",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "resources",
        "response",
        "speaker"
      ],
      "use_cases": [
        "How to dubbing resources update speaker",
        "How to list dubbing resources update speaker"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Amend the metadata associated with a speaker, such as their voice. Both voice cloning and using voices from the ElevenLabs library are supported.\n### Path parameters\ndubbing_idstringRequired\nID of the dubbing project.\nspeaker_idstringRequired\nID of the speaker.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nspeaker_namestring or nullOptional\nName to attribute to this speaker.\nvoice_idstring or nullOptional\nEither the identifier of a voice from the ElevenLabs voice library, or one of [‘track-clone’, ‘clip-clone’].\nvoice_stabilitydouble or nullOptional\nFor models that support it, the voice similarity value to use. This will default to 0.65, with a valid range of [0.0, 1.0].\nvoice_similaritydouble or nullOptional\nFor models that support it, the voice similarity value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\nvoice_styledouble or nullOptional\nFor models that support it, the voice style value to use. This will default to 1.0, with a valid range of [0.0, 1.0].\nlanguageslist of strings or nullOptional\nLanguages to apply these changes to. If empty, will apply to all languages.\n### Response\nSuccessful Response\nversioninteger\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "History Download",
      "path": "history-download",
      "url": "https://elevenlabs.io/docs/api-reference/history/download",
      "keywords": [
        "download",
        "endpoint",
        "errors",
        "get",
        "headers",
        "history",
        "request",
        "response"
      ],
      "use_cases": [
        "How to history download",
        "How to list history download"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 7,
      "content": "Download one or more history items. If one history item ID is provided, we will return a single audio file. If more than one history item IDs are provided, we will provide the history items packed into a .zip file.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nhistory_item_idslist of stringsRequired\nA list of history items to download, you can get IDs of history items and other metadata using the GET <https://api.elevenlabs.io/v1/history> endpoint.\noutput_formatstring or nullOptional\nOutput format to transcode the audio file, can be wav or default.\n### Response\nThe requested audio file, or a zip file containing multiple audio files when multiple history items are requested.\n### Errors\n400\nBad Request Error\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Introduction",
      "path": "introduction",
      "url": "https://elevenlabs.io/docs/api-reference/introduction",
      "keywords": [
        "costs",
        "generation",
        "get",
        "installation",
        "introduction",
        "request",
        "response",
        "tracking"
      ],
      "use_cases": [
        "How to introduction",
        "How to convert introduction"
      ],
      "tags": [
        "getting-started",
        "api-reference"
      ],
      "priority": 10,
      "content": "## Installation\nYou can interact with the API through HTTP or Websocket requests from any language, via our official Python bindings or our official Node.js libraries.\nTo install the official Python bindings, run the following command:\n```\n\n\n$\n| pip install elevenlabs\n  \n---|---  \n\n```\n\nTo install the official Node.js library, run the following command in your Node.js project directory:\n```\n\n\n$\n| npm install @elevenlabs/elevenlabs-js\n  \n---|---  \n\n```\n\n## Tracking generation costs\nAccess response headers to retrieve generation metadata including character costs.\nPythonJavaScript\n```\n\n\n\n1\n| from elevenlabs.client import ElevenLabs\n  \n---|---  \n\n\n2\n| \n  \n\n\n3\n| client = ElevenLabs(api_key=\"your_api_key\")\n  \n\n\n4\n| \n  \n\n\n5\n| # Get raw response with headers\n  \n\n\n6\n| response = client.text_to_speech.with_raw_response.convert(\n  \n\n\n7\n|     text=\"Hello, world!\",\n  \n\n\n8\n|     voice_id=\"voice_id\"\n  \n\n\n9\n| )\n  \n\n\n10\n| \n  \n\n\n11\n| # Access character cost from headers\n  \n\n\n12\n| char_cost = response.headers.get(\"x-character-count\")\n  \n\n\n13\n| request_id = response.headers.get(\"request-id\")\n  \n\n\n14\n| audio_data = response.data\n  \n\n\n\n```\n\nThe raw response provides access to:\n  * Response data - The actual API response content\n  * HTTP headers - Metadata including character costs and request IDs\n\n\n"
    },
    {
      "title": "Mcp Approval Policies Update",
      "path": "mcp-approval-policies-update",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/approval-policies/update",
      "keywords": [
        "approval",
        "endpoint",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "patch",
        "path",
        "policies",
        "request"
      ],
      "use_cases": [
        "How to mcp approval policies update",
        "How to list mcp approval policies update",
        "How to update mcp approval policies update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Update the approval policy configuration for an MCP server. DEPRECATED: Use PATCH /mcp-servers/{id} endpoint instead.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\napproval_policyenumRequired\nThe approval mode to set for the MCP server\nAllowed values:auto_approve_allrequire_approval_allrequire_approval_per_tool\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "History Get Audio",
      "path": "history-get-audio",
      "url": "https://elevenlabs.io/docs/api-reference/history/get-audio",
      "keywords": [
        "audio",
        "endpoint",
        "errors",
        "get",
        "headers",
        "history",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to history get audio",
        "How to list history get audio"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 7,
      "content": "Returns the audio of an history item.\n### Path parameters\nhistory_item_idstringRequired\nID of the history item to be used. You can use the [Get generated items](https://elevenlabs.io/docs/api-reference/history/list) endpoint to retrieve a list of history items.\n### Headers\nxi-api-keystringRequired\n### Response\nThe audio file of the history item.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "History Get",
      "path": "history-get",
      "url": "https://elevenlabs.io/docs/api-reference/history/get",
      "keywords": [
        "endpoint",
        "errors",
        "get",
        "headers",
        "history",
        "parameters",
        "path",
        "request",
        "response",
        "text"
      ],
      "use_cases": [
        "How to history get",
        "How to create history get",
        "How to list history get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 7,
      "content": "Retrieves a history item.\n### Path parameters\nhistory_item_idstringRequired\nID of the history item to be used. You can use the [Get generated items](https://elevenlabs.io/docs/api-reference/history/list) endpoint to retrieve a list of history items.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nhistory_item_idstring\nThe ID of the history item.\ndate_unixinteger\nUnix timestamp of when the item was created.\ncharacter_count_change_frominteger\nThe character count change from.\ncharacter_count_change_tointeger\nThe character count change to.\ncontent_typestring\nThe content type of the generated item.\nstateany\nrequest_idstring or null\nThe ID of the request.\nvoice_idstring or null\nThe ID of the voice used.\nmodel_idstring or null\nThe ID of the model.\nvoice_namestring or null\nThe name of the voice.\nvoice_categoryenum or null\nThe category of the voice. Either 'premade', 'cloned', 'generated' or 'professional'.\nAllowed values:premadeclonedgeneratedprofessional\ntextstring or null\nThe text used to generate the audio item.\nsettingsobject or null\nThe settings of the history item.\nfeedbackobject or null\nFeedback associated with the generated item. Returns null if no feedback has been provided.\nShow 8 properties\nshare_link_idstring or null\nThe ID of the share link.\nsourceenum or null\nThe source of the history item. Either TTS (text to speech), STS (speech to text), AN (audio native), Projects, Dubbing, PlayAPI, PD (pronunciation dictionary) or ConvAI (Agents Platform).\nShow 9 enum values\nalignmentsobject or null\nThe alignments of the history item.\nShow 2 properties\ndialoguelist of objects or null\nThe dialogue (voice and text pairs) used to generate the audio item. If this is set then the top level `text` and `voice_id` fields will be empty.\nShow 3 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Llm Usage Calculate",
      "path": "llm-usage-calculate",
      "url": "https://elevenlabs.io/docs/api-reference/llm-usage/calculate",
      "keywords": [
        "calculate",
        "endpoint",
        "errors",
        "headers",
        "llm",
        "request",
        "response",
        "usage"
      ],
      "use_cases": [
        "How to llm usage calculate",
        "How to list llm usage calculate"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Returns a list of LLM models and the expected cost for using them based on the provided values.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nprompt_lengthintegerRequired\nLength of the prompt in characters.\nnumber_of_pagesintegerRequired\nPages of content in PDF documents or URLs in the agent's knowledge base.\nrag_enabledbooleanRequired\nWhether RAG is enabled.\n### Response\nSuccessful Response\nllm_priceslist of objects\nShow 2 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Approval Policies Create",
      "path": "mcp-approval-policies-create",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/approval-policies/create",
      "keywords": [
        "approval",
        "create",
        "endpoint",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "path",
        "policies",
        "request"
      ],
      "use_cases": [
        "How to mcp approval policies create",
        "How to list mcp approval policies create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Add approval for a specific MCP tool when using per-tool approval mode.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\ntool_namestringRequired\nThe name of the MCP tool\ntool_descriptionstringRequired\nThe description of the MCP tool\ninput_schemaobjectOptional\nThe input schema of the MCP tool (the schema defined on the MCP server before ElevenLabs does any extra processing)\napproval_policyenumOptional\nThe tool-level approval policy\nAllowed values:auto_approvedrequires_approval\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Create",
      "path": "mcp-create",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/create",
      "keywords": [
        "create",
        "endpoint",
        "errors",
        "headers",
        "mcp",
        "request",
        "response"
      ],
      "use_cases": [
        "How to mcp create",
        "How to create mcp create",
        "How to list mcp create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Create a new MCP server configuration in the workspace.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nconfigobjectRequired\nConfiguration details for the MCP Server.\nShow 15 properties\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "History List",
      "path": "history-list",
      "url": "https://elevenlabs.io/docs/api-reference/history/list",
      "keywords": [
        "desc",
        "endpoint",
        "errors",
        "get",
        "headers",
        "history",
        "list",
        "parameter",
        "parameters",
        "query"
      ],
      "use_cases": [
        "How to history list",
        "How to create history list",
        "How to list history list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 7,
      "content": "Returns a list of your generated audio.\n### Headers\nxi-api-keystringRequired\n### Query parameters\npage_sizeintegerOptionalDefaults to `100`\nHow many history items to return at maximum. Can not exceed 1000, defaults to 100.\nstart_after_history_item_idstring or nullOptional\nAfter which ID to start fetching, use this parameter to paginate across a large collection of history items. In case this parameter is not provided history items will be fetched starting from the most recently created one ordered descending by their creation date.\nvoice_idstring or nullOptional\nID of the voice to be filtered for. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\nmodel_idstring or nullOptional\nSearch term used for filtering history items. If provided, source becomes required.\ndate_before_unixinteger or nullOptional\nUnix timestamp to filter history items before this date (exclusive).\ndate_after_unixinteger or nullOptional\nUnix timestamp to filter history items after this date (inclusive).\nsort_directionenum or nullOptionalDefaults to `desc`\nSort direction for the results.\nAllowed values:ascdesc\nsearchstring or nullOptional\nsearch term used for filtering\nsourceenum or nullOptional\nSource of the generated history item\nAllowed values:TTSSTS\n### Response\nSuccessful Response\nhistorylist of objects\nA list of speech history items.\nShow 18 properties\nhas_moreboolean\nWhether there are more history items to fetch.\nlast_history_item_idstring or null\nThe ID of the last history item.\nscanned_untilinteger or null\nThe timestamp of the last history item.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Approval Policies Delete",
      "path": "mcp-approval-policies-delete",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/approval-policies/delete",
      "keywords": [
        "approval",
        "delete",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "path",
        "policies",
        "response"
      ],
      "use_cases": [
        "How to mcp approval policies delete",
        "How to list mcp approval policies delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Remove approval for a specific MCP tool when using per-tool approval mode.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\ntool_namestringRequired\nName of the MCP tool to remove approval for.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Delete",
      "path": "mcp-delete",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/delete",
      "keywords": [
        "delete",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to mcp delete",
        "How to delete mcp delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Delete a specific MCP server configuration from the workspace.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Get",
      "path": "mcp-get",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/get",
      "keywords": [
        "errors",
        "get",
        "headers",
        "mcp",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to mcp get",
        "How to list mcp get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Retrieve a specific MCP server configuration from the workspace.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp List",
      "path": "mcp-list",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/list",
      "keywords": [
        "errors",
        "headers",
        "list",
        "mcp",
        "response"
      ],
      "use_cases": [
        "How to mcp list",
        "How to list mcp list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Retrieve all MCP server configurations available in the workspace.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nmcp_serverslist of objects\nShow 5 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Update",
      "path": "mcp-update",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/update",
      "keywords": [
        "endpoint",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "path",
        "request",
        "response",
        "update"
      ],
      "use_cases": [
        "How to mcp update",
        "How to list mcp update",
        "How to update mcp update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Update the configuration settings for an MCP server.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\napproval_policyenum or nullOptional\nThe approval mode to set for the MCP server\nAllowed values:auto_approve_allrequire_approval_allrequire_approval_per_tool\nforce_pre_tool_speechboolean or nullOptional\nIf set, overrides the server’s force_pre_tool_speech setting for this tool\ndisable_interruptionsboolean or nullOptional\nIf set, overrides the server’s disable_interruptions setting for this tool\ntool_call_soundenum or nullOptional\nPredefined tool call sound type to play during tool execution for all tools from this MCP server\nAllowed values:typingelevator1elevator2elevator3elevator4\ntool_call_sound_behaviorenum or nullOptional\nDetermines when the tool call sound should play for all tools from this MCP server\nAllowed values:autoalways\nexecution_modeenum or nullOptional\nIf set, overrides the server’s execution_mode setting for this tool\nAllowed values:immediatepost_tool_speechasync\nrequest_headersmap from strings to strings or objects or nullOptional\nThe headers to include in requests to the MCP server\nShow 3 variants\ndisable_compressionboolean or nullOptional\nWhether to disable HTTP compression for this MCP server\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Tool Configuration Delete",
      "path": "mcp-tool-configuration-delete",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/tool-configuration/delete",
      "keywords": [
        "configuration",
        "delete",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "path",
        "response",
        "tool"
      ],
      "use_cases": [
        "How to mcp tool configuration delete",
        "How to list mcp tool configuration delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Remove configuration overrides for a specific MCP tool.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\ntool_namestringRequired\nName of the MCP tool to remove config overrides for.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp List Tools",
      "path": "mcp-list-tools",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/list-tools",
      "keywords": [
        "errors",
        "headers",
        "list",
        "mcp",
        "parameters",
        "path",
        "response",
        "tools"
      ],
      "use_cases": [
        "How to mcp list tools",
        "How to list mcp list tools"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Retrieve all tools available for a specific MCP server configuration.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nsuccessboolean\nIndicates if the operation was successful.\ntoolslist of objects\nA list of tools available on the MCP server.\nShow 7 properties\nerror_messagestring or null\nError message if the operation was not successful.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Tool Configuration Get",
      "path": "mcp-tool-configuration-get",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/tool-configuration/get",
      "keywords": [
        "configuration",
        "errors",
        "get",
        "headers",
        "mcp",
        "parameters",
        "path",
        "response",
        "tool"
      ],
      "use_cases": [
        "How to mcp tool configuration get",
        "How to list mcp tool configuration get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Retrieve configuration overrides for a specific MCP tool.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\ntool_namestringRequired\nName of the MCP tool to retrieve config overrides for.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\ntool_namestring\nThe name of the MCP tool\nforce_pre_tool_speechboolean or null\nIf set, overrides the server’s force_pre_tool_speech setting for this tool\ndisable_interruptionsboolean or null\nIf set, overrides the server’s disable_interruptions setting for this tool\ntool_call_soundenum or null\nIf set, overrides the server’s tool_call_sound setting for this tool\nAllowed values:typingelevator1elevator2elevator3elevator4\ntool_call_sound_behaviorenum or null\nIf set, overrides the server’s tool_call_sound_behavior setting for this tool\nAllowed values:autoalways\nexecution_modeenum or null\nIf set, overrides the server’s execution_mode setting for this tool\nAllowed values:immediatepost_tool_speechasync\nassignmentslist of objects or null\nDynamic variable assignments for this MCP tool\nShow 3 properties\n### Errors\n404\nNot Found Error\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Tool Configuration Create",
      "path": "mcp-tool-configuration-create",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/tool-configuration/create",
      "keywords": [
        "configuration",
        "create",
        "endpoint",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to mcp tool configuration create",
        "How to create mcp tool configuration create",
        "How to list mcp tool configuration create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Create configuration overrides for a specific MCP tool.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\ntool_namestringRequired\nThe name of the MCP tool\nforce_pre_tool_speechboolean or nullOptional\nIf set, overrides the server’s force_pre_tool_speech setting for this tool\ndisable_interruptionsboolean or nullOptional\nIf set, overrides the server’s disable_interruptions setting for this tool\ntool_call_soundenum or nullOptional\nIf set, overrides the server’s tool_call_sound setting for this tool\nAllowed values:typingelevator1elevator2elevator3elevator4\ntool_call_sound_behaviorenum or nullOptional\nIf set, overrides the server’s tool_call_sound_behavior setting for this tool\nAllowed values:autoalways\nexecution_modeenum or nullOptional\nIf set, overrides the server’s execution_mode setting for this tool\nAllowed values:immediatepost_tool_speechasync\nassignmentslist of objects or nullOptional\nDynamic variable assignments for this MCP tool\nShow 3 properties\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n409\nConflict Error\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Models List",
      "path": "models-list",
      "url": "https://elevenlabs.io/docs/api-reference/models/list",
      "keywords": [
        "errors",
        "headers",
        "list",
        "models",
        "response"
      ],
      "use_cases": [
        "How to models list",
        "How to list models list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 7,
      "content": "Gets a list of available models.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nmodel_idstring\nThe unique identifier of the model.\nnamestring or null\nThe name of the model.\ncan_be_finetunedboolean or null\nWhether the model can be finetuned.\ncan_do_text_to_speechboolean or null\nWhether the model can do text-to-speech.\ncan_do_voice_conversionboolean or null\nWhether the model can do voice conversion.\ncan_use_styleboolean or null\nWhether the model can use style.\ncan_use_speaker_boostboolean or null\nWhether the model can use speaker boost.\nserves_pro_voicesboolean or null\nWhether the model serves pro voices.\ntoken_cost_factordouble or null\nThe cost factor for the model.\ndescriptionstring or null\nThe description of the model.\nrequires_alpha_accessboolean or null\nWhether the model requires alpha access.\nmax_characters_request_free_userinteger or null\nThe maximum number of characters that can be requested by a free user.\nmax_characters_request_subscribed_userinteger or null\nThe maximum number of characters that can be requested by a subscribed user.\nmaximum_text_length_per_requestinteger or null\nThe maximum length of text that can be requested for this model.\nlanguageslist of objects or null\nThe languages supported by the model.\nShow 2 properties\nmodel_ratesobject or null\nThe rates for the model.\nShow 1 properties\nconcurrency_groupstring or null\nThe concurrency group for the model.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Mcp Tool Configuration Update",
      "path": "mcp-tool-configuration-update",
      "url": "https://elevenlabs.io/docs/api-reference/mcp/tool-configuration/update",
      "keywords": [
        "configuration",
        "endpoint",
        "errors",
        "headers",
        "mcp",
        "parameters",
        "path",
        "request",
        "response",
        "tool"
      ],
      "use_cases": [
        "How to mcp tool configuration update",
        "How to list mcp tool configuration update",
        "How to update mcp tool configuration update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Update configuration overrides for a specific MCP tool.\n### Path parameters\nmcp_server_idstringRequired\nID of the MCP Server.\ntool_namestringRequired\nName of the MCP tool to update config overrides for.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nforce_pre_tool_speechboolean or nullOptional\nIf set, overrides the server’s force_pre_tool_speech setting for this tool\ndisable_interruptionsboolean or nullOptional\nIf set, overrides the server’s disable_interruptions setting for this tool\ntool_call_soundenum or nullOptional\nIf set, overrides the server’s tool_call_sound setting for this tool\nAllowed values:typingelevator1elevator2elevator3elevator4\ntool_call_sound_behaviorenum or nullOptional\nIf set, overrides the server’s tool_call_sound_behavior setting for this tool\nAllowed values:autoalways\nexecution_modeenum or nullOptional\nIf set, overrides the server’s execution_mode setting for this tool\nAllowed values:immediatepost_tool_speechasync\nassignmentslist of objects or nullOptional\nDynamic variable assignments for this MCP tool\nShow 3 properties\n### Response\nSuccessful Response\nidstring\nconfigobject\nShow 15 properties\nmetadataobject\nThe metadata of the MCP Server\nShow 2 properties\naccess_infoobject or null\nThe access information of the MCP Server\nShow 4 properties\ndependent_agentslist of objects or null\nList of agents that depend on this MCP Server.\nShow 2 variants\n### Errors\n404\nNot Found Error\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Music Compose",
      "path": "music-compose",
      "url": "https://elevenlabs.io/docs/api-reference/music/compose",
      "keywords": [
        "compose",
        "composition_plan",
        "duration_ms",
        "endpoint",
        "errors",
        "false",
        "headers",
        "music",
        "music_v1",
        "parameters"
      ],
      "use_cases": [
        "How to music compose"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Compose a song from a prompt or a composition plan.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\npromptstring or nullOptional`<=4100 characters`\nA simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\ncomposition_planobject or nullOptional\nA detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\nShow 3 properties\nmusic_length_msinteger or nullOptional`3000-600000`\nThe length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 600000ms. Optional - if not provided, the model will choose a length based on the prompt.\nmodel_idenumOptionalDefaults to `music_v1`\nThe model to use for the generation.\nAllowed values:music_v1\nforce_instrumentalbooleanOptionalDefaults to `false`\nIf true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\nrespect_sections_durationsbooleanOptionalDefaults to `true`\nControls how strictly section durations in the `composition_plan` are enforced. Only used with `composition_plan`. When set to true, the model will precisely respect each section’s `duration_ms` from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.\nstore_for_inpaintingbooleanOptionalDefaults to `false`\nWhether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\nsign_with_c2pabooleanOptionalDefaults to `false`\nWhether to sign the generated song with C2PA. Applicable only for mp3 files.\n### Response\nThe generated audio file in the format specified\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries Create From Rules",
      "path": "pronunciation-dictionaries-create-from-rules",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/create-from-rules",
      "keywords": [
        "create",
        "dictionaries",
        "endpoint",
        "errors",
        "headers",
        "pronunciation",
        "request",
        "response",
        "rules"
      ],
      "use_cases": [
        "How to pronunciation dictionaries create from rules",
        "How to create pronunciation dictionaries create from rules",
        "How to list pronunciation dictionaries create from rules"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Creates a new pronunciation dictionary from provided rules.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nruleslist of objectsRequired\nList of pronunciation rules. Rule can be either: an alias rule: {‘string_to_replace’: ‘a’, ‘type’: ‘alias’, ‘alias’: ‘b’, } or a phoneme rule: {‘string_to_replace’: ‘a’, ‘type’: ‘phoneme’, ‘phoneme’: ‘b’, ‘alphabet’: ‘ipa’ }\nShow 2 variants\nnamestringRequired\nThe name of the pronunciation dictionary, used for identification only.\ndescriptionstring or nullOptional\nA description of the pronunciation dictionary, used for identification only.\nworkspace_accessenum or nullOptional\nShould be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\nAllowed values:admineditorcommenterviewer\n### Response\nSuccessful Response\nidstring\nThe ID of the created pronunciation dictionary.\nnamestring\nThe name of the created pronunciation dictionary.\ncreated_bystring\nThe user ID of the creator of the pronunciation dictionary.\ncreation_time_unixinteger\nThe creation time of the pronunciation dictionary in Unix timestamp.\nversion_idstring\nThe ID of the created pronunciation dictionary version.\nversion_rules_numinteger\nThe number of rules in the version of the pronunciation dictionary.\npermission_on_resourceenum or null\nThe permission on the resource of the pronunciation dictionary.\nAllowed values:admineditorcommenterviewer\ndescriptionstring or null\nThe description of the pronunciation dictionary.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Music Create Composition Plan",
      "path": "music-create-composition-plan",
      "url": "https://elevenlabs.io/docs/api-reference/music/create-composition-plan",
      "keywords": [
        "composition",
        "create",
        "endpoint",
        "errors",
        "headers",
        "music",
        "music_v1",
        "plan",
        "request",
        "response"
      ],
      "use_cases": [
        "How to music create composition plan",
        "How to create music create composition plan",
        "How to list music create composition plan"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Create a composition plan for music generation. Usage of this endpoint does not cost any credits but is subject to rate limiting depending on your tier.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\npromptstringRequired`<=4100 characters`\nA simple text prompt to compose a plan from.\nmusic_length_msinteger or nullOptional`3000-600000`\nThe length of the composition plan to generate in milliseconds. Must be between 3000ms and 600000ms. Optional - if not provided, the model will choose a length based on the prompt.\nsource_composition_planobject or nullOptional\nAn optional composition plan to use as a source for the new composition plan.\nShow 3 properties\nmodel_idenumOptionalDefaults to `music_v1`\nThe model to use for the generation.\nAllowed values:music_v1\n### Response\nSuccessful Response\npositive_global_styleslist of strings\nThe styles and musical directions that should be present in the entire song. Use English language for best result.\nnegative_global_styleslist of strings\nThe styles and musical directions that should not be present in the entire song. Use English language for best result.\nsectionslist of objects\nThe sections of the song.\nShow 6 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries Create From File",
      "path": "pronunciation-dictionaries-create-from-file",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/create-from-file",
      "keywords": [
        "create",
        "dictionaries",
        "endpoint",
        "errors",
        "file",
        "headers",
        "pronunciation",
        "request",
        "response"
      ],
      "use_cases": [
        "How to pronunciation dictionaries create from file",
        "How to create pronunciation dictionaries create from file"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Creates a new pronunciation dictionary from a lexicon .PLS file\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing an optional file.\nnamestringRequired\nThe name of the pronunciation dictionary, used for identification only.\nfilefileOptional\nA lexicon .pls file which we will use to initialize the project with.\ndescriptionstring or nullOptional\nA description of the pronunciation dictionary, used for identification only.\nworkspace_accessenum or nullOptional\nShould be one of 'admin', 'editor' or 'viewer'. If not provided, defaults to no access.\nAllowed values:admineditorcommenterviewer\n### Response\nSuccessful Response\nidstring\nThe ID of the created pronunciation dictionary.\nnamestring\nThe name of the created pronunciation dictionary.\ncreated_bystring\nThe user ID of the creator of the pronunciation dictionary.\ncreation_time_unixinteger\nThe creation time of the pronunciation dictionary in Unix timestamp.\nversion_idstring\nThe ID of the created pronunciation dictionary version.\nversion_rules_numinteger\nThe number of rules in the version of the pronunciation dictionary.\npermission_on_resourceenum or null\nThe permission on the resource of the pronunciation dictionary.\nAllowed values:admineditorcommenterviewer\ndescriptionstring or null\nThe description of the pronunciation dictionary.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Music Stream",
      "path": "music-stream",
      "url": "https://elevenlabs.io/docs/api-reference/music/stream",
      "keywords": [
        "composition_plan",
        "endpoint",
        "errors",
        "false",
        "headers",
        "music",
        "music_v1",
        "parameters",
        "prompt",
        "query"
      ],
      "use_cases": [
        "How to music stream",
        "How to stream music stream"
      ],
      "tags": [
        "api-reference",
        "streaming"
      ],
      "priority": 6,
      "content": "Stream a composed song from a prompt or a composition plan.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\npromptstring or nullOptional`<=4100 characters`\nA simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\ncomposition_planobject or nullOptional\nA detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\nShow 3 properties\nmusic_length_msinteger or nullOptional`3000-600000`\nThe length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 600000ms. Optional - if not provided, the model will choose a length based on the prompt.\nmodel_idenumOptionalDefaults to `music_v1`\nThe model to use for the generation.\nAllowed values:music_v1\nforce_instrumentalbooleanOptionalDefaults to `false`\nIf true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\nstore_for_inpaintingbooleanOptionalDefaults to `false`\nWhether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\n### Response\nStreaming audio data in the format specified\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries Download",
      "path": "pronunciation-dictionaries-download",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/download",
      "keywords": [
        "dictionaries",
        "download",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "pronunciation",
        "response"
      ],
      "use_cases": [
        "How to pronunciation dictionaries download"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Get a PLS file with a pronunciation dictionary version rules\n### Path parameters\ndictionary_idstringRequired\nThe id of the pronunciation dictionary\nversion_idstringRequired\nThe id of the pronunciation dictionary version\n### Headers\nxi-api-keystringRequired\n### Response\nThe PLS file containing pronunciation dictionary rules\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries Get",
      "path": "pronunciation-dictionaries-get",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/get",
      "keywords": [
        "dictionaries",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "pronunciation",
        "response"
      ],
      "use_cases": [
        "How to pronunciation dictionaries get",
        "How to create pronunciation dictionaries get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get metadata for a pronunciation dictionary\n### Path parameters\npronunciation_dictionary_idstringRequired\nThe id of the pronunciation dictionary\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nidstring\nThe ID of the pronunciation dictionary.\nlatest_version_idstring\nThe ID of the latest version of the pronunciation dictionary.\nlatest_version_rules_numinteger\nThe number of rules in the latest version of the pronunciation dictionary.\nnamestring\nThe name of the pronunciation dictionary.\npermission_on_resourceenum or null\nThe permission on the resource of the pronunciation dictionary.\nAllowed values:admineditorcommenterviewer\ncreated_bystring\nThe user ID of the creator of the pronunciation dictionary.\ncreation_time_unixinteger\nThe creation time of the pronunciation dictionary in Unix timestamp.\narchived_time_unixinteger or null\nThe archive time of the pronunciation dictionary in Unix timestamp.\ndescriptionstring or null\nThe description of the pronunciation dictionary.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries List",
      "path": "pronunciation-dictionaries-list",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/list",
      "keywords": [
        "creation_time_unix",
        "descending",
        "dictionaries",
        "errors",
        "get",
        "headers",
        "list",
        "parameters",
        "pronunciation",
        "query"
      ],
      "use_cases": [
        "How to pronunciation dictionaries list",
        "How to create pronunciation dictionaries list",
        "How to list pronunciation dictionaries list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get a list of the pronunciation dictionaries you have access to and their metadata\n### Headers\nxi-api-keystringRequired\n### Query parameters\ncursorstring or nullOptional\nUsed for fetching next page. Cursor is returned in the response.\npage_sizeintegerOptional`1-100`Defaults to `30`\nHow many pronunciation dictionaries to return at maximum. Can not exceed 100, defaults to 30.\nsortenum or nullOptionalDefaults to `creation_time_unix`\nWhich field to sort by, one of ‘created_at_unix’ or ‘name’.\nAllowed values:creation_time_unixname\nsort_directionstring or nullOptionalDefaults to `DESCENDING`\nWhich direction to sort the voices in. 'ascending' or 'descending'.\n### Response\nSuccessful Response\npronunciation_dictionarieslist of objects\nA list of pronunciation dictionaries and their metadata.\nShow 9 properties\nhas_moreboolean\nWhether there are more pronunciation dictionaries to fetch.\nnext_cursorstring or null\nThe next cursor to use for pagination.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Music Compose Detailed",
      "path": "music-compose-detailed",
      "url": "https://elevenlabs.io/docs/api-reference/music/compose-detailed",
      "keywords": [
        "compose",
        "composition_plan",
        "detailed",
        "endpoint",
        "errors",
        "false",
        "headers",
        "music",
        "music_v1",
        "parameters"
      ],
      "use_cases": [
        "How to music compose detailed"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Compose a song from a prompt or a composition plan.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\npromptstring or nullOptional`<=4100 characters`\nA simple text prompt to generate a song from. Cannot be used in conjunction with `composition_plan`.\ncomposition_planobject or nullOptional\nA detailed composition plan to guide music generation. Cannot be used in conjunction with `prompt`.\nShow 3 properties\nmusic_length_msinteger or nullOptional`3000-600000`\nThe length of the song to generate in milliseconds. Used only in conjunction with `prompt`. Must be between 3000ms and 600000ms. Optional - if not provided, the model will choose a length based on the prompt.\nmodel_idenumOptionalDefaults to `music_v1`\nThe model to use for the generation.\nAllowed values:music_v1\nforce_instrumentalbooleanOptionalDefaults to `false`\nIf true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the `prompt`. Can only be used with `prompt`.\nstore_for_inpaintingbooleanOptionalDefaults to `false`\nWhether to store the generated song for inpainting. Only available to enterprise clients with access to the inpainting API.\nwith_timestampsbooleanOptionalDefaults to `false`\nWhether to return the timestamps of the words in the generated song.\nsign_with_c2pabooleanOptionalDefaults to `false`\nWhether to sign the generated song with C2PA. Applicable only for mp3 files.\n### Response\nMultipart/mixed response with JSON metadata and binary audio file\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Music Separate Stems",
      "path": "music-separate-stems",
      "url": "https://elevenlabs.io/docs/api-reference/music/separate-stems",
      "keywords": [
        "endpoint",
        "errors",
        "false",
        "headers",
        "music",
        "parameters",
        "query",
        "request",
        "response",
        "separate"
      ],
      "use_cases": [
        "How to music separate stems"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Separate an audio file into individual stems. This endpoint might have high latency, depending on the length of the audio file.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects a multipart form containing a file.\nfilefileRequired\nThe audio file to separate into stems.\nstem_variation_idenumOptionalDefaults to `six_stems_v1`\nThe id of the stem variation to use.\nAllowed values:two_stems_v1six_stems_v1\nsign_with_c2pabooleanOptionalDefaults to `false`\nWhether to sign the generated song with C2PA. Applicable only for mp3 files.\n### Response\nZIP archive containing separated audio stems. Each stem is provided as a separate audio file in the requested output format.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries Rules Add",
      "path": "pronunciation-dictionaries-rules-add",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/rules/add",
      "keywords": [
        "add",
        "dictionaries",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "pronunciation",
        "request",
        "response"
      ],
      "use_cases": [
        "How to pronunciation dictionaries rules add",
        "How to list pronunciation dictionaries rules add"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Add rules to the pronunciation dictionary\n### Path parameters\npronunciation_dictionary_idstringRequired\nThe id of the pronunciation dictionary\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nruleslist of objectsRequired\nList of pronunciation rules. Rule can be either: an alias rule: {‘string_to_replace’: ‘a’, ‘type’: ‘alias’, ‘alias’: ‘b’, } or a phoneme rule: {‘string_to_replace’: ‘a’, ‘type’: ‘phoneme’, ‘phoneme’: ‘b’, ‘alphabet’: ‘ipa’ }\nShow 2 variants\n### Response\nSuccessful Response\nidstring\nThe ID of the pronunciation dictionary.\nversion_idstring\nThe version ID of the pronunciation dictionary.\nversion_rules_numinteger\nThe number of rules in the version of the pronunciation dictionary.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Service Accounts Api Keys Update",
      "path": "service-accounts-api-keys-update",
      "url": "https://elevenlabs.io/docs/api-reference/service-accounts/api-keys/update",
      "keywords": [
        "accounts",
        "api",
        "endpoint",
        "errors",
        "headers",
        "keys",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to service accounts api keys update",
        "How to list service accounts api keys update",
        "How to update service accounts api keys update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Update an existing API key for a service account\n### Path parameters\nservice_account_user_idstringRequired\napi_key_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nis_enabledbooleanRequired\nWhether to enable or disable the API key.\nnamestringRequired\nThe name of the XI API key to use (used for identification purposes only).\npermissionslist of enums or \"all\"Required\nThe permissions of the XI API.\nShow 2 variants\ncharacter_limitinteger or nullOptional\nThe character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Service Accounts Api Keys Delete",
      "path": "service-accounts-api-keys-delete",
      "url": "https://elevenlabs.io/docs/api-reference/service-accounts/api-keys/delete",
      "keywords": [
        "accounts",
        "api",
        "delete",
        "errors",
        "headers",
        "keys",
        "parameters",
        "path",
        "response",
        "service"
      ],
      "use_cases": [
        "How to service accounts api keys delete",
        "How to delete service accounts api keys delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Delete an existing API key for a service account\n### Path parameters\nservice_account_user_idstringRequired\napi_key_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Service Accounts Api Keys List",
      "path": "service-accounts-api-keys-list",
      "url": "https://elevenlabs.io/docs/api-reference/service-accounts/api-keys/list",
      "keywords": [
        "accounts",
        "api",
        "errors",
        "get",
        "headers",
        "keys",
        "list",
        "parameters",
        "path",
        "response"
      ],
      "use_cases": [
        "How to service accounts api keys list",
        "How to list service accounts api keys list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Get all API keys for a service account\n### Path parameters\nservice_account_user_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\napi-keyslist of objects\nShow 9 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries Rules Remove",
      "path": "pronunciation-dictionaries-rules-remove",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/rules/remove",
      "keywords": [
        "dictionaries",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "pronunciation",
        "remove",
        "request",
        "response"
      ],
      "use_cases": [
        "How to pronunciation dictionaries rules remove",
        "How to list pronunciation dictionaries rules remove"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Remove rules from the pronunciation dictionary\n### Path parameters\npronunciation_dictionary_idstringRequired\nThe id of the pronunciation dictionary\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nrule_stringslist of stringsRequired\nList of strings to remove from the pronunciation dictionary.\n### Response\nSuccessful Response\nidstring\nThe ID of the pronunciation dictionary.\nversion_idstring\nThe version ID of the pronunciation dictionary.\nversion_rules_numinteger\nThe number of rules in the version of the pronunciation dictionary.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Service Accounts Api Keys Create",
      "path": "service-accounts-api-keys-create",
      "url": "https://elevenlabs.io/docs/api-reference/service-accounts/api-keys/create",
      "keywords": [
        "accounts",
        "api",
        "create",
        "endpoint",
        "errors",
        "headers",
        "keys",
        "parameters",
        "path",
        "request"
      ],
      "use_cases": [
        "How to service accounts api keys create",
        "How to create service accounts api keys create",
        "How to list service accounts api keys create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Create a new API key for a service account\n### Path parameters\nservice_account_user_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnamestringRequired\npermissionslist of enums or \"all\"Required\nThe permissions of the XI API.\nShow 2 variants\ncharacter_limitinteger or nullOptional\nThe character limit of the XI API key. If provided this will limit the usage of this api key to n characters per month where n is the chosen value. Requests that incur charges will fail after reaching this monthly limit.\n### Response\nSuccessful Response\nxi-api-keystring\nkey_idstring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Pronunciation Dictionaries Update",
      "path": "pronunciation-dictionaries-update",
      "url": "https://elevenlabs.io/docs/api-reference/pronunciation-dictionaries/update",
      "keywords": [
        "dictionaries",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "pronunciation",
        "request",
        "response",
        "update"
      ],
      "use_cases": [
        "How to pronunciation dictionaries update",
        "How to create pronunciation dictionaries update",
        "How to update pronunciation dictionaries update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Partially update the pronunciation dictionary without changing the version\n### Path parameters\npronunciation_dictionary_idstringRequired\nThe id of the pronunciation dictionary\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\narchivedbooleanOptional\nThe name of the pronunciation dictionary, used for identification only.\nnamestringOptional\nThe name of the pronunciation dictionary, used for identification only.\n### Response\nSuccessful Response\nidstring\nThe ID of the pronunciation dictionary.\nlatest_version_idstring\nThe ID of the latest version of the pronunciation dictionary.\nlatest_version_rules_numinteger\nThe number of rules in the latest version of the pronunciation dictionary.\nnamestring\nThe name of the pronunciation dictionary.\npermission_on_resourceenum or null\nThe permission on the resource of the pronunciation dictionary.\nAllowed values:admineditorcommenterviewer\ncreated_bystring\nThe user ID of the creator of the pronunciation dictionary.\ncreation_time_unixinteger\nThe creation time of the pronunciation dictionary in Unix timestamp.\narchived_time_unixinteger or null\nThe archive time of the pronunciation dictionary in Unix timestamp.\ndescriptionstring or null\nThe description of the pronunciation dictionary.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Speech To Speech Convert",
      "path": "speech-to-speech-convert",
      "url": "https://elevenlabs.io/docs/api-reference/speech-to-speech/convert",
      "keywords": [
        "convert",
        "eleven_english_sts_v2",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "mp3_44100_128",
        "other",
        "parameters"
      ],
      "use_cases": [
        "How to speech to speech convert",
        "How to list speech to speech convert",
        "How to stream speech to speech convert"
      ],
      "tags": [
        "api-reference",
        "conversion",
        "speech"
      ],
      "priority": 8,
      "content": "Transform audio from one voice to another. Maintain full control over emotion, timing and delivery.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. Use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\noptimize_streaming_latencyinteger or nullOptionalDeprecated\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\noutput_formatenumOptionalDefaults to `mp3_44100_128`\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects a multipart form containing a file.\naudiofileRequired\nThe audio file which holds the content and emotion that will control the generated speech.\nmodel_idstringOptionalDefaults to `eleven_english_sts_v2`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\nvoice_settingsstring or nullOptional\nVoice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nremove_background_noisebooleanOptionalDefaults to `false`\nIf set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\nfile_formatenum or nullOptionalDefaults to `other`\nThe format of input audio. Options are ‘pcm_s16le_16’ or ‘other’ For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\nAllowed values:pcm_s16le_16other\n### Response\nThe generated audio file\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Sip Trunk Outbound Call",
      "path": "sip-trunk-outbound-call",
      "url": "https://elevenlabs.io/docs/api-reference/sip-trunk/outbound-call",
      "keywords": [
        "call",
        "endpoint",
        "errors",
        "headers",
        "outbound",
        "request",
        "response",
        "sip",
        "trunk"
      ],
      "use_cases": [
        "How to sip trunk outbound call"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Handle an outbound call via SIP trunk\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nagent_idstringRequired\nagent_phone_number_idstringRequired\nto_numberstringRequired\nconversation_initiation_client_dataobject or nullOptional\nShow 5 properties\n### Response\nSuccessful Response\nsuccessboolean\nmessagestring\nconversation_idstring or null\nsip_call_idstring or null\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Service Accounts List",
      "path": "service-accounts-list",
      "url": "https://elevenlabs.io/docs/api-reference/service-accounts/list",
      "keywords": [
        "accounts",
        "errors",
        "headers",
        "list",
        "response",
        "service"
      ],
      "use_cases": [
        "How to service accounts list",
        "How to list service accounts list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "List all service accounts in the workspace\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nservice-accountslist of objects\nShow 4 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Speech To Speech Stream",
      "path": "speech-to-speech-stream",
      "url": "https://elevenlabs.io/docs/api-reference/speech-to-speech/stream",
      "keywords": [
        "eleven_english_sts_v2",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "mp3_44100_128",
        "other",
        "parameters",
        "path"
      ],
      "use_cases": [
        "How to speech to speech stream",
        "How to list speech to speech stream",
        "How to stream speech to speech stream"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "speech"
      ],
      "priority": 8,
      "content": "Stream audio from one voice to another. Maintain full control over emotion, timing and delivery.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. Use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\noptimize_streaming_latencyinteger or nullOptionalDeprecated\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\noutput_formatenumOptionalDefaults to `mp3_44100_128`\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects a multipart form containing a file.\naudiofileRequired\nThe audio file which holds the content and emotion that will control the generated speech.\nmodel_idstringOptionalDefaults to `eleven_english_sts_v2`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.\nvoice_settingsstring or nullOptional\nVoice settings overriding stored settings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nremove_background_noisebooleanOptionalDefaults to `false`\nIf set, will remove the background noise from your audio input using our audio isolation model. Only applies to Voice Changer.\nfile_formatenum or nullOptionalDefaults to `other`\nThe format of input audio. Options are ‘pcm_s16le_16’ or ‘other’ For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\nAllowed values:pcm_s16le_16other\n### Response\nStreaming audio data\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Api Information",
      "path": "studio-api-information",
      "url": "https://elevenlabs.io/docs/api-reference/studio-api-information",
      "keywords": [
        "api",
        "get",
        "information",
        "request",
        "studio"
      ],
      "use_cases": [
        "How to studio api information"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "The Studio API is only available upon request. To get access, [contact sales](https://elevenlabs.io/contact-sales).\n"
    },
    {
      "title": "Streaming",
      "path": "streaming",
      "url": "https://elevenlabs.io/docs/api-reference/streaming",
      "keywords": [
        "request",
        "streaming"
      ],
      "use_cases": [
        "How to streaming",
        "How to stream streaming"
      ],
      "tags": [
        "api-reference",
        "streaming"
      ],
      "priority": 8,
      "content": "The ElevenLabs API supports real-time audio streaming for select endpoints, returning raw audio bytes (e.g., MP3 data) directly over HTTP using chunked transfer encoding. This allows clients to process or play audio incrementally as it is generated.\nOur official [Node](https://github.com/elevenlabs/elevenlabs-js) and [Python](https://github.com/elevenlabs/elevenlabs-python) libraries include utilities to simplify handling this continuous audio stream.\nStreaming is supported for the [Text to Speech API](https://elevenlabs.io/docs/api-reference/text-to-speech/stream), [Voice Changer API](https://elevenlabs.io/docs/api-reference/speech-to-speech/stream) & [Audio Isolation API](https://elevenlabs.io/docs/api-reference/audio-isolation/stream). This section focuses on how streaming works for requests made to the Text to Speech API.\nIn Python, a streaming request looks like:\n```\n\n\n\n1\n| from elevenlabs import stream\n  \n---|---  \n\n\n2\n| from elevenlabs.client import ElevenLabs\n  \n\n\n3\n| \n  \n\n\n4\n| elevenlabs = ElevenLabs()\n  \n\n\n5\n| \n  \n\n\n6\n| audio_stream = elevenlabs.text_to_speech.stream(\n  \n\n\n7\n|     text=\"This is a test\",\n  \n\n\n8\n|     voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n  \n\n\n9\n|     model_id=\"eleven_multilingual_v2\"\n  \n\n\n10\n| )\n  \n\n\n11\n| \n  \n\n\n12\n| # option 1: play the streamed audio locally\n  \n\n\n13\n| stream(audio_stream)\n  \n\n\n14\n| \n  \n\n\n15\n| # option 2: process the audio bytes manually\n  \n\n\n16\n| for chunk in audio_stream:\n  \n\n\n17\n|     if isinstance(chunk, bytes):\n  \n\n\n18\n|         print(chunk)\n  \n\n\n\n```\n\nIn Node / Typescript, a streaming request looks like:\n```\n\n\n\n1\n| import { ElevenLabsClient, stream } from '@elevenlabs/elevenlabs-js';\n  \n---|---  \n\n\n2\n| import { Readable } from 'stream';\n  \n\n\n3\n| \n  \n\n\n4\n| const elevenlabs = new ElevenLabsClient();\n  \n\n\n5\n| \n  \n\n\n6\n| async function main() {\n  \n\n\n7\n|   const audioStream = await elevenlabs.textToSpeech.stream('JBFqnCBsd6RMkjVDRZzb', {\n  \n\n\n8\n|     text: 'This is a test',\n  \n\n\n9\n|     modelId: 'eleven_multilingual_v2',\n  \n\n\n10\n|   });\n  \n\n\n11\n| \n  \n\n\n12\n|   // option 1: play the streamed audio locally\n  \n\n\n13\n|   await stream(Readable.from(audioStream));\n  \n\n\n14\n| \n  \n\n\n15\n|   // option 2: process the audio manually\n  \n\n\n16\n|   for await (const chunk of audioStream) {\n  \n\n\n17\n|     console.log(chunk);\n  \n\n\n18\n|   }\n  \n\n\n19\n| }\n  \n\n\n20\n| \n  \n\n\n21\n| main();\n  \n\n\n\n```\n\n"
    },
    {
      "title": "Speech To Text V 1 Speech To Text Realtime",
      "path": "speech-to-text-v-1-speech-to-text-realtime",
      "url": "https://elevenlabs.io/docs/api-reference/speech-to-text/v-1-speech-to-text-realtime",
      "keywords": [
        "api-reference",
        "committed_transcript_with_timestamps",
        "docs",
        "elevenlabs",
        "endpoint",
        "event",
        "explorer",
        "false",
        "flow",
        "handshake"
      ],
      "use_cases": [
        "How to speech to text v 1 speech to text realtime",
        "How to create speech to text v 1 speech to text realtime",
        "How to stream speech to text v 1 speech to text realtime"
      ],
      "tags": [
        "api-reference",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Realtime speech-to-text transcription service. This WebSocket API enables streaming audio input and receiving transcription results.\n## Event Flow\n  * Audio chunks are sent as `input_audio_chunk` messages\n  * Transcription results are streamed back in various formats (partial, committed, with timestamps)\n  * Supports manual commit or VAD-based automatic commit strategies\n\n\nAuthentication is done either by providing a valid API key in the `xi-api-key` header or by providing a valid token in the `token` query parameter. Tokens can be generated from the [single use token endpoint](https://elevenlabs.io/docs/api-reference/tokens/create). Use tokens if you want to transcribe audio from the client side.\n## Handshake[](https://elevenlabs.io/docs/api-reference/speech-to-text/v-1-speech-to-text-realtime?explorer=true)\nWSS\nwss://api.elevenlabs.io/v1/speech-to-text/realtime\n### Headers\nxi-api-keystringRequired\n### Query parameters\nmodel_idstringRequired\nID of the model to use for transcription.\ntokenstringOptional\nSingle use token for authentication. Only used when initiating a session from the client. If provided, `xi-api-key` is no longer required for authentication.\ninclude_timestampsbooleanOptionalDefaults to `false`\nWhether to receive the `committed_transcript_with_timestamps` event, which includes word-level timestamps.\ninclude_language_detectionbooleanOptionalDefaults to `false`\nWhether to include the detected language code in the `committed_transcript_with_timestamps` event.\naudio_formatenumOptionalDefaults to `pcm_16000`\nAudio encoding format for speech-to-text.\nShow 7 enum values\nlanguage_codestringOptional\nLanguage code in ISO 639-1 or ISO 639-3 format.\ncommit_strategyenumOptionalDefaults to `manual`\nStrategy for committing transcriptions.\nAllowed values:manualvad\nvad_silence_threshold_secsdoubleOptional`0.3-3`Defaults to `1.5`\nSilence threshold in seconds for VAD.\nvad_thresholddoubleOptional`0.1-0.9`Defaults to `0.4`\nThreshold for voice activity detection.\nmin_speech_duration_msintegerOptional`50-2000`Defaults to `100`\nMinimum speech duration in milliseconds.\nmin_silence_duration_msintegerOptional`50-2000`Defaults to `100`\nMinimum silence duration in milliseconds.\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request. Zero retention mode may only be used by enterprise customers.\n### Send\ninputAudioChunkobjectRequired\nShow 5 properties\n### Receive\nsessionStartedobjectRequired\nShow 3 properties\nOR\npartialTranscriptobjectRequired\nShow 2 properties\nOR\ncommittedTranscriptobjectRequired\nShow 2 properties\nOR\ncommittedTranscriptWithTimestampsobjectRequired\nShow 4 properties\nOR\nscribeErrorobjectRequired\nShow 2 properties\nOR\nscribeAuthErrorobjectRequired\nShow 2 properties\nOR\nscribeQuotaExceededErrorobjectRequired\nShow 2 properties\nOR\nscribeThrottledErrorobjectRequired\nShow 2 properties\nOR\nscribeUnacceptedTermsErrorobjectRequired\nShow 2 properties\nOR\nscribeRateLimitedErrorobjectRequired\nShow 2 properties\nOR\nscribeQueueOverflowErrorobjectRequired\nShow 2 properties\nOR\nscribeResourceExhaustedErrorobjectRequired\nShow 2 properties\nOR\nscribeSessionTimeLimitExceededErrorobjectRequired\nShow 2 properties\nOR\nscribeInputErrorobjectRequired\nShow 2 properties\nOR\nscribeChunkSizeExceededErrorobjectRequired\nShow 2 properties\nOR\nscribeInsufficientAudioActivityErrorobjectRequired\nShow 2 properties\nOR\nscribeTranscriberErrorobjectRequired\nShow 2 properties\n"
    },
    {
      "title": "Speech To Text Delete",
      "path": "speech-to-text-delete",
      "url": "https://elevenlabs.io/docs/api-reference/speech-to-text/delete",
      "keywords": [
        "delete",
        "errors",
        "headers",
        "parameters",
        "path",
        "response",
        "speech",
        "text"
      ],
      "use_cases": [
        "How to speech to text delete",
        "How to delete speech to text delete"
      ],
      "tags": [
        "api-reference",
        "crud",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Delete a previously generated transcript by its ID.\n### Path parameters\ntranscription_idstringRequired\nThe unique ID of the transcript to delete\n### Headers\nxi-api-keystringRequired\n### Response\nDelete completed successfully.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Speech To Text Get",
      "path": "speech-to-text-get",
      "url": "https://elevenlabs.io/docs/api-reference/speech-to-text/get",
      "keywords": [
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "speech",
        "text"
      ],
      "use_cases": [
        "How to speech to text get"
      ],
      "tags": [
        "api-reference",
        "crud",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Retrieve a previously generated transcript by its ID.\n### Path parameters\ntranscription_idstringRequired\nThe unique ID of the transcript to retrieve\n### Headers\nxi-api-keystringRequired\n### Response\nThe transcript data\nSpeechToTextChunkResponseModelobject\nShow 8 properties\nOR\nMultichannelSpeechToTextResponseModelobject\nShow 2 properties\nOR\nSpeechToTextChunkResponseModelobject\nShow 8 properties\nOR\nMultichannelSpeechToTextResponseModelobject\nShow 2 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Add Project",
      "path": "studio-add-project",
      "url": "https://elevenlabs.io/docs/api-reference/studio/add-project",
      "keywords": [
        "add",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameter",
        "project",
        "query",
        "request"
      ],
      "use_cases": [
        "How to studio add project",
        "How to create studio add project",
        "How to list studio add project",
        "How to convert studio add project"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Creates a new Studio project, it can be either initialized as blank, from a document or from a URL.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing an optional file.\nnamestringRequired\nThe name of the Studio project, used for identification only.\ndefault_title_voice_idstring or nullOptional\nThe voice_id that corresponds to the default voice used for new titles.\ndefault_paragraph_voice_idstring or nullOptional\nThe voice_id that corresponds to the default voice used for new paragraphs.\ndefault_model_idstring or nullOptional\nThe ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\nfrom_urlstring or nullOptional\nAn optional URL from which we will extract content to initialize the Studio project. If this is set, ‘from_url’ and ‘from_content’ must be null. If neither ‘from_url’, ‘from_document’, ‘from_content’ are provided we will initialize the Studio project as blank.\nfrom_documentfileOptional\nAn optional .epub, .pdf, .txt or similar file can be provided. If provided, we will initialize the Studio project with its content. If this is set, ‘from_url’ and ‘from_content’ must be null. If neither ‘from_url’, ‘from_document’, ‘from_content’ are provided we will initialize the Studio project as blank.\nfrom_content_jsonstringOptional\nAn optional content to initialize the Studio project with. If this is set, ‘from_url’ and ‘from_document’ must be null. If neither ‘from_url’, ‘from_document’, ‘from_content’ are provided we will initialize the Studio project as blank.\nExample: [{“name”: “Chapter A”, “blocks”: [{“sub_type”: “p”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “A”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “B”, “type”: “tts_node”}]}, {“sub_type”: “h1”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “C”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “D”, “type”: “tts_node”}]}]}, {“name”: “Chapter B”, “blocks”: [{“sub_type”: “p”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “E”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “F”, “type”: “tts_node”}]}, {“sub_type”: “h2”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “G”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “H”, “type”: “tts_node”}]}]}]\nquality_presetstringOptionalDefaults to `standard`\nOutput quality of the generated audio. Must be one of: standard - standard output format, 128kbps with 44.1kHz sample rate. high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format.\ntitlestring or nullOptional\nAn optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\nauthorstring or nullOptional\nAn optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\ndescriptionstring or nullOptional\nAn optional description of the Studio project.\ngenreslist of stringsOptional\nAn optional list of genres associated with the Studio project.\ntarget_audienceenum or nullOptional\nAn optional target audience of the Studio project.\nAllowed values:childrenyoung adultadultall ages\nlanguagestring or nullOptional`=2 characters`\nAn optional language of the Studio project. Two-letter language code (ISO 639-1).\ncontent_typestring or nullOptional\nAn optional content type of the Studio project.\noriginal_publication_datestring or nullOptional`format: \"^\\d{4}-\\d{2}-\\d{2}$|^\\d{4}$\"`\nAn optional original publication date of the Studio project, in the format YYYY-MM-DD or YYYY.\nmature_contentboolean or nullOptionalDefaults to `false`\nAn optional specification of whether this Studio project contains mature content.\nisbn_numberstring or nullOptional\nAn optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\nacx_volume_normalizationbooleanOptionalDefaults to `false`\n[Deprecated] When the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\nvolume_normalizationbooleanOptionalDefaults to `false`\nWhen the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\npronunciation_dictionary_locatorslist of stringsOptional\nA list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple —form lines in your curl, such as —form ‘pronunciation_dictionary_locators=”{“pronunciation_dictionary_id”:“Vmd4Zor6fplcA7WrINey”,“version_id”:“hRPaxjlTdR7wFMhV4w0b”}”’ —form ‘pronunciation_dictionary_locators=”{“pronunciation_dictionary_id”:“JzWtcGQMJ6bnlWwyMo7e”,“version_id”:“lbmwxiLu4q6txYxgdZqn”}”’.\ncallback_urlstring or nullOptional\nA url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion Messages:\n  1. When project was converted successfully: { type: “project_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, conversion_status: “success”, project_snapshot_id: “22m00Tcm4TlvDq8ikMAT”, error_details: None, } }\n  2. When project conversion failed: { type: “project_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, conversion_status: “error”, project_snapshot_id: None, error_details: “Error details if conversion failed” } }\n  3. When chapter was converted successfully: { type: “chapter_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, chapter_id: “22m00Tcm4TlvDq8ikMAT”, conversion_status: “success”, chapter_snapshot_id: “23m00Tcm4TlvDq8ikMAV”, error_details: None, } }\n  4. When chapter conversion failed: { type: “chapter_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, chapter_id: “22m00Tcm4TlvDq8ikMAT”, conversion_status: “error”, chapter_snapshot_id: None, error_details: “Error details if conversion failed” } }\n\n\nfictionenum or nullOptional\nAn optional specification of whether the content of this Studio project is fiction.\nAllowed values:fictionnon-fiction\napply_text_normalizationenum or nullOptional\nThis parameter controls text normalization with four modes: ‘auto’, ‘on’, ‘apply_english’ and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. ‘apply_english’ is the same as ‘on’ but will assume that text is in English.\nAllowed values:autoonoffapply_english\nauto_convertbooleanOptionalDefaults to `false`\nWhether to auto convert the Studio project to audio or not.\nauto_assign_voicesboolean or nullOptionalDefaults to `false`\n[Alpha Feature] Whether automatically assign voices to phrases in the create Project.\nsource_typeenum or nullOptional\nThe type of Studio project to create.\nShow 6 enum values\nvoice_settingslist of stringsOptional\nOptional voice settings overrides for the project, encoded as a list of JSON strings.\nExample: [”{“voice_id”: “21m00Tcm4TlvDq8ikWAM”, “stability”: 0.7, “similarity_boost”: 0.8, “style”: 0.5, “speed”: 1.0, “use_speaker_boost”: true}”]\n### Response\nSuccessful Response\nprojectobject\nShow 33 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Archive Snapshot",
      "path": "studio-archive-snapshot",
      "url": "https://elevenlabs.io/docs/api-reference/studio/archive-snapshot",
      "keywords": [
        "archive",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "snapshot",
        "studio"
      ],
      "use_cases": [
        "How to studio archive snapshot",
        "How to list studio archive snapshot",
        "How to stream studio archive snapshot"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Returns a compressed archive of the Studio project's audio.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nproject_snapshot_idstringRequired\nThe ID of the Studio project snapshot.\n### Headers\nxi-api-keystringRequired\n### Response\nStreaming archive data\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Add Chapter",
      "path": "studio-add-chapter",
      "url": "https://elevenlabs.io/docs/api-reference/studio/add-chapter",
      "keywords": [
        "add",
        "chapter",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "studio"
      ],
      "use_cases": [
        "How to studio add chapter",
        "How to create studio add chapter"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Creates a new chapter either as blank or from a URL.\n### Path parameters\nproject_idstringRequired\nThe ID of the Studio project.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnamestringRequired\nThe name of the chapter, used for identification only.\nfrom_urlstring or nullOptional\nAn optional URL from which we will extract content to initialize the Studio project. If this is set, ‘from_url’ and ‘from_content’ must be null. If neither ‘from_url’, ‘from_document’, ‘from_content’ are provided we will initialize the Studio project as blank.\n### Response\nSuccessful Response\nchapterobject\nShow 11 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Speech To Text Convert",
      "path": "speech-to-text-convert",
      "url": "https://elevenlabs.io/docs/api-reference/speech-to-text/convert",
      "keywords": [
        "convert",
        "endpoint",
        "errors",
        "false",
        "headers",
        "other",
        "parameter",
        "parameters",
        "pcm_s16le_16",
        "query"
      ],
      "use_cases": [
        "How to speech to text convert",
        "How to list speech to text convert"
      ],
      "tags": [
        "api-reference",
        "conversion",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Transcribe an audio or video file. If webhook is set to true, the request will be processed asynchronously and results sent to configured webhooks. When use_multi_channel is true and the provided audio has multiple channels, a ‘transcripts’ object with separate transcripts for each channel is returned. Otherwise, returns a single transcript. The optional webhook_metadata parameter allows you to attach custom data that will be included in webhook responses for request correlation and tracking.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean log and transcript storage features are unavailable for this request. Zero retention mode may only be used by enterprise customers.\n### Request\nThis endpoint expects a multipart form containing an optional file.\nmodel_idstringRequired\nThe ID of the model to use for transcription, currently only ‘scribe_v1’ and ‘scribe_v1_experimental’ are available.\nfilefileOptional\nThe file to transcribe. All major audio and video formats are supported. Exactly one of the file or cloud_storage_url parameters must be provided. The file size must be less than 3.0GB.\nlanguage_codestring or nullOptional\nAn ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file. Can sometimes improve transcription performance if known beforehand. Defaults to null, in this case the language is predicted automatically.\ntag_audio_eventsbooleanOptionalDefaults to `true`\nWhether to tag audio events like (laughter), (footsteps), etc. in the transcription.\nnum_speakersinteger or nullOptional`1-32`\nThe maximum amount of speakers talking in the uploaded file. Can help with predicting who speaks when. The maximum amount of speakers that can be predicted is 32. Defaults to null, in this case the amount of speakers is set to the maximum value the model supports.\ntimestamps_granularityenumOptionalDefaults to `word`\nThe granularity of the timestamps in the transcription. ‘word’ provides word-level timestamps and ‘character’ provides character-level timestamps per word.\nAllowed values:nonewordcharacter\ndiarizebooleanOptionalDefaults to `false`\nWhether to annotate which speaker is currently talking in the uploaded file.\ndiarization_thresholddouble or nullOptional`0.1-0.4`\nDiarization threshold to apply during speaker diarization. A higher value means there will be a lower chance of one speaker being diarized as two different speakers but also a higher chance of two different speakers being diarized as one speaker (less total speakers predicted). A low value means there will be a higher chance of one speaker being diarized as two different speakers but also a lower chance of two different speakers being diarized as one speaker (more total speakers predicted). Can only be set when diarize=True and num_speakers=None. Defaults to None, in which case we will choose a threshold based on the model_id (0.22 usually).\nadditional_formatslist of objectsOptional\nA list of additional formats to export the transcript to.\nShow 6 variants\nfile_formatenumOptionalDefaults to `other`\nThe format of input audio. Options are ‘pcm_s16le_16’ or ‘other’ For `pcm_s16le_16`, the input audio must be 16-bit PCM at a 16kHz sample rate, single channel (mono), and little-endian byte order. Latency will be lower than with passing an encoded waveform.\nAllowed values:pcm_s16le_16other\ncloud_storage_urlstring or nullOptional\nThe HTTPS URL of the file to transcribe. Exactly one of the file or cloud_storage_url parameters must be provided. The file must be accessible via HTTPS and the file size must be less than 2GB. Any valid HTTPS URL is accepted, including URLs from cloud storage providers (AWS S3, Google Cloud Storage, Cloudflare R2, etc.), CDNs, or any other HTTPS source. URLs can be pre-signed or include authentication tokens in query parameters.\nwebhookbooleanOptionalDefaults to `false`\nWhether to send the transcription result to configured speech-to-text webhooks. If set the request will return early without the transcription, which will be delivered later via webhook.\nwebhook_idstring or nullOptional\nOptional specific webhook ID to send the transcription result to. Only valid when webhook is set to true. If not provided, transcription will be sent to all configured speech-to-text webhooks.\ntemperaturedouble or nullOptional`0-2`\nControls the randomness of the transcription output. Accepts values between 0.0 and 2.0, where higher values result in more diverse and less deterministic results. If omitted, we will use a temperature based on the model you selected which is usually 0.\nseedinteger or nullOptional`0-2147483647`\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be an integer between 0 and 2147483647.\nuse_multi_channelbooleanOptionalDefaults to `false`\nWhether the audio file contains multiple channels where each channel contains a single speaker. When enabled, each channel will be transcribed independently and the results will be combined. Each word in the response will include a ‘channel_index’ field indicating which channel it was spoken on. A maximum of 5 channels is supported.\nwebhook_metadatastring or map from strings to any or nullOptional\nOptional metadata to be included in the webhook response. This should be a JSON string representing an object with a maximum depth of 2 levels and maximum size of 16KB. Useful for tracking internal IDs, job references, or other contextual information.\nShow 2 variants\nentity_detectionstring or list of strings or nullOptional\nDetect entities in the transcript. Can be ‘all’ to detect all entities, a single entity type or category string, or a list of entity types/categories. Categories include ‘pii’, ‘phi’, ‘pci’, ‘other’, ‘offensive_language’. When enabled, detected entities will be returned in the ‘entities’ field with their text, type, and character positions.\nShow 2 variants\nkeytermslist of stringsOptional\nA list of keyterms to bias the transcription towards. The keyterms are words or phrases you want the model to recognise more accurately. The number of keyterms cannot exceed 100. The length of each keyterm must be less than 50 characters. Keyterms can contain at most 5 words (after normalisation). For example [“hello”, “world”, “technical term”]\n### Response\n200\nSynchronous transcription result\nSpeechToTextChunkResponseModelobject\nShow 8 properties\nOR\nMultichannelSpeechToTextResponseModelobject\nShow 2 properties\nOR\nSpeechToTextWebhookResponseModelobject\nShow 3 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Convert Chapter",
      "path": "studio-convert-chapter",
      "url": "https://elevenlabs.io/docs/api-reference/studio/convert-chapter",
      "keywords": [
        "chapter",
        "convert",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to studio convert chapter",
        "How to list studio convert chapter"
      ],
      "tags": [
        "api-reference",
        "conversion"
      ],
      "priority": 6,
      "content": "Starts conversion of a specific chapter.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nchapter_idstringRequired\nThe ID of the chapter to be used. You can use the [List project chapters](https://elevenlabs.io/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the studio chapter conversion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Chapter Snapshot",
      "path": "studio-get-chapter-snapshot",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-chapter-snapshot",
      "keywords": [
        "chapter",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "snapshot",
        "studio"
      ],
      "use_cases": [
        "How to studio get chapter snapshot",
        "How to create studio get chapter snapshot",
        "How to list studio get chapter snapshot"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns the chapter snapshot.\n### Path parameters\nproject_idstringRequired\nThe ID of the Studio project.\nchapter_idstringRequired\nThe ID of the chapter.\nchapter_snapshot_idstringRequired\nThe ID of the chapter snapshot.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nchapter_snapshot_idstring\nThe ID of the chapter snapshot.\nproject_idstring\nThe ID of the project.\nchapter_idstring\nThe ID of the chapter.\ncreated_at_unixinteger\nThe creation date of the chapter snapshot.\nnamestring\nThe name of the chapter snapshot.\ncharacter_alignmentslist of objects\nShow 3 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Delete Project",
      "path": "studio-delete-project",
      "url": "https://elevenlabs.io/docs/api-reference/studio/delete-project",
      "keywords": [
        "delete",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "project",
        "request",
        "response"
      ],
      "use_cases": [
        "How to studio delete project",
        "How to delete studio delete project",
        "How to list studio delete project"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Deletes a Studio project.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the studio project deletion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Convert Project",
      "path": "studio-convert-project",
      "url": "https://elevenlabs.io/docs/api-reference/studio/convert-project",
      "keywords": [
        "convert",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "project",
        "request",
        "response"
      ],
      "use_cases": [
        "How to studio convert project",
        "How to list studio convert project"
      ],
      "tags": [
        "api-reference",
        "conversion"
      ],
      "priority": 6,
      "content": "Starts conversion of a Studio project and all of its chapters.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the studio project conversion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Delete Chapter",
      "path": "studio-delete-chapter",
      "url": "https://elevenlabs.io/docs/api-reference/studio/delete-chapter",
      "keywords": [
        "chapter",
        "delete",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to studio delete chapter",
        "How to delete studio delete chapter",
        "How to list studio delete chapter"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Deletes a chapter.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nchapter_idstringRequired\nThe ID of the chapter to be used. You can use the [List project chapters](https://elevenlabs.io/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the studio chapter deletion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Edit Project",
      "path": "studio-edit-project",
      "url": "https://elevenlabs.io/docs/api-reference/studio/edit-project",
      "keywords": [
        "edit",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "project",
        "request"
      ],
      "use_cases": [
        "How to studio edit project",
        "How to create studio edit project",
        "How to list studio edit project",
        "How to update studio edit project"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 6,
      "content": "Updates the specified Studio project by setting the values of the parameters passed.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnamestringRequired\nThe name of the Studio project, used for identification only.\ndefault_title_voice_idstringRequired\nThe voice_id that corresponds to the default voice used for new titles.\ndefault_paragraph_voice_idstringRequired\nThe voice_id that corresponds to the default voice used for new paragraphs.\ntitlestring or nullOptional\nAn optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\nauthorstring or nullOptional\nAn optional name of the author of the Studio project, this will be added as metadata to the mp3 file on Studio project or chapter download.\nisbn_numberstring or nullOptional\nAn optional ISBN number of the Studio project you want to create, this will be added as metadata to the mp3 file on Studio project or chapter download.\nvolume_normalizationbooleanOptionalDefaults to `false`\nWhen the Studio project is downloaded, should the returned audio have postprocessing in order to make it compliant with audiobook normalized volume requirements\n### Response\nSuccessful Response\nprojectobject\nShow 33 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Chapter Snapshots",
      "path": "studio-get-chapter-snapshots",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-chapter-snapshots",
      "keywords": [
        "chapter",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "snapshots",
        "studio"
      ],
      "use_cases": [
        "How to studio get chapter snapshots",
        "How to create studio get chapter snapshots",
        "How to list studio get chapter snapshots",
        "How to convert studio get chapter snapshots"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Gets information about all the snapshots of a chapter. Each snapshot can be downloaded as audio. Whenever a chapter is converted a snapshot will automatically be created.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nchapter_idstringRequired\nThe ID of the chapter to be used. You can use the [List project chapters](https://elevenlabs.io/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nsnapshotslist of objects\nList of chapter snapshots.\nShow 5 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Chapter",
      "path": "studio-get-chapter",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-chapter",
      "keywords": [
        "chapter",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "studio"
      ],
      "use_cases": [
        "How to studio get chapter",
        "How to list studio get chapter",
        "How to convert studio get chapter"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns information about a specific chapter.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nchapter_idstringRequired\nThe ID of the chapter to be used. You can use the [List project chapters](https://elevenlabs.io/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nchapter_idstring\nThe ID of the chapter.\nnamestring\nThe name of the chapter.\ncan_be_downloadedboolean\nWhether the chapter can be downloaded.\nstateenum\nThe state of the chapter.\nAllowed values:defaultconverting\ncontentobject\nShow 1 properties\nlast_conversion_date_unixinteger or null\nThe last conversion date of the chapter.\nconversion_progressdouble or null\nThe conversion progress of the chapter.\nhas_videoboolean or null\nWhether the chapter has a video.\nvoice_idslist of strings or null\nList of voice ids used by the chapter\nstatisticsobject or null\nThe statistics of the chapter.\nShow 4 properties\nlast_conversion_errorstring or null\nThe last conversion error of the chapter.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Create Pronunciation Dictionaries",
      "path": "studio-create-pronunciation-dictionaries",
      "url": "https://elevenlabs.io/docs/api-reference/studio/create-pronunciation-dictionaries",
      "keywords": [
        "create",
        "dictionaries",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "pronunciation",
        "request"
      ],
      "use_cases": [
        "How to studio create pronunciation dictionaries",
        "How to create studio create pronunciation dictionaries",
        "How to list studio create pronunciation dictionaries",
        "How to convert studio create pronunciation dictionaries"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Create a set of pronunciation dictionaries acting on a project. This will automatically mark text within this project as requiring reconverting where the new dictionary would apply or the old one no longer does.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\npronunciation_dictionary_locatorslist of objectsRequired\nA list of pronunciation dictionary locators (pronunciation_dictionary_id, version_id) encoded as a list of JSON strings for pronunciation dictionaries to be applied to the text. A list of json encoded strings is required as adding projects may occur through formData as opposed to jsonBody. To specify multiple dictionaries use multiple —form lines in your curl, such as —form ‘pronunciation_dictionary_locators=”{“pronunciation_dictionary_id”:“Vmd4Zor6fplcA7WrINey”,“version_id”:“hRPaxjlTdR7wFMhV4w0b”}”’ —form ‘pronunciation_dictionary_locators=”{“pronunciation_dictionary_id”:“JzWtcGQMJ6bnlWwyMo7e”,“version_id”:“lbmwxiLu4q6txYxgdZqn”}”’.\nShow 2 properties\ninvalidate_affected_textbooleanOptionalDefaults to `true`\nThis will automatically mark text in this project for reconversion when the new dictionary applies or the old one no longer does.\n### Response\nSuccessful Response\nstatusstring\nThe status of the create pronunciation dictionary request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Create Podcast",
      "path": "studio-create-podcast",
      "url": "https://elevenlabs.io/docs/api-reference/studio/create-podcast",
      "keywords": [
        "create",
        "default",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameter",
        "podcast",
        "query",
        "request"
      ],
      "use_cases": [
        "How to studio create podcast",
        "How to create studio create podcast",
        "How to list studio create podcast",
        "How to convert studio create podcast"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Create and auto-convert a podcast project. Currently, the LLM cost is covered by us but you will still be charged for the audio generation. In the future, you will be charged for both the LLM and audio generation costs.\n### Headers\nxi-api-keystringRequired\nsafety-identifierstring or nullOptional\nUsed for moderation. Your workspace must be allowlisted to use this feature.\n### Request\nThis endpoint expects an object.\nmodel_idstringRequired\nThe ID of the model to be used for this Studio project, you can query GET /v1/models to list all available models.\nmodeobjectRequired\nThe type of podcast to generate. Can be 'conversation', an interaction between two voices, or 'bulletin', a monologue.\nShow 2 variants\nsourceobject or list of objectsRequired\nThe source content for the Podcast.\nShow 3 variants\nquality_presetenumOptionalDefaults to `standard`\nOutput quality of the generated audio. Must be one of: standard - standard output format, 128kbps with 44.1kHz sample rate. high - high quality output format, 192kbps with 44.1kHz sample rate and major improvements on our side. ultra - ultra quality output format, 192kbps with 44.1kHz sample rate and highest improvements on our side. ultra lossless - ultra quality output format, 705.6kbps with 44.1kHz sample rate and highest improvements on our side in a fully lossless format.\nAllowed values:standardhighhighestultraultra_lossless\nduration_scaleenumOptionalDefaults to `default`\nDuration of the generated podcast. Must be one of: short - produces podcasts shorter than 3 minutes. default - produces podcasts roughly between 3-7 minutes. long - produces podcasts longer than 7 minutes.\nAllowed values:shortdefaultlong\nlanguagestring or nullOptional`=2 characters`\nAn optional language of the Studio project. Two-letter language code (ISO 639-1).\nintrostring or nullOptional`<=1500 characters`\nThe intro text that will always be added to the beginning of the podcast.\noutrostring or nullOptional`<=1500 characters`\nThe outro text that will always be added to the end of the podcast.\ninstructions_promptstring or nullOptional`<=3000 characters`\nAdditional instructions prompt for the podcast generation used to adjust the podcast's style and tone.\nhighlightslist of strings or nullOptional\nA brief summary or highlights of the Studio project's content, providing key points or themes. This should be between 10 and 70 characters.\ncallback_urlstring or nullOptional\nA url that will be called by our service when the Studio project is converted. Request will contain a json blob containing the status of the conversion Messages:\n  1. When project was converted successfully: { type: “project_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, conversion_status: “success”, project_snapshot_id: “22m00Tcm4TlvDq8ikMAT”, error_details: None, } }\n  2. When project conversion failed: { type: “project_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, conversion_status: “error”, project_snapshot_id: None, error_details: “Error details if conversion failed” } }\n  3. When chapter was converted successfully: { type: “chapter_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, chapter_id: “22m00Tcm4TlvDq8ikMAT”, conversion_status: “success”, chapter_snapshot_id: “23m00Tcm4TlvDq8ikMAV”, error_details: None, } }\n  4. When chapter conversion failed: { type: “chapter_conversion_status”, event_timestamp: 1234567890, data: { request_id: “1234567890”, project_id: “21m00Tcm4TlvDq8ikWAM”, chapter_id: “22m00Tcm4TlvDq8ikMAT”, conversion_status: “error”, chapter_snapshot_id: None, error_details: “Error details if conversion failed” } }\n\n\napply_text_normalizationenum or nullOptional\nThis parameter controls text normalization with four modes: ‘auto’, ‘on’, ‘apply_english’ and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. ‘apply_english’ is the same as ‘on’ but will assume that text is in English.\nAllowed values:autoonoffapply_english\n### Response\nSuccessful Response\nprojectobject\nThe project associated with the created podcast.\nShow 33 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Chapters",
      "path": "studio-get-chapters",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-chapters",
      "keywords": [
        "chapters",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "studio"
      ],
      "use_cases": [
        "How to studio get chapters",
        "How to list studio get chapters"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns a list of a Studio project's chapters.\n### Path parameters\nproject_idstringRequired\nThe ID of the Studio project.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nchapterslist of objects\nShow 10 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Projects",
      "path": "studio-get-projects",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-projects",
      "keywords": [
        "errors",
        "get",
        "headers",
        "projects",
        "response",
        "studio"
      ],
      "use_cases": [
        "How to studio get projects",
        "How to list studio get projects"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns a list of your Studio projects with metadata.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nprojectslist of objects\nA list of projects with their metadata.\nShow 33 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Stream Chapter Snapshot",
      "path": "studio-stream-chapter-snapshot",
      "url": "https://elevenlabs.io/docs/api-reference/studio/stream-chapter-snapshot",
      "keywords": [
        "chapter",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to studio stream chapter snapshot",
        "How to list studio stream chapter snapshot",
        "How to stream studio stream chapter snapshot",
        "How to convert studio stream chapter snapshot"
      ],
      "tags": [
        "api-reference",
        "streaming"
      ],
      "priority": 6,
      "content": "Stream the audio from a chapter snapshot. Use `GET /v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots` to return the snapshots of a chapter.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nchapter_idstringRequired\nThe ID of the chapter to be used. You can use the [List project chapters](https://elevenlabs.io/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\nchapter_snapshot_idstringRequired\nThe ID of the chapter snapshot to be used. You can use the [List project chapter snapshots](https://elevenlabs.io/docs/api-reference/studio/get-snapshots) endpoint to list all the available snapshots.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nconvert_to_mpegbooleanOptionalDefaults to `false`\nWhether to convert the audio to mpeg format.\n### Response\nStreaming audio data\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Snapshots",
      "path": "studio-get-snapshots",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-snapshots",
      "keywords": [
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "snapshots",
        "studio"
      ],
      "use_cases": [
        "How to studio get snapshots",
        "How to list studio get snapshots"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Retrieves a list of snapshots for a Studio project.\n### Path parameters\nproject_idstringRequired\nThe ID of the Studio project.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nsnapshotslist of objects\nList of project snapshots.\nShow 6 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Update Chapter",
      "path": "studio-update-chapter",
      "url": "https://elevenlabs.io/docs/api-reference/studio/update-chapter",
      "keywords": [
        "chapter",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "studio"
      ],
      "use_cases": [
        "How to studio update chapter",
        "How to list studio update chapter",
        "How to update studio update chapter"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Updates a chapter.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nchapter_idstringRequired\nThe ID of the chapter to be used. You can use the [List project chapters](https://elevenlabs.io/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnamestring or nullOptional\nThe name of the chapter, used for identification only.\ncontentobject or nullOptional\nThe chapter content to use.\nShow 1 properties\n### Response\nSuccessful Response\nchapterobject\nShow 11 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Stream Snapshot",
      "path": "studio-stream-snapshot",
      "url": "https://elevenlabs.io/docs/api-reference/studio/stream-snapshot",
      "keywords": [
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "snapshot"
      ],
      "use_cases": [
        "How to studio stream snapshot",
        "How to list studio stream snapshot",
        "How to stream studio stream snapshot",
        "How to convert studio stream snapshot"
      ],
      "tags": [
        "api-reference",
        "streaming"
      ],
      "priority": 6,
      "content": "Stream the audio from a Studio project snapshot.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\nproject_snapshot_idstringRequired\nThe ID of the Studio project snapshot.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nconvert_to_mpegbooleanOptionalDefaults to `false`\nWhether to convert the audio to mpeg format.\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Update Content",
      "path": "studio-update-content",
      "url": "https://elevenlabs.io/docs/api-reference/studio/update-content",
      "keywords": [
        "content",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to studio update content",
        "How to list studio update content",
        "How to update studio update content",
        "How to convert studio update content"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Updates Studio project content.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing an optional file.\nfrom_urlstring or nullOptional\nAn optional URL from which we will extract content to initialize the Studio project. If this is set, ‘from_url’ and ‘from_content’ must be null. If neither ‘from_url’, ‘from_document’, ‘from_content’ are provided we will initialize the Studio project as blank.\nfrom_documentfileOptional\nAn optional .epub, .pdf, .txt or similar file can be provided. If provided, we will initialize the Studio project with its content. If this is set, ‘from_url’ and ‘from_content’ must be null. If neither ‘from_url’, ‘from_document’, ‘from_content’ are provided we will initialize the Studio project as blank.\nfrom_content_jsonstringOptional\nAn optional content to initialize the Studio project with. If this is set, ‘from_url’ and ‘from_document’ must be null. If neither ‘from_url’, ‘from_document’, ‘from_content’ are provided we will initialize the Studio project as blank.\nExample: [{“name”: “Chapter A”, “blocks”: [{“sub_type”: “p”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “A”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “B”, “type”: “tts_node”}]}, {“sub_type”: “h1”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “C”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “D”, “type”: “tts_node”}]}]}, {“name”: “Chapter B”, “blocks”: [{“sub_type”: “p”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “E”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “F”, “type”: “tts_node”}]}, {“sub_type”: “h2”, “nodes”: [{“voice_id”: “6lCwbsX1yVjD49QmpkT0”, “text”: “G”, “type”: “tts_node”}, {“voice_id”: “6lCwbsX1yVjD49QmpkT1”, “text”: “H”, “type”: “tts_node”}]}]}]\nauto_convertbooleanOptionalDefaults to `false`\nWhether to auto convert the Studio project to audio or not.\n### Response\nSuccessful Response\nprojectobject\nShow 33 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Project",
      "path": "studio-get-project",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-project",
      "keywords": [
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "project",
        "query",
        "response",
        "studio"
      ],
      "use_cases": [
        "How to studio get project",
        "How to create studio get project",
        "How to list studio get project",
        "How to convert studio get project"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns information about a specific Studio project. This endpoint returns more detailed information about a project than `GET /v1/studio`.\n### Path parameters\nproject_idstringRequired\nThe ID of the project to be used. You can use the [List projects](https://elevenlabs.io/docs/api-reference/studio/get-projects) endpoint to list all the available projects.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nshare_idstring or nullOptional\nThe share ID of the project\n### Response\nSuccessful Response\nproject_idstring\nThe ID of the project.\nnamestring\nThe name of the project.\ncreate_date_unixinteger\nThe creation date of the project.\ncreated_by_user_idstring or null\nThe user ID who created the project.\ndefault_title_voice_idstring\nThe default title voice ID.\ndefault_paragraph_voice_idstring\nThe default paragraph voice ID.\ndefault_model_idstring\nThe default model ID.\ncan_be_downloadedboolean\nWhether the project can be downloaded.\nvolume_normalizationboolean\nWhether the project uses volume normalization.\nstateenum\nThe state of the project.\nAllowed values:creatingdefaultconvertingin_queue\naccess_levelenum\nThe access level of the project.\nAllowed values:admineditorcommenterviewer\nquality_presetenum\nThe quality preset level of the project.\nAllowed values:standardhighhighestultraultra_lossless\nchapterslist of objects\nList of chapters of the project and their metadata.\nShow 10 properties\npronunciation_dictionary_versionslist of objects\nList of pronunciation dictionary versions of the project and their metadata.\nShow 9 properties\npronunciation_dictionary_locatorslist of objects\nList of pronunciation dictionary locators.\nShow 2 properties\napply_text_normalizationenum\nWhether text normalization is applied to the project.\nAllowed values:autoonoffapply_english\nassetslist of objects\nList of uploaded assets e.g. videos, audios.\nShow 3 variants\nvoiceslist of objects\nList of configured project voices.\nShow 9 properties\nquality_check_onbooleanDeprecated\nWhether quality check is enabled for this project.\nquality_check_on_when_bulk_convertbooleanDeprecated\nWhether quality check is enabled on the project when bulk converting.\nlast_conversion_date_unixinteger or null\nThe last conversion date of the project.\ntitlestring or null\nThe title of the project.\nauthorstring or null\nThe author of the project.\ndescriptionstring or null\nThe description of the project.\ngenreslist of strings or null\nList of genres of the project.\ncover_image_urlstring or null\nThe cover image URL of the project.\ntarget_audienceenum or null\nThe target audience of the project.\nAllowed values:childrenyoung adultadultall ages\nlanguagestring or null\nTwo-letter language code (ISO 639-1) of the language of the project.\ncontent_typestring or null\nThe content type of the project, e.g. 'Novel' or 'Short Story'\noriginal_publication_datestring or null\nThe original publication date of the project.\nmature_contentboolean or null\nWhether the project contains mature content.\nisbn_numberstring or null\nThe ISBN number of the project.\nfictionenum or null\nWhether the project is fiction.\nAllowed values:fictionnon-fiction\ncreation_metaobject or null\nThe creation meta of the project.\nShow 3 properties\nsource_typeenum or null\nThe source type of the project.\nShow 6 enum values\nchapters_enabledboolean or nullDefaults to `true`\nWhether chapters are enabled for the project.\ncaptions_enabledboolean or nullDefaults to `true`\nWhether captions are enabled for the project.\ncaption_styleobject or null\nGlobal styling to be applied to all captions\nShow 23 properties\npublic_share_idstring or null\nThe public share ID of the project.\naspect_ratioenum or null\nThe aspect ratio of the project.\nAllowed values:16:99:164:51:1\nexperimentalobject or null\nExperimental features for the project.\nbase_voiceslist of objects or null\nList of voices used by the project.\nShow 22 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Studio Get Project Snapshot",
      "path": "studio-get-project-snapshot",
      "url": "https://elevenlabs.io/docs/api-reference/studio/get-project-snapshot",
      "keywords": [
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "project",
        "response",
        "snapshot",
        "studio"
      ],
      "use_cases": [
        "How to studio get project snapshot",
        "How to create studio get project snapshot",
        "How to list studio get project snapshot"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 6,
      "content": "Returns the project snapshot.\n### Path parameters\nproject_idstringRequired\nThe ID of the Studio project.\nproject_snapshot_idstringRequired\nThe ID of the Studio project snapshot.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nproject_snapshot_idstring\nThe ID of the project snapshot.\nproject_idstring\nThe ID of the project.\ncreated_at_unixinteger\nThe creation date of the project snapshot.\nnamestring\nThe name of the project snapshot.\ncharacter_alignmentslist of objects\nShow 3 properties\naudio_duration_secsdouble\nThe total duration of the audio in seconds.\naudio_uploadobject or null\n(Deprecated)\nzip_uploadobject or null\n(Deprecated)\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Dialogue Convert",
      "path": "text-to-dialogue-convert",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-dialogue/convert",
      "keywords": [
        "auto",
        "convert",
        "dialogue",
        "eleven_v3",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameter",
        "parameters"
      ],
      "use_cases": [
        "How to text to dialogue convert",
        "How to list text to dialogue convert",
        "How to convert text to dialogue convert"
      ],
      "tags": [
        "api-reference",
        "conversion",
        "text"
      ],
      "priority": 5,
      "content": "Converts a list of text and voice ID pairs into speech (dialogue) and returns audio.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ninputslist of objectsRequired\nA list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\nShow 2 properties\nmodel_idstringOptionalDefaults to `eleven_v3`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nsettingsobject or nullOptional\nSettings controlling the dialogue generation.\nShow 1 properties\npronunciation_dictionary_locatorslist of objects or nullOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\n### Response\nThe generated audio file\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Dialogue Convert With Timestamps",
      "path": "text-to-dialogue-convert-with-timestamps",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-dialogue/convert-with-timestamps",
      "keywords": [
        "auto",
        "convert",
        "dialogue",
        "eleven_v3",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameter",
        "parameters"
      ],
      "use_cases": [
        "How to text to dialogue convert with timestamps",
        "How to list text to dialogue convert with timestamps",
        "How to convert text to dialogue convert with timestamps"
      ],
      "tags": [
        "api-reference",
        "conversion",
        "text"
      ],
      "priority": 5,
      "content": "Generate dialogue from text with precise character-level timing information for audio-text synchronization.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ninputslist of objectsRequired\nA list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\nShow 2 properties\nmodel_idstringOptionalDefaults to `eleven_v3`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nsettingsobject or nullOptional\nSettings controlling the dialogue generation.\nShow 1 properties\npronunciation_dictionary_locatorslist of objects or nullOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\n### Response\nSuccessful Response\naudio_base64string\nBase64 encoded audio data\nvoice_segmentslist of objects\nVoice segments for the audio\nShow 6 properties\nalignmentobject or null\nTimestamp information for each character in the original text\nShow 3 properties\nnormalized_alignmentobject or null\nTimestamp information for each character in the normalized text\nShow 3 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Speech V 1 Text To Speech Voice Id Multi Stream Input",
      "path": "text-to-speech-v-1-text-to-speech-voice-id-multi-stream-input",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/v-1-text-to-speech-voice-id-multi-stream-input",
      "keywords": [
        "api-reference",
        "auto",
        "close_socket",
        "docs",
        "elevenlabs",
        "explorer",
        "false",
        "handshake",
        "headers",
        "https"
      ],
      "use_cases": [
        "How to text to speech v 1 text to speech voice id multi stream input",
        "How to create text to speech v 1 text to speech voice id multi stream input",
        "How to stream text to speech v 1 text to speech voice id multi stream input"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "voices",
        "speech"
      ],
      "priority": 8,
      "content": "The Multi-Context Text-to-Speech WebSockets API allows for generating audio from text input while managing multiple independent audio generation streams (contexts) over a single WebSocket connection. This is useful for scenarios requiring concurrent or interleaved audio generations, such as dynamic conversational AI applications.\nEach context, identified by a context id, maintains its own state. You can send text to specific contexts, flush them, or close them independently. A `close_socket` message can be used to terminate the entire connection gracefully.\nFor more information on best practices for how to use this API, please see the [multi context websocket guide](https://elevenlabs.io/docs/developers/guides/cookbooks/multi-context-web-socket).\n## Handshake[](https://elevenlabs.io/docs/api-reference/text-to-speech/v-1-text-to-speech-voice-id-multi-stream-input?explorer=true)\nWSS\nwss://api.elevenlabs.io/v1/text-to-speech/:voice_id/multi-stream-input\n### Headers\nxi-api-keystringRequired\n### Path parameters\nvoice_idstringRequired\nThe unique identifier for the voice to use in the TTS process.\n### Query parameters\nauthorizationstringOptional\nYour authorization bearer token.\nsingle_use_tokenstringOptional\nYour [single use token](https://elevenlabs.io/docs/api-reference/tokens/create). Use this if you want to initiate a session from the client. When providing this parameter, `xi-api-key` is no longer required for authentication.\nmodel_idstringOptional\nThe model ID to use.\nlanguage_codestringOptional\nThe ISO 639-1 language code (for specific models).\nenable_loggingbooleanOptionalDefaults to `true`\nWhether to enable logging of the request.\nenable_ssml_parsingbooleanOptionalDefaults to `false`\nWhether to enable SSML parsing.\noutput_formatenumOptional\nThe output audio format\nShow 18 enum values\ninactivity_timeoutintegerOptionalDefaults to `20`\nTimeout for inactivity before a context is closed (seconds), can be up to 180 seconds.\nsync_alignmentbooleanOptionalDefaults to `false`\nWhether to include timing data with every audio chunk.\nauto_modebooleanOptionalDefaults to `false`\nReduces latency by disabling chunk schedule and buffers. Recommended for full sentences/phrases.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes - ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. For ‘eleven_turbo_v2_5’ and ‘eleven_flash_v2_5’ models, text normalization can only be enabled with Enterprise plans. Defaults to ‘auto’.\nAllowed values:autoonoff\nseedintegerOptional`0-4294967295`\nIf specified, system will best-effort sample deterministically. Integer between 0 and 4294967295.\n### Send\ninitializeConnectionMultiobjectRequired\nShow 7 properties\nOR\ninitialiseContextobjectRequired\nShow 7 properties\nOR\nsendTextMultiobjectRequired\nShow 3 properties\nOR\nflushContextClientobjectRequired\nShow 3 properties\nOR\ncloseContextClientobjectRequired\nShow 2 properties\nOR\ncloseSocketClientobjectRequired\nShow 1 properties\nOR\nkeepContextAliveobjectRequired\nShow 2 properties\n### Receive\naudioOutputMultiobjectRequired\nShow 4 properties\nOR\nfinalOutputMultiobjectRequired\nShow 2 properties\n"
    },
    {
      "title": "Text To Speech V 1 Text To Speech Voice Id Stream Input",
      "path": "text-to-speech-v-1-text-to-speech-voice-id-stream-input",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/v-1-text-to-speech-voice-id-stream-input",
      "keywords": [
        "api-reference",
        "auto",
        "docs",
        "elevenlabs",
        "explorer",
        "false",
        "handshake",
        "headers",
        "https",
        "input"
      ],
      "use_cases": [
        "How to text to speech v 1 text to speech voice id stream input",
        "How to create text to speech v 1 text to speech voice id stream input",
        "How to stream text to speech v 1 text to speech voice id stream input"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "voices",
        "speech"
      ],
      "priority": 8,
      "content": "The Text-to-Speech WebSockets API is designed to generate audio from partial text input while ensuring consistency throughout the generated audio. Although highly flexible, the WebSockets API isn’t a one-size-fits-all solution. It’s well-suited for scenarios where:\n  * The input text is being streamed or generated in chunks.\n  * Word-to-audio alignment information is required.\n\n\nHowever, it may not be the best choice when:\n  * The entire input text is available upfront. Given that the generations are partial, some buffering is involved, which could potentially result in slightly higher latency compared to a standard HTTP request.\n  * You want to quickly experiment or prototype. Working with WebSockets can be harder and more complex than using a standard HTTP API, which might slow down rapid development and testing.\n\n\n## Handshake[](https://elevenlabs.io/docs/api-reference/text-to-speech/v-1-text-to-speech-voice-id-stream-input?explorer=true)\nWSS\nwss://api.elevenlabs.io/v1/text-to-speech/:voice_id/stream-input\n### Headers\nxi-api-keystringRequired\n### Path parameters\nvoice_idstringRequired\nThe unique identifier for the voice to use in the TTS process.\n### Query parameters\nauthorizationstringOptional\nYour authorization bearer token.\nsingle_use_tokenstringOptional\nYour [single use token](https://elevenlabs.io/docs/api-reference/tokens/create). Use this if you want to initiate a session from the client. When providing this parameter, `xi-api-key` is no longer required for authentication.\nmodel_idstringOptional\nThe model ID to use.\nlanguage_codestringOptional\nThe ISO 639-1 language code (for specific models).\nenable_loggingbooleanOptionalDefaults to `true`\nWhether to enable logging of the request.\nenable_ssml_parsingbooleanOptionalDefaults to `false`\nWhether to enable SSML parsing.\noutput_formatenumOptional\nThe output audio format\nShow 18 enum values\ninactivity_timeoutintegerOptionalDefaults to `20`\nTimeout for inactivity before a context is closed (seconds), can be up to 180 seconds.\nsync_alignmentbooleanOptionalDefaults to `false`\nWhether to include timing data with every audio chunk.\nauto_modebooleanOptionalDefaults to `false`\nReduces latency by disabling chunk schedule and buffers. Recommended for full sentences/phrases.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes - ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. For ‘eleven_turbo_v2_5’ and ‘eleven_flash_v2_5’ models, text normalization can only be enabled with Enterprise plans. Defaults to ‘auto’.\nAllowed values:autoonoff\nseedintegerOptional`0-4294967295`\nIf specified, system will best-effort sample deterministically. Integer between 0 and 4294967295.\n### Send\ninitializeConnectionobjectRequired\nShow 6 properties\nOR\nsendTextobjectRequired\nShow 5 properties\nOR\ncloseConnectionobjectRequired\nShow 1 properties\n### Receive\naudioOutputobjectRequired\nShow 3 properties\nOR\nfinalOutputobjectRequired\nShow 1 properties\n"
    },
    {
      "title": "Text To Dialogue Stream",
      "path": "text-to-dialogue-stream",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-dialogue/stream",
      "keywords": [
        "auto",
        "dialogue",
        "eleven_v3",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameter",
        "parameters",
        "query"
      ],
      "use_cases": [
        "How to text to dialogue stream",
        "How to list text to dialogue stream",
        "How to stream text to dialogue stream",
        "How to convert text to dialogue stream"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "text"
      ],
      "priority": 5,
      "content": "Converts a list of text and voice ID pairs into speech (dialogue) and returns an audio stream.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ninputslist of objectsRequired\nA list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\nShow 2 properties\nmodel_idstringOptionalDefaults to `eleven_v3`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nsettingsobject or nullOptional\nSettings controlling the dialogue generation.\nShow 1 properties\npronunciation_dictionary_locatorslist of objects or nullOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\n### Response\nStreaming audio data\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Speech Convert With Timestamps",
      "path": "text-to-speech-convert-with-timestamps",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert-with-timestamps",
      "keywords": [
        "auto",
        "convert",
        "eleven_multilingual_v2",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "mp3_44100_128",
        "parameter"
      ],
      "use_cases": [
        "How to text to speech convert with timestamps",
        "How to list text to speech convert with timestamps",
        "How to stream text to speech convert with timestamps",
        "How to convert text to speech convert with timestamps"
      ],
      "tags": [
        "api-reference",
        "conversion",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Generate speech from text with precise character-level timing information for audio-text synchronization.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\noptimize_streaming_latencyinteger or nullOptionalDeprecated\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\noutput_formatenumOptionalDefaults to `mp3_44100_128`\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ntextstringRequired\nThe text that will get converted into speech.\nmodel_idstringOptionalDefaults to `eleven_multilingual_v2`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nvoice_settingsobject or nullOptional\nVoice settings overriding stored settings for the given voice. They are applied only on the given request.\nShow 5 properties\npronunciation_dictionary_locatorslist of objectsOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nprevious_textstring or nullOptional\nThe text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nnext_textstring or nullOptional\nThe text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nprevious_request_idslist of stringsOptional\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nnext_request_idslist of stringsOptional\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\napply_language_text_normalizationbooleanOptionalDefaults to `false`\nThis parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\nuse_pvc_as_ivcbooleanOptionalDefaults to `false`Deprecated\nIf true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n### Response\nSuccessful Response\naudio_base64string\nBase64 encoded audio data\nalignmentobject or null\nTimestamp information for each character in the original text\nShow 3 properties\nnormalized_alignmentobject or null\nTimestamp information for each character in the normalized text\nShow 3 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Speech Convert",
      "path": "text-to-speech-convert",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/convert",
      "keywords": [
        "auto",
        "convert",
        "eleven_multilingual_v2",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "mp3_44100_128",
        "parameter"
      ],
      "use_cases": [
        "How to text to speech convert",
        "How to list text to speech convert",
        "How to stream text to speech convert",
        "How to convert text to speech convert"
      ],
      "tags": [
        "api-reference",
        "conversion",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Converts text into speech using a voice of your choice and returns audio.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. Use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\noptimize_streaming_latencyinteger or nullOptionalDeprecated\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\noutput_formatenumOptionalDefaults to `mp3_44100_128`\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ntextstringRequired\nThe text that will get converted into speech.\nmodel_idstringOptionalDefaults to `eleven_multilingual_v2`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nvoice_settingsobject or nullOptional\nVoice settings overriding stored settings for the given voice. They are applied only on the given request.\nShow 5 properties\npronunciation_dictionary_locatorslist of objects or nullOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nprevious_textstring or nullOptional\nThe text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nnext_textstring or nullOptional\nThe text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nprevious_request_idslist of strings or nullOptional\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nnext_request_idslist of strings or nullOptional\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\napply_language_text_normalizationbooleanOptionalDefaults to `false`\nThis parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\nuse_pvc_as_ivcbooleanOptionalDefaults to `false`Deprecated\nIf true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n### Response\nThe generated audio file\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Speech Stream",
      "path": "text-to-speech-stream",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/stream",
      "keywords": [
        "auto",
        "eleven_multilingual_v2",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "mp3_44100_128",
        "parameter",
        "parameters"
      ],
      "use_cases": [
        "How to text to speech stream",
        "How to list text to speech stream",
        "How to stream text to speech stream",
        "How to convert text to speech stream"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Converts text into speech using a voice of your choice and returns audio as an audio stream.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. Use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\noptimize_streaming_latencyinteger or nullOptionalDeprecated\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\noutput_formatenumOptionalDefaults to `mp3_44100_128`\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ntextstringRequired\nThe text that will get converted into speech.\nmodel_idstringOptionalDefaults to `eleven_multilingual_v2`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nvoice_settingsobject or nullOptional\nVoice settings overriding stored settings for the given voice. They are applied only on the given request.\nShow 5 properties\npronunciation_dictionary_locatorslist of objects or nullOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nprevious_textstring or nullOptional\nThe text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nnext_textstring or nullOptional\nThe text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nprevious_request_idslist of strings or nullOptional\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nnext_request_idslist of strings or nullOptional\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\napply_language_text_normalizationbooleanOptionalDefaults to `false`\nThis parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\nuse_pvc_as_ivcbooleanOptionalDefaults to `false`Deprecated\nIf true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n### Response\nStreaming audio data\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Dialogue Stream With Timestamps",
      "path": "text-to-dialogue-stream-with-timestamps",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-dialogue/stream-with-timestamps",
      "keywords": [
        "auto",
        "dialogue",
        "eleven_v3",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameter",
        "parameters",
        "query"
      ],
      "use_cases": [
        "How to text to dialogue stream with timestamps",
        "How to list text to dialogue stream with timestamps",
        "How to stream text to dialogue stream with timestamps",
        "How to convert text to dialogue stream with timestamps"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "text"
      ],
      "priority": 5,
      "content": "Converts a list of text and voice ID pairs into speech (dialogue) and returns a stream of JSON blobs containing audio as a base64 encoded string and timestamps\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ninputslist of objectsRequired\nA list of dialogue inputs, each containing text and a voice ID which will be converted into speech.\nShow 2 properties\nmodel_idstringOptionalDefaults to `eleven_v3`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nsettingsobject or nullOptional\nSettings controlling the dialogue generation.\nShow 1 properties\npronunciation_dictionary_locatorslist of objects or nullOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\n### Response\nStream of transcription chunks\naudio_base64string\nBase64 encoded audio data\nvoice_segmentslist of objects\nVoice segments for the audio\nShow 6 properties\nalignmentobject or null\nTimestamp information for each character in the original text\nShow 3 properties\nnormalized_alignmentobject or null\nTimestamp information for each character in the normalized text\nShow 3 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Sound Effects Convert",
      "path": "text-to-sound-effects-convert",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-sound-effects/convert",
      "keywords": [
        "convert",
        "effects",
        "eleven_text_to_sound_v2",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "query"
      ],
      "use_cases": [
        "How to text to sound effects convert",
        "How to create text to sound effects convert",
        "How to convert text to sound effects convert"
      ],
      "tags": [
        "api-reference",
        "conversion",
        "text"
      ],
      "priority": 5,
      "content": "Turn text into sound effects for your videos, voice-overs or video games using the most advanced sound effects models in the world.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ntextstringRequired\nThe text that will get converted into a sound effect.\nloopbooleanOptionalDefaults to `false`\nWhether to create a sound effect that loops smoothly. Only available for the ‘eleven_text_to_sound_v2 model’.\nduration_secondsdouble or nullOptional\nThe duration of the sound which will be generated in seconds. Must be at least 0.5 and at most 30. If set to None we will guess the optimal duration using the prompt. Defaults to None.\nprompt_influencedouble or nullOptionalDefaults to `0.3`\nA higher prompt influence makes your generation follow the prompt more closely while also making generations less variable. Must be a value between 0 and 1. Defaults to 0.3.\nmodel_idstringOptionalDefaults to `eleven_text_to_sound_v2`\nThe model ID to use for the sound generation.\n### Response\nThe generated sound effect as an MP3 file\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Speech Stream With Timestamps",
      "path": "text-to-speech-stream-with-timestamps",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-speech/stream-with-timestamps",
      "keywords": [
        "auto",
        "eleven_multilingual_v2",
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "mp3_44100_128",
        "parameter",
        "parameters"
      ],
      "use_cases": [
        "How to text to speech stream with timestamps",
        "How to list text to speech stream with timestamps",
        "How to stream text to speech stream with timestamps",
        "How to convert text to speech stream with timestamps"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "speech",
        "text"
      ],
      "priority": 9,
      "content": "Converts text into speech using a voice of your choice and returns a stream of JSONs containing audio as a base64 encoded string together with information on when which character was spoken.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. Use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nenable_loggingbooleanOptionalDefaults to `true`\nWhen enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.\noptimize_streaming_latencyinteger or nullOptionalDeprecated\nYou can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).\nDefaults to None.\noutput_formatenumOptionalDefaults to `mp3_44100_128`\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\ntextstringRequired\nThe text that will get converted into speech.\nmodel_idstringOptionalDefaults to `eleven_multilingual_v2`\nIdentifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.\nlanguage_codestring or nullOptional\nLanguage code (ISO 639-1) used to enforce a language for the model and text normalization. If the model does not support provided language code, an error will be returned.\nvoice_settingsobject or nullOptional\nVoice settings overriding stored settings for the given voice. They are applied only on the given request.\nShow 5 properties\npronunciation_dictionary_locatorslist of objects or nullOptional\nA list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request\nShow 2 properties\nseedinteger or nullOptional\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.\nprevious_textstring or nullOptional\nThe text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nnext_textstring or nullOptional\nThe text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.\nprevious_request_idslist of strings or nullOptional\nA list of request_id of the samples that were generated before this generation. Can be used to improve the speech’s continuity when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.\nnext_request_idslist of strings or nullOptional\nA list of request_id of the samples that come after this generation. next_request_ids is especially useful for maintaining the speech’s continuity when regenerating a sample that has had some audio quality issues. For example, if you have generated 3 speech clips, and you want to improve clip 2, passing the request id of clip 3 as a next_request_id (and that of clip 1 as a previous_request_id) will help maintain natural flow in the combined speech. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.\napply_text_normalizationenumOptionalDefaults to `auto`\nThis parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped.\nAllowed values:autoonoff\napply_language_text_normalizationbooleanOptionalDefaults to `false`\nThis parameter controls language text normalization. This helps with proper pronunciation of text in some supported languages. WARNING: This parameter can heavily increase the latency of the request. Currently only supported for Japanese.\nuse_pvc_as_ivcbooleanOptionalDefaults to `false`Deprecated\nIf true, we won't use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.\n### Response\nStream of transcription chunks\naudio_base64string\nBase64 encoded audio data\nalignmentobject or null\nTimestamp information for each character in the original text\nShow 3 properties\nnormalized_alignmentobject or null\nTimestamp information for each character in the normalized text\nShow 3 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Voice Create",
      "path": "text-to-voice-create",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-voice/create",
      "keywords": [
        "create",
        "endpoint",
        "errors",
        "false",
        "header",
        "headers",
        "post",
        "request",
        "response",
        "text"
      ],
      "use_cases": [
        "How to text to voice create",
        "How to create text to voice create",
        "How to list text to voice create"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices",
        "text"
      ],
      "priority": 5,
      "content": "Create a voice from previously generated voice preview. This endpoint should be called after you fetched a generated_voice_id using POST /v1/text-to-voice/design or POST /v1/text-to-voice/:voice_id/remix.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nvoice_namestringRequired\nName to use for the created voice.\nvoice_descriptionstringRequired`20-1000 characters`\nDescription to use for the created voice.\ngenerated_voice_idstringRequired\nThe generated_voice_id to create, call POST /v1/text-to-voice/create-previews and fetch the generated_voice_id from the response header if don’t have one yet.\nlabelsmap from strings to strings or nullOptional\nOptional, metadata to add to the created voice. Defaults to None.\nplayed_not_selected_voice_idslist of strings or nullOptional\nList of voice ids that the user has played but not selected. Used for RLHF.\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the voice.\nnamestring or null\nThe name of the voice.\nsampleslist of objects or null\nList of samples associated with the voice.\nShow 12 properties\ncategoryenum or null\nThe category of the voice.\nShow 6 enum values\nfine_tuningobject or null\nFine-tuning information for the voice.\nShow 15 properties\nlabelsmap from strings to strings or null\nLabels associated with the voice.\ndescriptionstring or null\nThe description of the voice.\npreview_urlstring or null\nThe preview URL of the voice.\navailable_for_tierslist of strings or null\nThe tiers the voice is available for.\nsettingsobject or null\nThe settings of the voice.\nShow 5 properties\nsharingobject or null\nThe sharing information of the voice.\nShow 33 properties\nhigh_quality_base_model_idslist of strings or null\nThe base model IDs for high-quality voices.\nverified_languageslist of objects or null\nThe verified languages of the voice.\nShow 5 properties\ncollection_idslist of strings or null\nThe IDs of collections this voice belongs to.\nsafety_controlenum or null\nThe safety controls of the voice.\nAllowed values:NONEBANCAPTCHAENTERPRISE_BANENTERPRISE_CAPTCHA\nvoice_verificationobject or null\nThe voice verification of the voice.\nShow 6 properties\npermission_on_resourcestring or null\nThe permission on the resource of the voice.\nis_ownerboolean or null\nWhether the voice is owned by the user.\nis_legacyboolean or nullDefaults to `false`\nWhether the voice is legacy.\nis_mixedboolean or nullDefaults to `false`\nWhether the voice is mixed.\nfavorited_at_unixinteger or null\nTimestamp when the voice was marked as favorite in Unix time.\ncreated_at_unixinteger or null\nThe creation time of the voice in Unix time.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "User Get",
      "path": "user-get",
      "url": "https://elevenlabs.io/docs/api-reference/user/get",
      "keywords": [
        "errors",
        "false",
        "get",
        "headers",
        "response",
        "user"
      ],
      "use_cases": [
        "How to user get",
        "How to create user get",
        "How to list user get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Gets information about the user\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nuser_idstring\nThe unique identifier of the user.\nsubscriptionobject\nDetails of the user's subscription.\nShow 20 properties\nis_onboarding_completedboolean\nWhether the user's onboarding is completed.\nis_onboarding_checklist_completedboolean\nWhether the user's onboarding checklist is completed.\ncreated_atinteger\nThe unix timestamp of the user's creation. 0 if the user was created before the unix timestamp was added.\nis_new_userbooleanDeprecated\nWhether the user is new. This field is deprecated and will be removed in the future. Use ‘created_at’ instead.\ncan_use_delayed_payment_methodsbooleanDeprecated\nThis field is deprecated and will be removed in a future major version. Instead use subscription.trust_on_invoice_creation.\nxi_api_keystring or null\nThe API key of the user.\nfirst_namestring or null\nFirst name of the user.\nis_api_key_hashedboolean or nullDefaults to `false`\nWhether the user's API key is hashed.\nxi_api_key_previewstring or null\nThe preview of the user's API key.\nreferral_link_codestring or null\nThe referral link code of the user.\npartnerstack_partner_default_linkstring or null\nThe Partnerstack partner default link of the user.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Twilio Outbound Call",
      "path": "twilio-outbound-call",
      "url": "https://elevenlabs.io/docs/api-reference/twilio/outbound-call",
      "keywords": [
        "call",
        "endpoint",
        "errors",
        "headers",
        "outbound",
        "request",
        "response",
        "twilio"
      ],
      "use_cases": [
        "How to twilio outbound call"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Handle an outbound call via Twilio\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nagent_idstringRequired\nagent_phone_number_idstringRequired\nto_numberstringRequired\nconversation_initiation_client_dataobject or nullOptional\nShow 5 properties\n### Response\nSuccessful Response\nsuccessboolean\nmessagestring\nconversation_idstring or null\ncallSidstring or null\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Voice Stream",
      "path": "text-to-voice-stream",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-voice/stream",
      "keywords": [
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "response",
        "stream",
        "text",
        "voice"
      ],
      "use_cases": [
        "How to text to voice stream",
        "How to create text to voice stream",
        "How to stream text to voice stream"
      ],
      "tags": [
        "api-reference",
        "streaming",
        "voices",
        "text"
      ],
      "priority": 5,
      "content": "Stream a voice preview that was created via the /v1/text-to-voice/design endpoint.\n### Path parameters\ngenerated_voice_idstringRequired\nThe generated_voice_id to stream.\n### Headers\nxi-api-keystringRequired\n### Response\nStreaming audio data\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "User Subscription Get",
      "path": "user-subscription-get",
      "url": "https://elevenlabs.io/docs/api-reference/user/subscription/get",
      "keywords": [
        "errors",
        "get",
        "headers",
        "response",
        "subscription",
        "user"
      ],
      "use_cases": [
        "How to user subscription get",
        "How to list user subscription get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Gets extended information about the users subscription\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\ntierstring\nThe tier of the user's subscription.\ncharacter_countinteger\nThe number of characters used by the user.\ncharacter_limitinteger\nThe maximum number of characters allowed in the current billing period.\nmax_character_limit_extensioninteger or null\nMaximum number of characters that the character limit can be exceeded by. Managed by the workspace admin.\ncan_extend_character_limitboolean\nWhether the user can extend their character limit.\nallowed_to_extend_character_limitboolean\nWhether the user is allowed to extend their character limit.\nvoice_slots_usedinteger\nThe number of voice slots used by the user.\nprofessional_voice_slots_usedinteger\nThe number of professional voice slots used by the workspace/user if single seat.\nvoice_limitinteger\nThe maximum number of voice slots allowed for the user.\nvoice_add_edit_counterinteger\nThe number of voice add/edits used by the user.\nprofessional_voice_limitinteger\nThe maximum number of professional voices allowed for the user.\ncan_extend_voice_limitboolean\nWhether the user can extend their voice limit.\ncan_use_instant_voice_cloningboolean\nWhether the user can use instant voice cloning.\ncan_use_professional_voice_cloningboolean\nWhether the user can use professional voice cloning.\nstatusenum\nThe status of the user's subscription.\nShow 6 enum values\nopen_invoiceslist of objects\nThe open invoices for the user.\nShow 9 properties\nhas_open_invoicesboolean\nWhether the user has open invoices.\nnext_character_count_reset_unixinteger or null\nThe Unix timestamp of the next character count reset.\nmax_voice_add_editsinteger or null\nThe maximum number of voice add/edits allowed for the user.\ncurrencyenum or null\nThe currency of the user's subscription.\nAllowed values:usdeurinr\nbilling_periodenum or null\nThe billing period of the user's subscription.\nAllowed values:monthly_period3_month_period6_month_periodannual_period\ncharacter_refresh_periodenum or null\nThe character refresh period of the user's subscription.\nAllowed values:monthly_period3_month_period6_month_periodannual_period\nnext_invoiceobject or null\nThe next invoice for the user.\nShow 9 properties\npending_changeobject or null\nThe pending change for the user.\nShow 2 variants\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Twilio Register Call",
      "path": "twilio-register-call",
      "url": "https://elevenlabs.io/docs/api-reference/twilio/register-call",
      "keywords": [
        "call",
        "endpoint",
        "errors",
        "headers",
        "inbound",
        "register",
        "request",
        "response",
        "twilio"
      ],
      "use_cases": [
        "How to twilio register call"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Register a Twilio call and return TwiML to connect the call\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nagent_idstringRequired\nfrom_numberstringRequired\nto_numberstringRequired\ndirectionenumOptionalDefaults to `inbound`\nAllowed values:inboundoutbound\nconversation_initiation_client_dataobject or nullOptional\nShow 5 properties\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Voice Design",
      "path": "text-to-voice-design",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-voice/design",
      "keywords": [
        "design",
        "eleven_multilingual_ttv_v2",
        "endpoint",
        "errors",
        "false",
        "headers",
        "parameters",
        "query",
        "request",
        "response"
      ],
      "use_cases": [
        "How to text to voice design",
        "How to create text to voice design",
        "How to list text to voice design",
        "How to stream text to voice design"
      ],
      "tags": [
        "api-reference",
        "voices",
        "text"
      ],
      "priority": 5,
      "content": "Design a voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\nvoice_descriptionstringRequired`20-1000 characters`\nDescription to use for the created voice.\nmodel_idenumOptionalDefaults to `eleven_multilingual_ttv_v2`\nModel to use for the voice generation. Possible values: eleven_multilingual_ttv_v2, eleven_ttv_v3.\nAllowed values:eleven_multilingual_ttv_v2eleven_ttv_v3\ntextstring or nullOptional`100-1000 characters`\nText to generate, text length has to be between 100 and 1000.\nauto_generate_textbooleanOptionalDefaults to `false`\nWhether to automatically generate a text suitable for the voice description.\nloudnessdoubleOptional`-1-1`Defaults to `0.5`\nControls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\nseedinteger or nullOptional`0-2147483647`\nRandom number that controls the voice generation. Same seed with same inputs produces same voice.\nguidance_scaledoubleOptional`0-100`Defaults to `5`\nControls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\nstream_previewsbooleanOptionalDefaults to `false`\nDetermines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\nshould_enhancebooleanOptionalDefaults to `false`\nWhether to enhance the voice description using AI to add more detail and improve voice generation quality. When enabled, the system will automatically expand simple prompts into more detailed voice descriptions. Defaults to False\nremixing_session_idstring or nullOptional\nThe remixing session id.\nremixing_session_iteration_idstring or nullOptional\nThe id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\nqualitydouble or nullOptional`-1-1`\nHigher quality results in better voice output but less variety.\nreference_audio_base64string or nullOptional\nReference audio to use for the voice generation. The audio should be base64 encoded. Only supported when using the eleven_ttv_v3 model.\nprompt_strengthdouble or nullOptional`0-1`\nControls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n### Response\nSuccessful Response\npreviewslist of objects\nThe previews of the generated voices.\nShow 5 properties\ntextstring\nThe text used to preview the voices.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Tokens Create",
      "path": "tokens-create",
      "url": "https://elevenlabs.io/docs/api-reference/tokens/create",
      "keywords": [
        "create",
        "errors",
        "headers",
        "parameters",
        "path",
        "response",
        "tokens"
      ],
      "use_cases": [
        "How to tokens create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Generate a time limited single-use token with embedded authentication for frontend clients.\n### Path parameters\ntoken_typeenumRequired\nAllowed values:realtime_scribetts_websocket\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\ntokenstring\nA time bound single use token that expires after 15 minutes. Will be consumed on use.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Usage Get",
      "path": "usage-get",
      "url": "https://elevenlabs.io/docs/api-reference/usage/get",
      "keywords": [
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "query",
        "response",
        "usage"
      ],
      "use_cases": [
        "How to usage get",
        "How to list usage get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Returns the usage metrics for the current user or the entire workspace they are part of. The response provides a time axis based on the specified aggregation interval (default: day), with usage values for each interval along that axis. Usage is broken down by the selected breakdown type. For example, breakdown type “voice” will return the usage of each voice for each interval along the time axis.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nstart_unixintegerRequired\nUTC Unix timestamp for the start of the usage window, in milliseconds. To include the first day of the window, the timestamp should be at 00:00:00 of that day.\nend_unixintegerRequired\nUTC Unix timestamp for the end of the usage window, in milliseconds. To include the last day of the window, the timestamp should be at 23:59:59 of that day.\ninclude_workspace_metricsbooleanOptionalDefaults to `false`\nWhether or not to include the statistics of the entire workspace.\nbreakdown_typeenumOptional\nHow to break down the information. Cannot be “user” if include_workspace_metrics is False.\nShow 16 enum values\naggregation_intervalenumOptional\nHow to aggregate usage data over time. Can be \"hour\", \"day\", \"week\", \"month\", or \"cumulative\".\nAllowed values:hourdayweekmonthcumulative\naggregation_bucket_sizeinteger or nullOptional\nAggregation bucket size in seconds. Overrides the aggregation interval.\nmetricenumOptional\nWhich metric to aggregate.\nShow 9 enum values\n### Response\nSuccessful Response\ntimelist of integers\nThe time axis with unix timestamps for each day.\nusagemap from strings to lists of doubles\nThe usage of each breakdown type along the time axis.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Text To Voice Remix",
      "path": "text-to-voice-remix",
      "url": "https://elevenlabs.io/docs/api-reference/text-to-voice/remix",
      "keywords": [
        "endpoint",
        "errors",
        "false",
        "headers",
        "parameters",
        "path",
        "query",
        "remix",
        "request",
        "response"
      ],
      "use_cases": [
        "How to text to voice remix",
        "How to create text to voice remix",
        "How to list text to voice remix",
        "How to stream text to voice remix"
      ],
      "tags": [
        "api-reference",
        "voices",
        "text"
      ],
      "priority": 5,
      "content": "Remix an existing voice via a prompt. This method returns a list of voice previews. Each preview has a generated_voice_id and a sample of the voice as base64 encoded mp3 audio. To create a voice use the generated_voice_id of the preferred preview with the /v1/text-to-voice endpoint.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\noutput_formatenumOptional\nOutput format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.\nShow 21 enum values\n### Request\nThis endpoint expects an object.\nvoice_descriptionstringRequired`5-1000 characters`\nDescription of the changes to make to the voice.\ntextstring or nullOptional`100-1000 characters`\nText to generate, text length has to be between 100 and 1000.\nauto_generate_textbooleanOptionalDefaults to `false`\nWhether to automatically generate a text suitable for the voice description.\nloudnessdoubleOptional`-1-1`Defaults to `0.5`\nControls the volume level of the generated voice. -1 is quietest, 1 is loudest, 0 corresponds to roughly -24 LUFS.\nseedinteger or nullOptional`0-2147483647`\nRandom number that controls the voice generation. Same seed with same inputs produces same voice.\nguidance_scaledoubleOptional`0-100`Defaults to `2`\nControls how closely the AI follows the prompt. Lower numbers give the AI more freedom to be creative, while higher numbers force it to stick more to the prompt. High numbers can cause voice to sound artificial or robotic. We recommend to use longer, more detailed prompts at lower Guidance Scale.\nstream_previewsbooleanOptionalDefaults to `false`\nDetermines whether the Text to Voice previews should be included in the response. If true, only the generated IDs will be returned which can then be streamed via the /v1/text-to-voice/:generated_voice_id/stream endpoint.\nremixing_session_idstring or nullOptional\nThe remixing session id.\nremixing_session_iteration_idstring or nullOptional\nThe id of the remixing session iteration where these generations should be attached to. If not provided, a new iteration will be created.\nprompt_strengthdouble or nullOptional`0-1`\nControls the balance of prompt versus reference audio when generating voice samples. 0 means almost no prompt influence, 1 means almost no reference audio influence. Only supported when using the eleven_ttv_v3 model and providing reference audio.\n### Response\nSuccessful Response\npreviewslist of objects\nThe previews of the generated voices.\nShow 5 properties\ntextstring\nThe text used to preview the voices.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Delete",
      "path": "voices-delete",
      "url": "https://elevenlabs.io/docs/api-reference/voices/delete",
      "keywords": [
        "delete",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "voices"
      ],
      "use_cases": [
        "How to voices delete",
        "How to delete voices delete",
        "How to list voices delete"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Deletes a voice by its ID.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the voice deletion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Get",
      "path": "voices-get",
      "url": "https://elevenlabs.io/docs/api-reference/voices/get",
      "keywords": [
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameter",
        "parameters",
        "path",
        "query",
        "response"
      ],
      "use_cases": [
        "How to voices get",
        "How to create voices get",
        "How to list voices get"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 9,
      "content": "Returns metadata about a specific voice.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nwith_settingsbooleanOptionalDefaults to `true`Deprecated\nThis parameter is now deprecated. It is ignored and will be removed in a future version.\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the voice.\nnamestring or null\nThe name of the voice.\nsampleslist of objects or null\nList of samples associated with the voice.\nShow 12 properties\ncategoryenum or null\nThe category of the voice.\nShow 6 enum values\nfine_tuningobject or null\nFine-tuning information for the voice.\nShow 15 properties\nlabelsmap from strings to strings or null\nLabels associated with the voice.\ndescriptionstring or null\nThe description of the voice.\npreview_urlstring or null\nThe preview URL of the voice.\navailable_for_tierslist of strings or null\nThe tiers the voice is available for.\nsettingsobject or null\nThe settings of the voice.\nShow 5 properties\nsharingobject or null\nThe sharing information of the voice.\nShow 33 properties\nhigh_quality_base_model_idslist of strings or null\nThe base model IDs for high-quality voices.\nverified_languageslist of objects or null\nThe verified languages of the voice.\nShow 5 properties\ncollection_idslist of strings or null\nThe IDs of collections this voice belongs to.\nsafety_controlenum or null\nThe safety controls of the voice.\nAllowed values:NONEBANCAPTCHAENTERPRISE_BANENTERPRISE_CAPTCHA\nvoice_verificationobject or null\nThe voice verification of the voice.\nShow 6 properties\npermission_on_resourcestring or null\nThe permission on the resource of the voice.\nis_ownerboolean or null\nWhether the voice is owned by the user.\nis_legacyboolean or nullDefaults to `false`\nWhether the voice is legacy.\nis_mixedboolean or nullDefaults to `false`\nWhether the voice is mixed.\nfavorited_at_unixinteger or null\nTimestamp when the voice was marked as favorite in Unix time.\ncreated_at_unixinteger or null\nThe creation time of the voice in Unix time.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Get Audio",
      "path": "voices-pvc-samples-get-audio",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/get-audio",
      "keywords": [
        "audio",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "pvc",
        "query",
        "response"
      ],
      "use_cases": [
        "How to voices pvc samples get audio",
        "How to list voices pvc samples get audio"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Retrieve the first 30 seconds of voice sample audio with or without noise removal.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\nsample_idstringRequired\nSample ID to be used\n### Headers\nxi-api-keystringRequired\n### Query parameters\nremove_background_noisebooleanOptionalDefaults to `false`\nIf set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n### Response\nSuccessful Response\naudio_base_64string\nThe base64 encoded audio.\nvoice_idstring\nThe ID of the voice.\nsample_idstring\nThe ID of the sample.\nmedia_typestring\nThe media type of the audio.\nduration_secsdouble or null\nThe duration of the audio in seconds.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Find Similar Voices",
      "path": "voices-find-similar-voices",
      "url": "https://elevenlabs.io/docs/api-reference/voices/find-similar-voices",
      "keywords": [
        "endpoint",
        "errors",
        "find",
        "headers",
        "request",
        "response",
        "similar",
        "voices"
      ],
      "use_cases": [
        "How to voices find similar voices",
        "How to list voices find similar voices"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 7,
      "content": "Returns a list of shared voices similar to the provided audio sample. If neither similarity_threshold nor top_k is provided, we will apply default values.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing an optional file.\naudio_filefileOptional\nsimilarity_thresholddouble or nullOptional\nThreshold for voice similarity between provided sample and library voices. Values range from 0 to 2. The smaller the value the more similar voices will be returned.\ntop_kinteger or nullOptional\nNumber of most similar voices to return. If similarity_threshold is provided, less than this number of voices may be returned. Values range from 1 to 100.\n### Response\nSuccessful Response\nvoiceslist of objects\nThe list of shared voices\nShow 31 properties\nhas_moreboolean\nWhether there are more shared voices in subsequent pages.\nlast_sort_idstring or null\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Create",
      "path": "voices-pvc-create",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/create",
      "keywords": [
        "create",
        "endpoint",
        "errors",
        "headers",
        "pvc",
        "request",
        "response",
        "voices"
      ],
      "use_cases": [
        "How to voices pvc create",
        "How to create voices pvc create"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Creates a new PVC voice with metadata but no samples\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnamestringRequired`<=100 characters`\nThe name that identifies this voice. This will be displayed in the dropdown of the website.\nlanguagestringRequired\nLanguage used in the samples.\ndescriptionstring or nullOptional`<=500 characters`\nDescription to use for the created voice.\nlabelsmap from strings to strings or nullOptional\nLabels for the voice. Keys can be language, accent, gender, or age.\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the voice.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Ivc Create",
      "path": "voices-ivc-create",
      "url": "https://elevenlabs.io/docs/api-reference/voices/ivc/create",
      "keywords": [
        "create",
        "endpoint",
        "errors",
        "false",
        "headers",
        "ivc",
        "request",
        "response",
        "voices"
      ],
      "use_cases": [
        "How to voices ivc create",
        "How to create voices ivc create",
        "How to list voices ivc create"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Create a voice clone and add it to your Voices\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form with multiple files.\nnamestringRequired\nThe name that identifies this voice. This will be displayed in the dropdown of the website.\nfilesfilesRequired\nA list of file paths to audio recordings intended for voice cloning.\nremove_background_noisebooleanOptionalDefaults to `false`\nIf set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\ndescriptionstring or nullOptional\nA description of the voice.\nlabelsmap from strings to strings or string or nullOptional\nLabels for the voice. Keys can be language, accent, gender, or age.\nShow 2 variants\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the newly created voice.\nrequires_verificationboolean\nWhether the voice requires verification\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Create",
      "path": "voices-pvc-samples-create",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/create",
      "keywords": [
        "create",
        "endpoint",
        "errors",
        "false",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response"
      ],
      "use_cases": [
        "How to voices pvc samples create",
        "How to create voices pvc samples create",
        "How to list voices pvc samples create"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Add audio samples to a PVC voice\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form with multiple files.\nfilesfilesRequired\nAudio files used to create the voice.\nremove_background_noisebooleanOptionalDefaults to `false`\nIf set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\n### Response\nSuccessful Response\nsample_idstring or null\nThe ID of the sample.\nfile_namestring or null\nThe name of the sample file.\nmime_typestring or null\nThe MIME type of the sample file.\nsize_bytesinteger or null\nThe size of the sample file in bytes.\nhashstring or null\nThe hash of the sample file.\nduration_secsdouble or null\nremove_background_noiseboolean or null\nhas_isolated_audioboolean or null\nhas_isolated_audio_previewboolean or null\nspeaker_separationobject or null\nShow 5 properties\ntrim_startinteger or null\ntrim_endinteger or null\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Get Separated Speaker Audio",
      "path": "voices-pvc-samples-get-separated-speaker-audio",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/get-separated-speaker-audio",
      "keywords": [
        "audio",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "pvc",
        "response",
        "samples",
        "separated"
      ],
      "use_cases": [
        "How to voices pvc samples get separated speaker audio",
        "How to list voices pvc samples get separated speaker audio"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Retrieve the separated audio for a specific speaker.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\nsample_idstringRequired\nSample ID to be used\nspeaker_idstringRequired\nSpeaker ID to be used, you can use GET [https://api.elevenlabs.io/v1/voices/{voice_id}/samples/{sample_id}/speakers](https://api.elevenlabs.io/v1/voices/%7Bvoice_id%7D/samples/%7Bsample_id%7D/speakers) to list all the available speakers for a sample.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\naudio_base_64string\nThe base64 encoded audio.\nmedia_typestring\nThe media type of the audio.\nduration_secsdouble\nThe duration of the audio in seconds.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Delete",
      "path": "voices-pvc-samples-delete",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/delete",
      "keywords": [
        "delete",
        "errors",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response",
        "samples",
        "voices"
      ],
      "use_cases": [
        "How to voices pvc samples delete",
        "How to delete voices pvc samples delete",
        "How to list voices pvc samples delete"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Delete a sample from a PVC voice.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\nsample_idstringRequired\nSample ID to be used\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the voice sample deletion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Get Speaker Separation Status",
      "path": "voices-pvc-samples-get-speaker-separation-status",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/get-speaker-separation-status",
      "keywords": [
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "pvc",
        "response",
        "samples",
        "separation",
        "speaker"
      ],
      "use_cases": [
        "How to voices pvc samples get speaker separation status",
        "How to list voices pvc samples get speaker separation status"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Retrieve the status of the speaker separation process and the list of detected speakers if complete.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\nsample_idstringRequired\nSample ID to be used\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the voice.\nsample_idstring\nThe ID of the sample.\nstatusenum\nThe status of the speaker separation.\nAllowed values:not_startedpendingcompletedfailed\nspeakersmap from strings to objects or null\nThe speakers of the sample.\nShow 3 properties\nselected_speaker_idslist of strings or null\nThe IDs of the selected speakers.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Get Waveform",
      "path": "voices-pvc-samples-get-waveform",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/get-waveform",
      "keywords": [
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "pvc",
        "response",
        "samples",
        "voices",
        "waveform"
      ],
      "use_cases": [
        "How to voices pvc samples get waveform",
        "How to list voices pvc samples get waveform"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Retrieve the visual waveform of a voice sample.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\nsample_idstringRequired\nSample ID to be used\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nsample_idstring\nThe ID of the sample.\nvisual_waveformlist of doubles\nThe visual waveform of the sample, represented as a list of floats.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Samples Get",
      "path": "voices-samples-get",
      "url": "https://elevenlabs.io/docs/api-reference/voices/samples/get",
      "keywords": [
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "samples",
        "voices"
      ],
      "use_cases": [
        "How to voices samples get",
        "How to list voices samples get"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Returns the audio corresponding to a sample attached to a voice.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\nsample_idstringRequired\nID of the sample to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Separate Speakers",
      "path": "voices-pvc-samples-separate-speakers",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/separate-speakers",
      "keywords": [
        "errors",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response",
        "samples",
        "separate",
        "speakers"
      ],
      "use_cases": [
        "How to voices pvc samples separate speakers",
        "How to list voices pvc samples separate speakers"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 7,
      "content": "Start speaker separation process for a sample\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\nsample_idstringRequired\nSample ID to be used\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the start speaker seperation request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Samples Delete",
      "path": "voices-samples-delete",
      "url": "https://elevenlabs.io/docs/api-reference/voices/samples/delete",
      "keywords": [
        "delete",
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "samples"
      ],
      "use_cases": [
        "How to voices samples delete",
        "How to list voices samples delete"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Removes a sample by its ID.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\nsample_idstringRequired\nID of the sample to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/get) endpoint list all the available samples for a voice.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstatusstring\nThe status of the sample deletion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Verification Request",
      "path": "voices-pvc-verification-request",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/verification/request",
      "keywords": [
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response",
        "verification",
        "voices"
      ],
      "use_cases": [
        "How to voices pvc verification request",
        "How to list voices pvc verification request"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 7,
      "content": "Request manual verification for a PVC voice.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form with multiple files.\nfilesfilesRequired\nVerification documents\nextra_textstring or nullOptional\nExtra text to be used in the manual verification process.\n### Response\nSuccessful Response\nstatusstring\nThe status of the request PVC manual verification request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Train",
      "path": "voices-pvc-train",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/train",
      "keywords": [
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response",
        "train",
        "voices"
      ],
      "use_cases": [
        "How to voices pvc train",
        "How to list voices pvc train"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 7,
      "content": "Start PVC training process for a voice.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nmodel_idstring or nullOptional\nThe model ID to use for the conversion.\n### Response\nSuccessful Response\nstatusstring\nThe status of the start PVC voice training request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Verification Captcha Verify",
      "path": "voices-pvc-verification-captcha-verify",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/verification/captcha/verify",
      "keywords": [
        "captcha",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response",
        "verification"
      ],
      "use_cases": [
        "How to voices pvc verification captcha verify",
        "How to list voices pvc verification captcha verify"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 7,
      "content": "Submit captcha verification for PVC voice.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form containing a file.\nrecordingfileRequired\nAudio recording of the user\n### Response\nSuccessful Response\nstatusstring\nThe status of the verify PVC captcha request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Samples Update",
      "path": "voices-pvc-samples-update",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/samples/update",
      "keywords": [
        "endpoint",
        "errors",
        "false",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response",
        "samples"
      ],
      "use_cases": [
        "How to voices pvc samples update",
        "How to list voices pvc samples update",
        "How to update voices pvc samples update"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Update a PVC voice sample - apply noise removal, select speaker, change trim times or file name.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\nsample_idstringRequired\nSample ID to be used\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nremove_background_noisebooleanOptionalDefaults to `false`\nIf set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\nselected_speaker_idslist of strings or nullOptional\nSpeaker IDs to be used for PVC training. Make sure you send all the speaker IDs you want to use for PVC training in one request because the last request will override the previous ones.\ntrim_start_timeinteger or nullOptional\nThe start time of the audio to be used for PVC training. Time should be in milliseconds\ntrim_end_timeinteger or nullOptional\nThe end time of the audio to be used for PVC training. Time should be in milliseconds\nfile_namestring or nullOptional\nThe name of the audio file to be used for PVC training.\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the voice.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Verification Captcha",
      "path": "voices-pvc-verification-captcha",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/verification/captcha",
      "keywords": [
        "captcha",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "pvc",
        "response",
        "verification",
        "voices"
      ],
      "use_cases": [
        "How to voices pvc verification captcha",
        "How to list voices pvc verification captcha"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 7,
      "content": "Get captcha for PVC voice verification.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Pvc Update",
      "path": "voices-pvc-update",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/update",
      "keywords": [
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "pvc",
        "request",
        "response",
        "update",
        "voices"
      ],
      "use_cases": [
        "How to voices pvc update",
        "How to create voices pvc update",
        "How to list voices pvc update"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Edit PVC voice metadata\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnamestringOptional`<=100 characters`\nThe name that identifies this voice. This will be displayed in the dropdown of the website.\nlanguagestringOptional\nLanguage used in the samples.\ndescriptionstring or nullOptional`<=500 characters`\nDescription to use for the created voice.\nlabelsmap from strings to strings or nullOptional\nLabels for the voice. Keys can be language, accent, gender, or age.\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the voice.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Search",
      "path": "voices-search",
      "url": "https://elevenlabs.io/docs/api-reference/voices/search",
      "keywords": [
        "delete",
        "errors",
        "headers",
        "parameters",
        "query",
        "request",
        "response",
        "search",
        "true",
        "voices"
      ],
      "use_cases": [
        "How to voices search",
        "How to create voices search",
        "How to delete voices search",
        "How to list voices search"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 9,
      "content": "Gets a list of all available voices for a user with search, filtering and pagination.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nnext_page_tokenstring or nullOptional\nThe next page token to use for pagination. Returned from the previous request. Use this in combination with the has_more flag for reliable pagination.\npage_sizeintegerOptionalDefaults to `10`\nHow many voices to return at maximum. Can not exceed 100, defaults to 10. Page 0 may include more voices due to default voices being included.\nsearchstring or nullOptional\nSearch term to filter voices by. Searches in name, description, labels, category.\nsortstring or nullOptional\nWhich field to sort by, one of ‘created_at_unix’ or ‘name’. ‘created_at_unix’ may not be available for older voices.\nsort_directionstring or nullOptional\nWhich direction to sort the voices in. 'asc' or 'desc'.\nvoice_typestring or nullOptional\nType of the voice to filter by. One of ‘personal’, ‘community’, ‘default’, ‘workspace’, ‘non-default’, ‘saved’. ‘non-default’ is equal to all but ‘default’. ‘saved’ is equal to non-default, but includes default voices if they have been added to a collection.\ncategorystring or nullOptional\nCategory of the voice to filter by. One of 'premade', 'cloned', 'generated', 'professional'\nfine_tuning_statestring or nullOptional\nState of the voice’s fine tuning to filter by. Applicable only to professional voices clones. One of ‘draft’, ‘not_verified’, ‘not_started’, ‘queued’, ‘fine_tuning’, ‘fine_tuned’, ‘failed’, ‘delayed’\ncollection_idstring or nullOptional\nCollection ID to filter voices by.\ninclude_total_countbooleanOptionalDefaults to `true`\nWhether to include the total count of voices found in the response. NOTE: The total_count value is a live snapshot and may change between requests as users create, modify, or delete voices. For pagination, rely on the has_more flag instead. Only enable this when you actually need the total count (e.g., for display purposes), as it incurs a performance cost.\nvoice_idslist of strings or nullOptional\nVoice IDs to lookup by. Maximum 100 voice IDs.\n### Response\nSuccessful Response\nvoiceslist of objects\nThe list of voices matching the query.\nShow 22 properties\nhas_moreboolean\nIndicates whether there are more voices available in subsequent pages. Use this flag (and next_page_token) for reliable pagination instead of relying on total_count.\ntotal_countinteger\nThe total count of voices matching the query. This value is a live snapshot that reflects the current state of the database and may change between requests as users create, modify, or delete voices. For reliable pagination, use the has_more flag instead of relying on this value. Only request this field when you actually need the total count (e.g., for display purposes), as calculating it incurs a performance cost.\nnext_page_tokenstring or null\nToken to retrieve the next page of results. Pass this value to the next request to continue pagination. Null if there are no more results.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Update",
      "path": "voices-update",
      "url": "https://elevenlabs.io/docs/api-reference/voices/update",
      "keywords": [
        "endpoint",
        "errors",
        "false",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "update"
      ],
      "use_cases": [
        "How to voices update",
        "How to create voices update",
        "How to list voices update"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Edit a voice created by you.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects a multipart form with multiple files.\nnamestringRequired\nThe name that identifies this voice. This will be displayed in the dropdown of the website.\nfilesfilesOptional\nAudio files to add to the voice\nremove_background_noisebooleanOptionalDefaults to `false`\nIf set will remove background noise for voice samples using our audio isolation model. If the samples do not include background noise, it can make the quality worse.\ndescriptionstring or nullOptional\nA description of the voice.\nlabelsmap from strings to strings or string or nullOptional\nLabels for the voice. Keys can be language, accent, gender, or age.\nShow 2 variants\n### Response\nSuccessful Response\nstatusstring\nThe status of the voice edit request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Settings Get Default",
      "path": "voices-settings-get-default",
      "url": "https://elevenlabs.io/docs/api-reference/voices/settings/get-default",
      "keywords": [
        "default",
        "get",
        "headers",
        "response",
        "settings",
        "true",
        "voices"
      ],
      "use_cases": [
        "How to voices settings get default"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Gets the default settings for voices. “similarity_boost” corresponds to”Clarity + Similarity Enhancement” in the web app and “stability” corresponds to “Stability” slider in the web app.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstabilitydouble or null`0-1`Defaults to `0.5`\nDetermines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion.\nuse_speaker_boostboolean or nullDefaults to `true`\nThis setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency.\nsimilarity_boostdouble or null`0-1`Defaults to `0.75`\nDetermines how closely the AI should adhere to the original voice when attempting to replicate it.\nstyledouble or nullDefaults to `0`\nDetermines the style exaggeration of the voice. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0.\nspeeddouble or nullDefaults to `1`\nAdjusts the speed of the voice. A value of 1.0 is the default speed, while values less than 1.0 slow down the speech, and values greater than 1.0 speed it up.\n"
    },
    {
      "title": "Voices Settings Update",
      "path": "voices-settings-update",
      "url": "https://elevenlabs.io/docs/api-reference/voices/settings/update",
      "keywords": [
        "endpoint",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "settings",
        "true"
      ],
      "use_cases": [
        "How to voices settings update",
        "How to list voices settings update"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Edit your settings for a specific voice. “similarity_boost” corresponds to “Clarity + Similarity Enhancement” in the web app and “stability” corresponds to “Stability” slider in the web app.\n### Path parameters\nvoice_idstringRequired\nID of the voice to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nstabilitydouble or nullOptional`0-1`Defaults to `0.5`\nDetermines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion.\nuse_speaker_boostboolean or nullOptionalDefaults to `true`\nThis setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency.\nsimilarity_boostdouble or nullOptional`0-1`Defaults to `0.75`\nDetermines how closely the AI should adhere to the original voice when attempting to replicate it.\nstyledouble or nullOptionalDefaults to `0`\nDetermines the style exaggeration of the voice. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0.\nspeeddouble or nullOptionalDefaults to `1`\nAdjusts the speed of the voice. A value of 1.0 is the default speed, while values less than 1.0 slow down the speech, and values greater than 1.0 speed it up.\n### Response\nSuccessful Response\nstatusstring\nThe status of the voice settings edit request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Whats App Accounts Delete",
      "path": "whats-app-accounts-delete",
      "url": "https://elevenlabs.io/docs/api-reference/whats-app/accounts/delete",
      "keywords": [
        "accounts",
        "app",
        "delete",
        "errors",
        "headers",
        "parameters",
        "path",
        "response",
        "whats"
      ],
      "use_cases": [
        "How to whats app accounts delete",
        "How to delete whats app accounts delete"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Delete a WhatsApp account\n### Path parameters\nphone_number_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Voice Library Get Shared",
      "path": "voices-voice-library-get-shared",
      "url": "https://elevenlabs.io/docs/api-reference/voices/voice-library/get-shared",
      "keywords": [
        "errors",
        "false",
        "get",
        "headers",
        "library",
        "parameters",
        "query",
        "response",
        "shared",
        "voice"
      ],
      "use_cases": [
        "How to voices voice library get shared",
        "How to list voices voice library get shared"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Retrieves a list of shared voices.\n### Headers\nxi-api-keystringRequired\n### Query parameters\npage_sizeintegerOptionalDefaults to `30`\nHow many shared voices to return at maximum. Can not exceed 100, defaults to 30.\ncategoryenumOptional\nVoice category used for filtering\nAllowed values:professionalfamoushigh_quality\ngenderstring or nullOptional\nGender used for filtering\nagestring or nullOptional\nAge used for filtering\naccentstring or nullOptional\nAccent used for filtering\nlanguagestring or nullOptional\nLanguage used for filtering\nlocalestring or nullOptional\nLocale used for filtering\nsearchstring or nullOptional\nSearch term used for filtering\nuse_caseslist of strings or nullOptional\nUse-case used for filtering\ndescriptiveslist of strings or nullOptional\nSearch term used for filtering\nfeaturedbooleanOptionalDefaults to `false`\nFilter featured voices\nmin_notice_period_daysinteger or nullOptional\nFilter voices with a minimum notice period of the given number of days.\ninclude_custom_ratesboolean or nullOptional\nInclude/exclude voices with custom rates\ninclude_live_moderatedboolean or nullOptional\nInclude/exclude voices that are live moderated\nreader_app_enabledbooleanOptionalDefaults to `false`\nFilter voices that are enabled for the reader app\nowner_idstring or nullOptional\nFilter voices by public owner ID\nsortstring or nullOptional\nSort criteria\npageintegerOptionalDefaults to `0`\n### Response\nSuccessful Response\nvoiceslist of objects\nThe list of shared voices\nShow 31 properties\nhas_moreboolean\nWhether there are more shared voices in subsequent pages.\nlast_sort_idstring or null\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Settings Get",
      "path": "voices-settings-get",
      "url": "https://elevenlabs.io/docs/api-reference/voices/settings/get",
      "keywords": [
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "settings",
        "true",
        "voices"
      ],
      "use_cases": [
        "How to voices settings get",
        "How to list voices settings get"
      ],
      "tags": [
        "api-reference",
        "crud",
        "voices"
      ],
      "priority": 7,
      "content": "Returns the settings for a specific voice. “similarity_boost” corresponds to”Clarity + Similarity Enhancement” in the web app and “stability” corresponds to “Stability” slider in the web app.\n### Path parameters\nvoice_idstringRequired\nVoice ID to be used, you can use <https://api.elevenlabs.io/v1/voices> to list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nstabilitydouble or null`0-1`Defaults to `0.5`\nDetermines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion.\nuse_speaker_boostboolean or nullDefaults to `true`\nThis setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency.\nsimilarity_boostdouble or null`0-1`Defaults to `0.75`\nDetermines how closely the AI should adhere to the original voice when attempting to replicate it.\nstyledouble or nullDefaults to `0`\nDetermines the style exaggeration of the voice. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0.\nspeeddouble or nullDefaults to `1`\nAdjusts the speed of the voice. A value of 1.0 is the default speed, while values less than 1.0 slow down the speech, and values greater than 1.0 speed it up.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Whats App Accounts Import",
      "path": "whats-app-accounts-import",
      "url": "https://elevenlabs.io/docs/api-reference/whats-app/accounts/import",
      "keywords": [
        "accounts",
        "app",
        "endpoint",
        "errors",
        "headers",
        "import",
        "request",
        "response",
        "whats"
      ],
      "use_cases": [
        "How to whats app accounts import"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Import a WhatsApp account\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nbusiness_account_idstringRequired\nphone_number_idstringRequired\ntoken_codestringRequired\n### Response\nSuccessful Response\nphone_number_idstring\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Voices Voice Library Share",
      "path": "voices-voice-library-share",
      "url": "https://elevenlabs.io/docs/api-reference/voices/voice-library/share",
      "keywords": [
        "endpoint",
        "errors",
        "get",
        "headers",
        "library",
        "parameters",
        "path",
        "request",
        "response",
        "share"
      ],
      "use_cases": [
        "How to voices voice library share",
        "How to list voices voice library share"
      ],
      "tags": [
        "api-reference",
        "voices"
      ],
      "priority": 7,
      "content": "Add a shared voice to your collection of Voices\n### Path parameters\npublic_user_idstringRequired\nPublic user ID used to publicly identify ElevenLabs users.\nvoice_idstringRequired\nID of the voice to be used. You can use the [Get voices](https://elevenlabs.io/docs/api-reference/voices/search) endpoint list all the available voices.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nnew_namestringRequired\nThe name that identifies this voice. This will be displayed in the dropdown of the website.\n### Response\nSuccessful Response\nvoice_idstring\nThe ID of the voice.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Whats App Accounts Get",
      "path": "whats-app-accounts-get",
      "url": "https://elevenlabs.io/docs/api-reference/whats-app/accounts/get",
      "keywords": [
        "accounts",
        "app",
        "errors",
        "get",
        "headers",
        "parameters",
        "path",
        "response",
        "whats"
      ],
      "use_cases": [
        "How to whats app accounts get"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Get a WhatsApp account\n### Path parameters\nphone_number_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nbusiness_account_idstring\nphone_number_idstring\nbusiness_account_namestring\nphone_number_namestring\nphone_numberstring\nassigned_agent_namestring or null\nassigned_agent_idstring or null\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Whats App Accounts List",
      "path": "whats-app-accounts-list",
      "url": "https://elevenlabs.io/docs/api-reference/whats-app/accounts/list",
      "keywords": [
        "accounts",
        "app",
        "errors",
        "headers",
        "list",
        "response",
        "whats"
      ],
      "use_cases": [
        "How to whats app accounts list",
        "How to list whats app accounts list"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "List all WhatsApp accounts\n### Headers\nxi-api-keystringRequired\n### Response\nSuccessful Response\nitemslist of objects\nShow 7 properties\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Workspace Groups Search",
      "path": "workspace-groups-search",
      "url": "https://elevenlabs.io/docs/api-reference/workspace/groups/search",
      "keywords": [
        "errors",
        "groups",
        "headers",
        "parameters",
        "query",
        "response",
        "search",
        "workspace"
      ],
      "use_cases": [
        "How to workspace groups search",
        "How to list workspace groups search"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 3,
      "content": "Searches for user groups in the workspace. Multiple or no groups may be returned.\n### Headers\nxi-api-keystringRequired\n### Query parameters\nnamestringRequired\nName of the target group.\n### Response\nSuccessful Response\nnamestring\nThe name of the workspace group.\nidstring\nThe ID of the workspace group.\nmembers_emailslist of strings\nThe emails of the members of the workspace group.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Whats App Accounts Update",
      "path": "whats-app-accounts-update",
      "url": "https://elevenlabs.io/docs/api-reference/whats-app/accounts/update",
      "keywords": [
        "accounts",
        "app",
        "endpoint",
        "errors",
        "headers",
        "parameters",
        "path",
        "request",
        "response",
        "update"
      ],
      "use_cases": [
        "How to whats app accounts update",
        "How to update whats app accounts update"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 5,
      "content": "Update a WhatsApp account\n### Path parameters\nphone_number_idstringRequired\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nassigned_agent_idstring or nullOptional\n### Response\nSuccessful Response\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Workspace Invites Create",
      "path": "workspace-invites-create",
      "url": "https://elevenlabs.io/docs/api-reference/workspace/invites/create",
      "keywords": [
        "create",
        "endpoint",
        "errors",
        "headers",
        "invites",
        "request",
        "response",
        "workspace"
      ],
      "use_cases": [
        "How to workspace invites create",
        "How to create workspace invites create",
        "How to list workspace invites create"
      ],
      "tags": [
        "api-reference",
        "crud"
      ],
      "priority": 3,
      "content": "Sends an email invitation to join your workspace to the provided email. If the user doesn't have an account they will be prompted to create one. If the user accepts this invite they will be added as a user to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators. If the user is already in the workspace a 400 error will be returned.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nemailstringRequired\nThe email of the customer\ngroup_idslist of strings or nullOptional\nThe group ids of the user\nworkspace_permissionenum or nullOptional\nThe workspace permission of the user\nShow 18 enum values\n### Response\nSuccessful Response\nstatusstring\nThe status of the workspace invite request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Workspace Groups Members Add",
      "path": "workspace-groups-members-add",
      "url": "https://elevenlabs.io/docs/api-reference/workspace/groups/members/add",
      "keywords": [
        "add",
        "endpoint",
        "errors",
        "groups",
        "headers",
        "members",
        "parameters",
        "path",
        "request",
        "response"
      ],
      "use_cases": [
        "How to workspace groups members add"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 3,
      "content": "Adds a member of your workspace to the specified group. This endpoint may only be called by workspace administrators.\n### Path parameters\ngroup_idstringRequired\nThe ID of the target group.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nemailstringRequired\nThe email of the target workspace member.\n### Response\nSuccessful Response\nstatusstring\nThe status of the workspace group member addition request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Whats App Outbound Call",
      "path": "whats-app-outbound-call",
      "url": "https://elevenlabs.io/docs/api-reference/whats-app/outbound-call",
      "keywords": [
        "app",
        "call",
        "endpoint",
        "errors",
        "headers",
        "outbound",
        "request",
        "response",
        "whats"
      ],
      "use_cases": [
        "How to whats app outbound call"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 5,
      "content": "Make an outbound call via WhatsApp\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nwhatsapp_phone_number_idstringRequired\nwhatsapp_user_idstringRequired\nwhatsapp_call_permission_request_template_namestringRequired\nwhatsapp_call_permission_request_template_language_codestringRequired\nagent_idstringRequired\nconversation_initiation_client_dataobject or nullOptional\nShow 5 properties\n### Response\nSuccessful Response\nsuccessboolean\nmessagestring\nconversation_idstring or null\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Workspace Groups Members Remove",
      "path": "workspace-groups-members-remove",
      "url": "https://elevenlabs.io/docs/api-reference/workspace/groups/members/remove",
      "keywords": [
        "endpoint",
        "errors",
        "groups",
        "headers",
        "members",
        "parameters",
        "path",
        "remove",
        "request",
        "response"
      ],
      "use_cases": [
        "How to workspace groups members remove"
      ],
      "tags": [
        "api-reference"
      ],
      "priority": 3,
      "content": "Removes a member from the specified group. This endpoint may only be called by workspace administrators.\n### Path parameters\ngroup_idstringRequired\nThe ID of the target group.\n### Headers\nxi-api-keystringRequired\n### Request\nThis endpoint expects an object.\nemailstringRequired\nThe email of the target workspace member.\n### Response\nSuccessful Response\nstatusstring\nThe status of the workspace group member deletion request. If the request was successful, the status will be 'ok'. Otherwise an error message with status 500 will be returned.\n### Errors\n422\nUnprocessable Entity Error\n"
    },
    {
      "title": "Error Messages",
      "path": "developers-resources-error-messages",
      "url": "https://elevenlabs.io/docs/developers/resources/error-messages",
      "keywords": [
        "error",
        "errors",
        "400",
        "401",
        "403",
        "429",
        "invalid_api_key",
        "quota_exceeded",
        "voice_not_found",
        "too_many_concurrent_requests",
        "system_busy",
        "max_character_limit_exceeded",
        "http",
        "status",
        "troubleshooting"
      ],
      "use_cases": [
        "How to handle API errors",
        "How to fix authentication errors",
        "How to handle rate limit errors",
        "How to fix validation errors",
        "How to troubleshoot API issues"
      ],
      "tags": [
        "errors",
        "api-reference",
        "troubleshooting"
      ],
      "priority": 10,
      "content": "This guide includes an overview of error messages you might see in the ElevenLabs dashboard & API.\n\n## Dashboard errors\n\n| Error Message | Cause | Solution |\n| --- | --- | --- |\n| The selected model can not be used for text-to-speech. | Occurs when switching between speech-to-speech and text-to-speech if the model does not switch correctly. | Select the desired model. If unresolved, select a different model, then switch back. |\n| Oops, something went wrong. | Indicates a client-side error, often due to device or browser issues. | Click \"Try again\" or refresh the page. If unresolved, clear browser cache and cookies. Temporarily pause browser-based translation tools like Google Translate. |\n\n## API errors\n\n### Code 400/401\n\n| Code | Overview |\n| --- | --- |\n| max_character_limit_exceeded | **Cause:** You are sending too many characters in a single request. **Solution:** Split the request into smaller chunks, see character limits for more information. |\n| invalid_api_key | **Cause:** You have not set your API key correctly. **Solution:** Ensure the request is correctly authenticated. See authentication for more information. |\n| quota_exceeded | **Cause:** You have insufficient quota to complete the request. **Solution:** On the Creator plan and above, you can enable usage-based billing from your Subscription page. |\n| voice_not_found | **Cause:** You have entered the incorrect voice_id. **Solution:** Check that you are using the correct voice_id for the voice you want to use. You can verify this in My Voices. |\n\n### Code 403\n\n| Code | Overview |\n| --- | --- |\n| only_for_creator+ | **Cause:** You are trying to use professional voices on a free or basic subscription. **Solution:** Upgrade to Creator tier or higher to access professional voices. |\n\n### Code 429\n\n| Code | Overview |\n| --- | --- |\n| too_many_concurrent_requests | **Cause:** You have exceeded the concurrency limit for your subscription. **Solution:** See concurrency limits and priority for more information. |\n| system_busy | **Cause:** Our services are experiencing high levels of traffic and your request could not be processed. **Solution:** Retry the request later, with exponential backoff. Consider upgrading your subscription to get higher priority. |"
    },
    {
      "title": "Models",
      "path": "overview-models",
      "url": "https://elevenlabs.io/docs/overview/models",
      "keywords": [
        "model",
        "models",
        "eleven_v3",
        "eleven_multilingual_v2",
        "eleven_flash_v2_5",
        "eleven_turbo_v2_5",
        "scribe_v2",
        "tts",
        "stt",
        "speech-to-text",
        "text-to-speech",
        "latency",
        "concurrency",
        "rate-limit",
        "character-limit"
      ],
      "use_cases": [
        "How to choose the right model",
        "How to understand model capabilities",
        "How to check model latency",
        "How to understand concurrency limits",
        "How to check character limits"
      ],
      "tags": [
        "models",
        "api-reference",
        "rate-limits"
      ],
      "priority": 10,
      "content": "## Models overview\n\nThe ElevenLabs API offers a range of audio models optimized for different use cases, quality levels, and performance requirements.\n\n| Model ID | Description | Languages |\n| --- | --- | --- |\n| `eleven_v3` | Human-like and expressive speech generation | 70+ languages |\n| `eleven_multilingual_v2` | Our most lifelike model with rich emotional expression | 29 languages |\n| `eleven_flash_v2_5` | Ultra-fast model optimized for real-time use (~75ms) | 32 languages |\n| `eleven_turbo_v2_5` | High quality, low-latency model (~250ms-300ms) | 32 languages |\n| `scribe_v2` | State-of-the-art speech recognition model | 90+ languages |\n| `scribe_v2_realtime` | Real-time speech recognition model (~150ms) | 90+ languages |\n\n## Character limits\n\n| Model ID | Character limit | Approximate audio duration |\n| --- | --- | --- |\n| `eleven_v3` | 5,000 | ~5 minutes |\n| `eleven_flash_v2_5` | 40,000 | ~40 minutes |\n| `eleven_turbo_v2_5` | 40,000 | ~40 minutes |\n| `eleven_multilingual_v2` | 10,000 | ~10 minutes |\n\n## Concurrency and priority\n\nYour subscription plan determines how many requests can be processed simultaneously and the priority level of your requests in the queue.\n\n| Plan | Concurrency Limit (Multilingual v2) | Concurrency Limit (Turbo & Flash) | STT Concurrency Limit | Priority level |\n| --- | --- | --- | --- | --- |\n| Free | 2 | 4 | 8 | 3 |\n| Starter | 3 | 6 | 12 | 4 |\n| Creator | 5 | 10 | 20 | 5 |\n| Pro | 10 | 20 | 40 | 5 |\n| Scale | 15 | 30 | 60 | 5 |\n| Business | 15 | 30 | 60 | 5 |\n| Enterprise | Elevated | Elevated | Elevated | 6 |\n\nThe response headers include `current-concurrent-requests` and `maximum-concurrent-requests` which you can use to monitor your concurrency.\n\n### Understanding concurrency limits\n\nThe concurrency limit should not be interpreted as the maximum number of simultaneous conversations. As a general rule, a concurrency limit of 5 can typically support up to approximately 100 simultaneous audio broadcasts."
    },
    {
      "title": "Burst Pricing",
      "path": "agents-platform-guides-burst-pricing",
      "url": "https://elevenlabs.io/docs/agents-platform/guides/burst-pricing",
      "keywords": [
        "burst",
        "pricing",
        "concurrency",
        "rate-limit",
        "throttle",
        "capacity",
        "agents",
        "calls",
        "limit",
        "exceeded"
      ],
      "use_cases": [
        "How to handle rate limit exceeded",
        "How to use burst pricing for higher concurrency",
        "How to configure burst pricing",
        "How to handle traffic spikes"
      ],
      "tags": [
        "rate-limits",
        "pricing",
        "agents"
      ],
      "priority": 10,
      "content": "## Overview\n\nBurst pricing allows your ElevenLabs agents to temporarily exceed your workspace's subscription concurrency limit during high-demand periods. When enabled, your agents can handle up to 3 times your normal concurrency limit, with excess calls charged at double the standard rate.\n\n## How burst pricing works\n\n1. **Normal capacity**: Calls within your subscription limit are charged at standard rates\n2. **Burst capacity**: Additional calls (up to 3x your usual limit or 300, whichever is lower) are accepted but charged at 2x the normal rate\n3. **Over-capacity rejection**: Calls exceeding the burst limit are rejected with an error\n\n### Capacity calculations\n\n| Subscription limit | Burst capacity | Maximum concurrent calls |\n| --- | --- | --- |\n| 10 calls | 30 calls | 30 calls |\n| 50 calls | 150 calls | 150 calls |\n| 100 calls | 300 calls | 300 calls |\n| 200 calls | 300 calls | 300 calls (capped) |\n\n## Cost implications\n\n- **Within subscription limit**: Standard per-minute rates apply\n- **Burst calls**: Charged at 2x the standard rate\n- **Deprioritized processing**: Burst calls receive lower priority for speech processing\n\n## Configuration\n\n### Dashboard configuration\n\n1. Navigate to your agent settings\n2. Go to the **Call Limits** section\n3. Enable the **Burst pricing** toggle\n4. Save your agent configuration\n\n### API configuration\n\n```python\nfrom elevenlabs.client import ElevenLabs\n\nelevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n\nresponse = elevenlabs.conversational_ai.agents.update(\n    agent_id=\"your-agent-id\",\n    agent_config={\n        \"platform_settings\": {\n            \"call_limits\": {\n                \"agent_concurrency_limit\": -1,\n                \"daily_limit\": 1000,\n                \"bursting_enabled\": True\n            }\n        }\n    }\n)\n```"
    },
    {
      "title": "Agent Authentication",
      "path": "agents-platform-customization-authentication",
      "url": "https://elevenlabs.io/docs/agents-platform/customization/authentication",
      "keywords": [
        "authentication",
        "auth",
        "signed-url",
        "allowlist",
        "security",
        "token",
        "websocket",
        "agent",
        "oauth",
        "hmac"
      ],
      "use_cases": [
        "How to authenticate agents",
        "How to use signed URLs for client-side authentication",
        "How to configure allowlists",
        "How to secure agent access"
      ],
      "tags": [
        "security",
        "authentication",
        "agents"
      ],
      "priority": 10,
      "content": "## Overview\n\nWhen building conversational agents, you may need to restrict access to certain agents or conversations. ElevenLabs provides multiple authentication mechanisms to ensure only authorized users can interact with your agents.\n\n## Authentication methods\n\n- **Signed URLs**: Generate temporary authenticated URLs for secure client-side connections without exposing API keys.\n- **Allowlists**: Restrict access to specific domains or hostnames that can connect to your agent.\n\n## Using signed URLs\n\nSigned URLs are the recommended approach for client-side applications.\n\n### How signed URLs work\n\n1. Your server requests a signed URL from ElevenLabs using your API key.\n2. ElevenLabs generates a temporary token and returns a signed WebSocket URL.\n3. Your client application uses this signed URL to establish a WebSocket connection.\n4. The signed URL expires after 15 minutes.\n\n### Generate a signed URL via the API\n\n```python\nfrom elevenlabs.client import ElevenLabs\n\nasync def get_signed_url():\n    elevenlabs = ElevenLabs(api_key=\"your-api-key\")\n    response = await elevenlabs.conversational_ai.conversations.get_signed_url(agent_id=\"your-agent-id\")\n    return response.signed_url\n```\n\nThe response has the format:\n```json\n{\n  \"signed_url\": \"wss://api.elevenlabs.io/v1/convai/conversation?agent_id=your-agent-id&conversation_signature=your-token\"\n}\n```\n\n## Using allowlists\n\nAllowlists provide a way to restrict access to your conversational agents based on the origin domain.\n\n### Example: setting up an allowlist\n\n```python\nfrom elevenlabs.client import ElevenLabs\nfrom elevenlabs.types import *\n\nelevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n\nagent = elevenlabs.conversational_ai.agents.create(\n  conversation_config=ConversationalConfig(\n    agent=AgentConfig(\n      first_message=\"Hi. I'm an authenticated agent.\",\n    )\n  ),\n  platform_settings=AgentPlatformSettingsRequestModel(\n    auth=AuthSettings(\n      enable_auth=False,\n      allowlist=[\n        AllowlistItem(hostname=\"example.com\"),\n        AllowlistItem(hostname=\"app.example.com\"),\n        AllowlistItem(hostname=\"localhost:3000\")\n      ]\n    )\n  )\n)\n```\n\n## Combining authentication methods\n\nFor maximum security, you can combine both authentication methods:\n\n1. Use `enable_auth` to require signed URLs.\n2. Configure an allowlist to restrict which domains can request those signed URLs."
    },
    {
      "title": "Voice Cloning Overview",
      "path": "creative-platform-voices-voice-cloning",
      "url": "https://elevenlabs.io/docs/creative-platform/voices/voice-cloning",
      "keywords": [
        "voice",
        "cloning",
        "ivc",
        "pvc",
        "instant",
        "professional",
        "clone",
        "audio",
        "recording",
        "microphone",
        "sample"
      ],
      "use_cases": [
        "How to clone a voice",
        "How to choose between IVC and PVC",
        "How to prepare audio samples",
        "How to record high-quality voice samples"
      ],
      "tags": [
        "voice",
        "guide",
        "getting-started"
      ],
      "priority": 8,
      "content": "## Overview\n\nWhen cloning a voice, there are two main options: Instant Voice Cloning (IVC) and Professional Voice Cloning (PVC). IVC is a quick and easy way to clone your voice, while PVC is a more accurate and customizable option.\n\n## Instant Voice Cloning\n\nIVC allows you to create voice clones from shorter samples near instantaneously. Creating an instant voice clone does not train or create a custom AI model. Instead, it relies on prior knowledge from training data to make an educated guess.\n\nThe biggest limitation of IVC is if you are trying to clone a very unique voice with a very unique accent where the AI might not have heard similar voices before during training.\n\n## Professional Voice Cloning\n\nA PVC is a special feature available to Creator+ plans. PVC allows you to train a hyper-realistic model of a voice by training a dedicated model on a large set of voice data.\n\nTraining time estimates:\n- **English:** ~3 hours\n- **Multilingual:** ~6 hours\n\n## Beginner's guide to audio recording\n\n### Recording location\nChoose a suitable location to minimize room echo/reverb. Consider a DIY vocal booth or closet with acoustic treatment.\n\n### Microphone setup\nA professional XLR microphone costing $150 to $300 is sufficient. Consider a Focusrite interface paired with an Audio-Technica AT2020 or Rode NT1 microphone.\n\nEnsure you have a proper pop-filter in front of the microphone to avoid plosives.\n\n### Recording levels\nMaintain optimal recording levels (not too loud or too quiet). Aim for peaks of -6 dB to -3 dB and an average loudness of -18 dB.\n\n### Positioning\nMaintain a distance of about two fists (20cm) from the microphone with a pop filter between you and the microphone.\n\n### Performance\nThe AI will try to clone everything about your voice including cadence, tonality, and performance style. Consistency is key to a proper clone - keep the same accent and animation level throughout the recording."
    },
    {
      "title": "Instant Voice Cloning Quickstart",
      "path": "developers-guides-cookbooks-voices-instant-voice-cloning",
      "url": "https://elevenlabs.io/docs/developers/guides/cookbooks/voices/instant-voice-cloning",
      "keywords": [
        "ivc",
        "instant",
        "voice",
        "cloning",
        "clone",
        "api",
        "sdk",
        "python",
        "typescript",
        "audio",
        "file"
      ],
      "use_cases": [
        "How to create an instant voice clone",
        "How to use the IVC API",
        "How to upload voice samples"
      ],
      "tags": [
        "voice",
        "guide",
        "ivc",
        "api-reference"
      ],
      "priority": 8,
      "content": "This guide shows how to create an Instant Voice Clone using the Clone Voice API.\n\n## Using the Instant Voice Clone API\n\n### 1. Create an API key\n\nCreate an API key in the dashboard, which you'll use to securely access the API.\n\n```env\nELEVENLABS_API_KEY=<your_api_key_here>\n```\n\n### 2. Install the SDK\n\n```bash\npip install elevenlabs\npip install python-dotenv\n```\n\n### 3. Make the API request\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom elevenlabs.client import ElevenLabs\nfrom io import BytesIO\n\nload_dotenv()\n\nelevenlabs = ElevenLabs(\n  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n)\n\nvoice = elevenlabs.voices.ivc.create(\n    name=\"My Voice Clone\",\n    # Replace with the paths to your audio files.\n    # The more files you add, the better the clone will be.\n    files=[BytesIO(open(\"/path/to/your/audio/file.mp3\", \"rb\").read())]\n)\n\nprint(voice.voice_id)\n```\n\n### 4. Execute the code\n\n```bash\npython example.py\n```\n\nYou should see the voice ID printed to the console."
    },
    {
      "title": "Professional Voice Cloning Quickstart",
      "path": "developers-guides-cookbooks-voices-professional-voice-cloning",
      "url": "https://elevenlabs.io/docs/developers/guides/cookbooks/voices/professional-voice-cloning",
      "keywords": [
        "pvc",
        "professional",
        "voice",
        "cloning",
        "clone",
        "api",
        "sdk",
        "training",
        "verification",
        "captcha",
        "speaker",
        "separation"
      ],
      "use_cases": [
        "How to create a professional voice clone",
        "How to use the PVC API",
        "How to verify voice ownership",
        "How to train a custom voice model"
      ],
      "tags": [
        "voice",
        "guide",
        "pvc",
        "api-reference"
      ],
      "priority": 8,
      "content": "This guide shows how to create a Professional Voice Clone (PVC) using the PVC API.\n\nCreating a PVC requires you to be on the Creator plan or above.\n\n## Using the Professional Voice Clone API\n\n### 1. Create a PVC voice\n\n```python\nfrom elevenlabs.client import ElevenLabs\n\nelevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n\nvoice = elevenlabs.voices.pvc.create(\n    name=\"My Professional Voice Clone\",\n    language=\"en\",\n    description=\"A professional voice clone of my voice\"\n)\n```\n\n### 2. Upload audio files\n\n```python\nsamples = elevenlabs.voices.pvc.samples.create(\n    voice_id=voice.voice_id,\n    files=files_to_upload\n)\n```\n\n### 3. Begin speaker separation\n\nThis step separates the audio files into individual speakers (required for multi-speaker audio).\n\n```python\nfor sample in samples:\n    elevenlabs.voices.pvc.samples.speakers.separate(\n        voice_id=voice.voice_id,\n        sample_id=sample.sample_id\n    )\n```\n\n### 4. Update samples with speaker IDs\n\n```python\nelevenlabs.voices.pvc.samples.update(\n    voice_id=voice.voice_id,\n    sample_id=sample.sample_id,\n    selected_speaker_ids=[speaker.speaker_id]\n)\n```\n\n### 5. Verify the PVC\n\nBefore training can begin, a verification step is required:\n\n```python\n# Get CAPTCHA\ncaptcha_response = elevenlabs.voices.pvc.verification.captcha.get(voice.voice_id)\n\n# Submit recording\nelevenlabs.voices.pvc.verification.captcha.verify(\n    voice_id=voice.voice_id,\n    recording=open('path/to/recording.mp3', 'rb')\n)\n```\n\n### 6. Train the PVC\n\n```python\nelevenlabs.voices.pvc.train(\n    voice_id=voice.voice_id,\n    model_id=\"eleven_multilingual_v2\"\n)\n```\n\nTraining will take approximately 3-6 hours depending on the model."
    },
    {
      "title": "Streaming Text to Speech",
      "path": "developers-guides-cookbooks-text-to-speech-streaming",
      "url": "https://elevenlabs.io/docs/developers/guides/cookbooks/text-to-speech/streaming",
      "keywords": [
        "streaming",
        "tts",
        "text-to-speech",
        "audio",
        "stream",
        "convert",
        "api",
        "websocket",
        "real-time",
        "latency"
      ],
      "use_cases": [
        "How to stream audio responses",
        "How to convert text to speech",
        "How to save audio to file",
        "How to stream audio in real-time"
      ],
      "tags": [
        "streaming",
        "guide",
        "tts",
        "api-reference"
      ],
      "priority": 7,
      "content": "In this tutorial, you'll learn how to convert text to speech with the ElevenLabs SDK, including generating speech as a file and streaming the response.\n\n## Convert text to speech (file)\n\n```python\nimport os\nimport uuid\nfrom dotenv import load_dotenv\nfrom elevenlabs import VoiceSettings\nfrom elevenlabs.client import ElevenLabs\n\nload_dotenv()\n\nelevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n\ndef text_to_speech_file(text: str) -> str:\n    response = elevenlabs.text_to_speech.convert(\n        voice_id=\"pNInz6obpgDQGcFmaJgB\",  # Adam pre-made voice\n        output_format=\"mp3_22050_32\",\n        text=text,\n        model_id=\"eleven_turbo_v2_5\",\n        voice_settings=VoiceSettings(\n            stability=0.0,\n            similarity_boost=1.0,\n            style=0.0,\n            use_speaker_boost=True,\n            speed=1.0,\n        ),\n    )\n\n    save_file_path = f\"{uuid.uuid4()}.mp3\"\n    with open(save_file_path, \"wb\") as f:\n        for chunk in response:\n            if chunk:\n                f.write(chunk)\n\n    return save_file_path\n```\n\n## Convert text to speech (streaming)\n\n```python\nfrom io import BytesIO\n\ndef text_to_speech_stream(text: str) -> IO[bytes]:\n    response = elevenlabs.text_to_speech.stream(\n        voice_id=\"pNInz6obpgDQGcFmaJgB\",\n        output_format=\"mp3_22050_32\",\n        text=text,\n        model_id=\"eleven_multilingual_v2\",\n        voice_settings=VoiceSettings(\n            stability=0.0,\n            similarity_boost=1.0,\n            style=0.0,\n            use_speaker_boost=True,\n            speed=1.0,\n        ),\n    )\n\n    audio_stream = BytesIO()\n    for chunk in response:\n        if chunk:\n            audio_stream.write(chunk)\n\n    audio_stream.seek(0)\n    return audio_stream\n```"
    },
    {
      "title": "Speech to Text Webhooks",
      "path": "developers-guides-cookbooks-speech-to-text-webhooks",
      "url": "https://elevenlabs.io/docs/developers/guides/cookbooks/speech-to-text/batch/webhooks",
      "keywords": [
        "webhooks",
        "webhook",
        "stt",
        "speech-to-text",
        "async",
        "notification",
        "callback",
        "transcription"
      ],
      "use_cases": [
        "How to configure webhooks",
        "How to receive webhook notifications",
        "How to handle async transcription results"
      ],
      "tags": [
        "webhooks",
        "guide",
        "stt",
        "api-reference"
      ],
      "priority": 7,
      "content": "## Overview\n\nWebhooks allow you to receive automatic notifications when your Speech to Text transcription tasks are completed, eliminating the need to continuously poll the API for status updates.\n\n## Using webhooks\n\n### 1. Create a webhook endpoint\n\nCreate a webhook in the ElevenLabs dashboard. Navigate to your webhooks settings and click \"Create Webhook\".\n\nConfigure your webhook with:\n- **Name**: A descriptive name for your webhook\n- **Callback URL**: Your publicly accessible HTTPS endpoint\n- **Webhook Auth Method**: Either `HMAC` or `OAuth`\n\n### 2. Associate webhook with transcription tasks\n\nIn the dashboard, navigate to the webhook events section and link your webhooks to speech-to-text events.\n\n### 3. Make API calls with webhook parameter enabled\n\n```python\nfrom elevenlabs.client import ElevenLabs\n\nelevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n\ndef transcribe_with_webhook(audio_file):\n    result = elevenlabs.speech_to_text.convert(\n        file=audio_file,\n        model_id=\"scribe_v2\",\n        webhook=True,\n    )\n    print(f\"Transcription started: {result.request_id}\")\n    return result\n```\n\n## Webhook payload\n\n```json\n{\n  \"type\": \"speech_to_text_transcription\",\n  \"data\": {\n    \"request_id\": \"some-request-id-123\",\n    \"webhook_metadata\": {},\n    \"transcription\": {\n      \"language_code\": \"en\",\n      \"language_probability\": 0.98,\n      \"text\": \"Hello world!\",\n      \"words\": [\n        {\"text\": \"Hello\", \"start\": 0.0, \"end\": 0.5, \"type\": \"word\", \"speaker_id\": \"speaker_1\"},\n        {\"text\": \"world!\", \"start\": 0.5, \"end\": 1.2, \"type\": \"word\", \"speaker_id\": \"speaker_1\"}\n      ]\n    }\n  }\n}\n```\n\n## Security considerations\n\n- Always verify webhook signatures using `elevenlabs.webhooks.constructEvent()`\n- Webhook URLs must use HTTPS\n- Implement rate limiting on your webhook endpoint\n- Return appropriate HTTP status codes (200-299 for success)"
    },
    {
      "title": "Speech to Text Overview",
      "path": "overview-capabilities-speech-to-text",
      "url": "https://elevenlabs.io/docs/overview/capabilities/speech-to-text",
      "keywords": [
        "stt",
        "speech-to-text",
        "transcription",
        "scribe",
        "language",
        "diarization",
        "timestamp",
        "realtime",
        "keyterm",
        "entity"
      ],
      "use_cases": [
        "How to transcribe audio",
        "How to use speech to text API",
        "How to detect speakers in audio",
        "How to get word timestamps"
      ],
      "tags": [
        "stt",
        "guide",
        "api-reference"
      ],
      "priority": 7,
      "content": "## Overview\n\nThe ElevenLabs Speech to Text (STT) API turns spoken audio into text with state of the art accuracy. The Scribe v2 model adapts to textual cues across 90+ languages and multiple voice styles.\n\n## Models\n\n| Model | Features |\n| --- | --- |\n| Scribe v2 | Accurate transcription in 90+ languages, keyterm prompting, entity detection, speaker diarization (up to 48 speakers), word-level timestamps |\n| Scribe v2 Realtime | Real-time transcription, 90+ languages, ~150ms latency, word-level timestamps |\n\n## Advanced features\n\n### Keyterm prompting\n\nHighlight up to 100 words or phrases to bias the model towards transcribing them. Useful for product names, names, or specific terms.\n\n### Entity detection\n\nDetect several categories of entities in the transcript with exact timestamps: credit card numbers, names, medical conditions, SSNs.\n\n## Supported formats\n\n**Audio formats**: aac, aiff, ogg, mpeg, mp3, opus, wav, webm, flac, m4a\n\n**Video formats**: mp4, avi, matroska, quicktime, wmv, flv, webm, mpeg, 3gpp\n\n**Limits**: Files up to 3 GB and up to 10 hours in duration.\n\n## Concurrency\n\nFor Speech to Text, files over 8 minutes are transcribed in parallel internally. The audio is chunked into up to four segments to be transcribed concurrently.\n\n## FAQ\n\n- **Video files supported?** Yes, both audio and video files work.\n- **Webhooks?** Yes, async results can be sent to configured webhooks.\n- **Multichannel?** Yes, supports up to 5 channels with independent speaker IDs."
    },
    {
      "title": "Error Handling Overview",
      "path": "error-handling-overview",
      "url": "https://elevenlabs.io/docs/api-reference",
      "keywords": [
        "error",
        "errors",
        "422",
        "401",
        "429",
        "rate-limit",
        "http-status",
        "exception",
        "handling",
        "troubleshooting"
      ],
      "use_cases": [
        "How to handle API errors",
        "What HTTP status codes does ElevenLabs return",
        "How to handle 422 Unprocessable Entity errors",
        "How to handle authentication errors",
        "What are the common error responses"
      ],
      "tags": [
        "errors",
        "api-reference",
        "troubleshooting"
      ],
      "priority": 10,
      "content": "## HTTP Error Codes\n\nThe ElevenLabs API uses standard HTTP status codes to indicate success or failure of requests.\n\n### Common Error Responses\n\n| Status Code | Error Type | Description |\n| --- | --- | --- |\n| 401 | Unauthorized | Invalid or missing API key. Check your `xi-api-key` header. |\n| 403 | Forbidden | API key doesn't have permission for this resource/action. |\n| 404 | Not Found | Resource (voice, agent, project) doesn't exist. |\n| 422 | Unprocessable Entity | Request validation failed. Check request body/parameters. |\n| 429 | Too Many Requests | Rate limit exceeded. Implement exponential backoff. |\n| 500 | Internal Server Error | Server-side error. Retry with backoff. |\n| 503 | Service Unavailable | Service temporarily unavailable. Retry later. |\n\n### 422 Unprocessable Entity Error\n\nMost ElevenLabs API endpoints return 422 for validation errors. Common causes:\n\n- Invalid `voice_id` format or non-existent voice\n- Text exceeds maximum length\n- Invalid `model_id`\n- Unsupported `language_code` for the selected model\n- Invalid audio file format\n- Missing required fields in request body\n\n### Authentication Errors (401)\n\n- API key is missing from `xi-api-key` header\n- API key is invalid or revoked\n- API key doesn't have required scope for the endpoint\n- Single-use token has expired\n\n### Tracking Requests\n\nAccess response headers to track requests and debug issues:\n\n```python\nfrom elevenlabs.client import ElevenLabs\n\nclient = ElevenLabs(api_key=\"your_api_key\")\n\nresponse = client.text_to_speech.with_raw_response.convert(\n    text=\"Hello, world!\",\n    voice_id=\"voice_id\"\n)\n\n# Access headers for debugging\nrequest_id = response.headers.get(\"request-id\")  # Use this for support tickets\nchar_cost = response.headers.get(\"x-character-count\")\n```"
    },
    {
      "title": "WebSocket Error Events",
      "path": "websocket-error-events",
      "url": "https://elevenlabs.io/docs/developers/guides/cookbooks/speech-to-text/realtime/event-reference",
      "keywords": [
        "websocket",
        "error",
        "events",
        "realtime",
        "rate-limit",
        "quota",
        "auth",
        "throttle",
        "connection"
      ],
      "use_cases": [
        "How to handle WebSocket errors",
        "What errors can occur in realtime STT",
        "How to handle rate limiting in WebSockets",
        "How to handle quota exceeded errors",
        "What is commit_throttled error"
      ],
      "tags": [
        "websocket",
        "errors",
        "stt",
        "realtime"
      ],
      "priority": 10,
      "content": "## WebSocket Error Types\n\nWhen using WebSocket APIs (Realtime STT, TTS streaming, Agents), errors are returned as messages before the connection is closed.\n\n### Realtime Speech-to-Text Errors\n\n| Error Type | Description | Resolution |\n| --- | --- | --- |\n| `auth_error` | Authentication failed | Double check your API key |\n| `quota_exceeded` | Usage quota exceeded | Upgrade plan or wait for quota reset |\n| `transcriber_error` | Transcription processing error | Retry the request |\n| `input_error` | Invalid input format/parameters | Check audio format and parameters |\n| `error` | Generic server error | Retry with backoff |\n| `commit_throttled` | Too many commit requests | Reduce commit frequency |\n| `unaccepted_terms` | Terms of service not accepted | Accept ToS in ElevenLabs dashboard |\n| `rate_limited` | Too many requests | Reduce request frequency |\n| `queue_overflow` | Processing queue full | Reduce request rate |\n| `resource_exhausted` | Server at capacity | Retry later |\n| `session_time_limit_exceeded` | Max session time reached | Start new session or upgrade |\n| `chunk_size_exceeded` | Audio chunk too large | Reduce chunk size |\n| `insufficient_audio_activity` | Not enough audio activity | Send more audio or close connection |\n\n### WebSocket Connection Best Practices\n\n```javascript\nwebsocket.onmessage = async (event) => {\n  const data = JSON.parse(event.data);\n  \n  // Handle ping to keep connection alive\n  if (data.type === \"ping\") {\n    setTimeout(() => {\n      sendMessage(websocket, {\n        type: \"pong\",\n        event_id: data.ping_event.event_id,\n      });\n    }, data.ping_event.ping_ms);\n  }\n  \n  // Handle errors\n  if (data.type === \"error\") {\n    console.error(`Error: ${data.error_type} - ${data.message}`);\n    // Implement retry logic based on error type\n  }\n};\n```\n\n### TTS WebSocket Parameters\n\n- `inactivity_timeout`: Timeout for inactivity (default: 20s, max: 180s)\n- `auto_mode`: Reduces latency by disabling chunk schedule (recommended for full sentences)"
    },
    {
      "title": "Rate Limits and Throttling",
      "path": "rate-limits-throttling",
      "url": "https://elevenlabs.io/docs/api-reference",
      "keywords": [
        "rate-limit",
        "throttling",
        "429",
        "concurrency",
        "burst",
        "quota",
        "limits",
        "requests-per-minute"
      ],
      "use_cases": [
        "What are ElevenLabs rate limits",
        "How to handle 429 errors",
        "How to avoid rate limiting",
        "What is burst pricing",
        "How many concurrent requests allowed"
      ],
      "tags": [
        "rate-limits",
        "api-reference",
        "errors"
      ],
      "priority": 10,
      "content": "## Rate Limits\n\nElevenLabs applies rate limits based on your subscription tier. Rate limits are applied per API key.\n\n### Handling 429 Too Many Requests\n\nWhen you exceed rate limits, implement exponential backoff:\n\n```python\nimport time\nimport random\n\ndef request_with_backoff(func, max_retries=5):\n    for attempt in range(max_retries):\n        try:\n            return func()\n        except Exception as e:\n            if '429' in str(e) and attempt < max_retries - 1:\n                # Exponential backoff with jitter\n                wait_time = (2 ** attempt) + random.uniform(0, 1)\n                print(f\"Rate limited. Waiting {wait_time:.2f}s...\")\n                time.sleep(wait_time)\n            else:\n                raise\n```\n\n### Concurrency Limits (Agents Platform)\n\nThe Agents Platform has concurrency limits for simultaneous calls:\n\n| Subscription Limit | Burst Capacity | Maximum Concurrent |\n| --- | --- | --- |\n| 10 calls | 30 calls | 30 calls |\n| 50 calls | 150 calls | 150 calls |\n| 100 calls | 300 calls | 300 calls |\n| 200 calls | 300 calls | 300 calls (capped) |\n\n### Burst Pricing\n\nBurst pricing allows temporarily exceeding concurrency limits:\n\n- **Normal capacity**: Standard rates apply\n- **Burst capacity**: Up to 3x normal limit, charged at 2x rate\n- **Over-capacity**: Calls rejected with error\n\n```python\n# Enable burst pricing via API\nelevenlabs.conversational_ai.agents.update(\n    agent_id=\"your-agent-id\",\n    agent_config={\n        \"platform_settings\": {\n            \"call_limits\": {\n                \"agent_concurrency_limit\": -1,  # Use workspace limit\n                \"daily_limit\": 1000,\n                \"bursting_enabled\": True\n            }\n        }\n    }\n)\n```\n\n### WebSocket Rate Limits\n\n- `commit_throttled`: Too many manual commit requests in STT\n- `rate_limited`: General rate limit exceeded\n- `queue_overflow`: Processing queue full"
    },
    {
      "title": "Retry Strategies",
      "path": "retry-strategies",
      "url": "https://elevenlabs.io/docs/api-reference",
      "keywords": [
        "retry",
        "backoff",
        "exponential",
        "resilience",
        "error-handling",
        "recovery",
        "fault-tolerance"
      ],
      "use_cases": [
        "How to implement retry logic",
        "Best practices for API resilience",
        "How to handle transient errors",
        "When to retry vs fail"
      ],
      "tags": [
        "best-practices",
        "errors",
        "api-reference"
      ],
      "priority": 9,
      "content": "## Retry Strategies\n\n### When to Retry\n\n| Error Type | Retry? | Strategy |\n| --- | --- | --- |\n| 429 Rate Limited | Yes | Exponential backoff (start 1s, max 30s) |\n| 500 Internal Error | Yes | Exponential backoff, max 3 retries |\n| 503 Service Unavailable | Yes | Exponential backoff with longer delays |\n| 422 Validation Error | No | Fix request and retry once |\n| 401 Unauthorized | No | Fix authentication |\n| 404 Not Found | No | Resource doesn't exist |\n\n### Exponential Backoff Implementation\n\n```python\nimport time\nimport random\nfrom functools import wraps\n\ndef retry_with_backoff(max_retries=5, base_delay=1, max_delay=30):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for attempt in range(max_retries):\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    error_str = str(e)\n                    is_retryable = any(code in error_str for code in ['429', '500', '503'])\n                    \n                    if not is_retryable or attempt == max_retries - 1:\n                        raise\n                    \n                    # Exponential backoff with jitter\n                    delay = min(base_delay * (2 ** attempt), max_delay)\n                    delay += random.uniform(0, delay * 0.1)  # 10% jitter\n                    \n                    print(f\"Attempt {attempt + 1} failed. Retrying in {delay:.2f}s...\")\n                    time.sleep(delay)\n            return None\n        return wrapper\n    return decorator\n\n@retry_with_backoff(max_retries=3)\ndef generate_speech(text, voice_id):\n    return elevenlabs.text_to_speech.convert(\n        text=text,\n        voice_id=voice_id\n    )\n```\n\n### TypeScript Implementation\n\n```typescript\nasync function withRetry<T>(\n  fn: () => Promise<T>,\n  maxRetries = 3,\n  baseDelay = 1000\n): Promise<T> {\n  for (let attempt = 0; attempt < maxRetries; attempt++) {\n    try {\n      return await fn();\n    } catch (error) {\n      const isRetryable = error.status === 429 || error.status >= 500;\n      \n      if (!isRetryable || attempt === maxRetries - 1) {\n        throw error;\n      }\n      \n      const delay = Math.min(baseDelay * Math.pow(2, attempt), 30000);\n      await new Promise(resolve => setTimeout(resolve, delay));\n    }\n  }\n  throw new Error('Max retries exceeded');\n}\n```\n\n### WebSocket Reconnection\n\n```javascript\nfunction createReconnectingWebSocket(url, maxRetries = 5) {\n  let retries = 0;\n  \n  function connect() {\n    const ws = new WebSocket(url);\n    \n    ws.onclose = (event) => {\n      if (!event.wasClean && retries < maxRetries) {\n        const delay = Math.pow(2, retries) * 1000;\n        retries++;\n        setTimeout(connect, delay);\n      }\n    };\n    \n    ws.onopen = () => {\n      retries = 0;  // Reset on successful connection\n    };\n    \n    return ws;\n  }\n  \n  return connect();\n}\n```"
    },
    {
      "title": "Voice Cloning Overview",
      "path": "voice-cloning-overview",
      "url": "https://elevenlabs.io/docs/creative-platform/voices/voice-cloning",
      "keywords": [
        "voice-cloning",
        "ivc",
        "pvc",
        "instant",
        "professional",
        "clone",
        "samples",
        "training"
      ],
      "use_cases": [
        "What is the difference between IVC and PVC",
        "How to clone a voice",
        "When to use instant vs professional voice cloning",
        "How long does voice cloning take"
      ],
      "tags": [
        "voice-cloning",
        "guide",
        "voices"
      ],
      "priority": 9,
      "content": "## Voice Cloning Options\n\n### Instant Voice Cloning (IVC)\n\n- **Speed**: Near-instantaneous\n- **Audio Required**: 1-2 minutes of consistent audio\n- **How it Works**: Uses prior knowledge from training data to make an educated guess\n- **Best For**: Standard voices, quick prototyping\n- **Limitation**: May struggle with very unique voices/accents\n\n### Professional Voice Cloning (PVC)\n\n- **Speed**: ~3 hours (English), ~6 hours (Multilingual)\n- **Audio Required**: Minimum 30 minutes, ideal 2-3 hours\n- **How it Works**: Trains a dedicated model on your voice data\n- **Best For**: Unique voices, production use, highest accuracy\n- **Requirements**: Creator+ plan, voice verification\n\n### Choosing Between IVC and PVC\n\n| Factor | IVC | PVC |\n| --- | --- | --- |\n| Setup Time | Seconds | 3-6 hours |\n| Audio Needed | 1-2 min | 30 min - 3 hours |\n| Accuracy | Good | Excellent |\n| Unique Accents | Limited | Full support |\n| Plan Required | Free+ | Creator+ |\n\n### Audio Quality Requirements\n\n**For Both IVC and PVC:**\n- Clean audio without background noise\n- Single speaker only\n- Consistent microphone distance (~20cm / 8 inches)\n- Use a pop filter to avoid plosives\n- Target levels: -23 dB to -18 dB RMS, true peak below -3 dB\n- Formats: WAV preferred at 44.1kHz or 48kHz, 24-bit\n\n**IVC Specific:**\n- Consistency in tonality, performance, accent is crucial\n- 1-2 minutes total\n\n**PVC Specific:**\n- Minimum 30 minutes, ideally 2-3 hours\n- Keep speaking style consistent throughout\n- Use language you want the PVC to primarily speak"
    },
    {
      "title": "Voice Cloning API - IVC",
      "path": "voice-cloning-api-ivc",
      "url": "https://elevenlabs.io/docs/api-reference/voices/ivc/create",
      "keywords": [
        "ivc",
        "instant-voice-cloning",
        "api",
        "create-voice",
        "clone",
        "files",
        "samples"
      ],
      "use_cases": [
        "How to create an instant voice clone via API",
        "What files are needed for IVC",
        "How to upload audio samples for cloning"
      ],
      "tags": [
        "voice-cloning",
        "api-reference",
        "ivc"
      ],
      "priority": 8,
      "content": "## Create Instant Voice Clone (IVC)\n\n### Endpoint\n\n`POST /v1/voices/add`\n\n### Request (multipart/form-data)\n\n| Field | Type | Required | Description |\n| --- | --- | --- | --- |\n| name | string | Yes | Name for the voice (displayed in dropdown) |\n| files | files | Yes | Audio files for cloning |\n| remove_background_noise | boolean | No | Remove noise using audio isolation (default: false) |\n| description | string | No | Voice description |\n| labels | object | No | Labels: language, accent, gender, age |\n\n### Python Example\n\n```python\nfrom elevenlabs.client import ElevenLabs\nfrom io import BytesIO\n\nelevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n\nvoice = elevenlabs.voices.ivc.create(\n    name=\"My Voice Clone\",\n    files=[BytesIO(open(\"/path/to/audio.mp3\", \"rb\").read())],\n    remove_background_noise=False,\n    description=\"A professional male voice\",\n    labels={\"accent\": \"American\", \"gender\": \"male\"}\n)\n\nprint(voice.voice_id)  # Use this ID for TTS\n```\n\n### Response\n\n```json\n{\n  \"voice_id\": \"abc123xyz\",\n  \"requires_verification\": false\n}\n```\n\n### Errors\n\n| Code | Reason |\n| --- | --- |\n| 422 | Invalid audio format, too short, or validation failed |\n| 401 | Invalid API key |\n| 403 | Plan doesn't support voice cloning |"
    },
    {
      "title": "Voice Cloning API - PVC",
      "path": "voice-cloning-api-pvc",
      "url": "https://elevenlabs.io/docs/api-reference/voices/pvc/create",
      "keywords": [
        "pvc",
        "professional-voice-cloning",
        "api",
        "create",
        "train",
        "verification",
        "samples",
        "speaker-separation"
      ],
      "use_cases": [
        "How to create a professional voice clone via API",
        "How to upload PVC samples",
        "How to verify PVC voice",
        "How to train PVC model",
        "How to handle speaker separation"
      ],
      "tags": [
        "voice-cloning",
        "api-reference",
        "pvc"
      ],
      "priority": 8,
      "content": "## Professional Voice Cloning (PVC) API Workflow\n\n### Step 1: Create PVC Voice\n\n```python\nvoice = elevenlabs.voices.pvc.create(\n    name=\"My Professional Clone\",\n    language=\"en\",\n    description=\"Professional voice clone\"\n)\nvoice_id = voice.voice_id\n```\n\n### Step 2: Upload Samples\n\n```python\nfrom contextlib import ExitStack\nfrom io import BytesIO\n\nsample_paths = [\"/path/to/sample1.mp3\", \"/path/to/sample2.wav\"]\n\nwith ExitStack() as stack:\n    files = [BytesIO(stack.enter_context(open(p, \"rb\")).read()) \n             for p in sample_paths]\n    \n    samples = elevenlabs.voices.pvc.samples.create(\n        voice_id=voice_id,\n        files=files\n    )\n```\n\n### Step 3: Speaker Separation (if needed)\n\n```python\nimport time\n\nfor sample in samples:\n    elevenlabs.voices.pvc.samples.speakers.separate(\n        voice_id=voice_id,\n        sample_id=sample.sample_id\n    )\n\n# Poll for completion\nwhile True:\n    status = elevenlabs.voices.pvc.samples.speakers.get(\n        voice_id=voice_id,\n        sample_id=sample.sample_id\n    )\n    if status.status in [\"completed\", \"failed\"]:\n        break\n    time.sleep(5)\n```\n\n### Step 4: Verify Voice (Required)\n\n```python\n# Get CAPTCHA image\ncaptcha = elevenlabs.voices.pvc.verification.captcha.get(voice_id)\nwith open('captcha.png', 'wb') as f:\n    f.write(base64.b64decode(captcha))\n\n# Record and submit verification audio\nelevenlabs.voices.pvc.verification.captcha.verify(\n    voice_id=voice_id,\n    recording=open('verification_recording.mp3', 'rb')\n)\n```\n\n### Step 5: Train Model\n\n```python\nelevenlabs.voices.pvc.train(\n    voice_id=voice_id,\n    model_id=\"eleven_multilingual_v2\"\n)\n\n# Poll for training completion\nwhile True:\n    voice_details = elevenlabs.voices.get(voice_id=voice_id)\n    state = voice_details.fine_tuning.state.get(\"eleven_multilingual_v2\")\n    \n    if state in [\"fine_tuned\", \"failed\"]:\n        break\n    \n    progress = voice_details.fine_tuning.progress.get(\"eleven_multilingual_v2\")\n    print(f\"Training progress: {progress}\")\n    time.sleep(30)\n```\n\n### Training Times\n\n- English: ~3 hours\n- Multilingual: ~6 hours\n\n### Common Errors\n\n| Error | Cause | Solution |\n| --- | --- | --- |\n| Verification failed | Voice doesn't match samples | Use same equipment, similar tone |\n| Training failed | Poor audio quality | Re-upload cleaner samples |\n| 422 | Invalid language code | Use supported language |"
    },
    {
      "title": "Voice Cloning Troubleshooting",
      "path": "voice-cloning-troubleshooting",
      "url": "https://elevenlabs.io/docs/creative-platform/troubleshooting",
      "keywords": [
        "troubleshooting",
        "voice-cloning",
        "issues",
        "quality",
        "mispronunciation",
        "inconsistent",
        "accent-drift",
        "corrupt-speech"
      ],
      "use_cases": [
        "How to fix inconsistent voice cloning",
        "How to fix mispronunciation issues",
        "How to fix accent drift",
        "How to fix corrupt speech",
        "Why is my clone quality poor"
      ],
      "tags": [
        "troubleshooting",
        "voice-cloning",
        "guide"
      ],
      "priority": 9,
      "content": "## Voice Cloning Troubleshooting\n\n### Inconsistent Volume/Quality\n\n**Causes:**\n- Inconsistent training audio\n- Background noise in samples\n- Variable microphone distance\n\n**Solutions:**\n- Apply compression to training audio (RMS: -23 to -18 dB, peak < -3 dB)\n- Remove background noise before uploading\n- Maintain consistent mic distance throughout recording\n- Break text into smaller segments for generation\n\n### Mispronunciation\n\n**Causes:**\n- Words appearing in multiple languages\n- Unusual names or technical terms\n\n**Solutions:**\n- Use Studio feature for easier regeneration\n- Use properly cloned voice in target language\n- Create pronunciation dictionary with phoneme/alias tags\n- Specify pronunciation: `<phoneme alphabet=\"cmu-arpabet\" ph=\"M AE1 D IH0 S AH0 N\">Madison</phoneme>`\n\n### Language Switching / Accent Drift\n\n**Causes:**\n- Long generations\n- Using English-based voice for other languages\n\n**Solutions:**\n- Use IVC or PVC trained on target language\n- Keep text under 800-900 characters\n- Use Studio workflow for longer content\n- Write text in the desired language\n\n### Corrupt/Distorted Speech\n\n**Cause:** Rare, unpredictable model behavior\n\n**Solution:** Regenerate the affected section\n\n### Audio Degradation Over Length\n\n**Solutions:**\n- Break text into sections under 800 characters\n- Use high-quality voice samples\n- Adjust Stability and Similarity settings\n- Keep Style Exaggeration at 0 for stability\n\n### Style Exaggeration Issues\n\n**Problems:** Inconsistent speed, mispronunciation, extra sounds\n\n**Solution:** Keep Style Exaggeration setting at 0\n\n### Best Practices Summary\n\n| Issue | Quick Fix |\n| --- | --- |\n| Inconsistent volume | Compress audio to -23 to -18 dB RMS |\n| Mispronunciation | Use pronunciation dictionary |\n| Accent drift | Keep generations under 800 chars |\n| Poor quality | Use cleaner training samples |\n| Distortion | Regenerate the section |"
    },
    {
      "title": "Text-to-Speech Best Practices",
      "path": "tts-best-practices",
      "url": "https://elevenlabs.io/docs/overview/capabilities/text-to-speech/best-practices",
      "keywords": [
        "tts",
        "best-practices",
        "ssml",
        "pronunciation",
        "pauses",
        "emotion",
        "normalization",
        "v3"
      ],
      "use_cases": [
        "How to control pauses in TTS",
        "How to fix pronunciation",
        "How to add emotion to speech",
        "How to normalize numbers and dates",
        "How to use Eleven v3 audio tags"
      ],
      "tags": [
        "tts",
        "best-practices",
        "guide"
      ],
      "priority": 8,
      "content": "## TTS Best Practices\n\n### Controlling Pauses\n\n**SSML Break Tags** (not supported in v3):\n```xml\n\"Hold on, let me think.\" <break time=\"1.5s\" /> \"Alright, I've got it.\"\n```\n\n**Alternatives:**\n- Dashes (- or —) for short pauses\n- Ellipses (…) for hesitant tones\n\n### Pronunciation Control\n\n**Phoneme Tags** (Flash v2, Turbo v2, English v1 only):\n```xml\n<phoneme alphabet=\"cmu-arpabet\" ph=\"M AE1 D IH0 S AH0 N\">Madison</phoneme>\n```\n\n**Alias Tags** (for v2.5, Multilingual v2):\n```xml\n<lexeme>\n  <grapheme>Claughton</grapheme>\n  <alias>Cloffton</alias>\n</lexeme>\n```\n\n### Emotion Control\n\nUse narrative context:\n```\n\"You're leaving?\" she asked, her voice trembling with sadness.\n\"That's it!\" he exclaimed triumphantly.\n```\n\n### Speed Control\n\n- Default: 1.0\n- Slow down: 0.7 - 0.99\n- Speed up: 1.01 - 1.2\n- Extreme values may affect quality\n\n### Text Normalization\n\nProblematic inputs:\n- Phone numbers: \"123-456-7890\"\n- Currencies: \"$47,345.67\"\n- Dates: \"2024-01-01\"\n- URLs: \"example.com/link\"\n\n**LLM Prompt for normalization:**\n```\nConvert the output text for text-to-speech:\n- \"$42.50\" → \"forty-two dollars and fifty cents\"\n- \"555-555-5555\" → \"five five five, five five five, five five five five\"\n- \"2024-01-01\" → \"January first, two-thousand twenty-four\"\n```\n\n### Eleven v3 Audio Tags\n\n```\n[whispers] I never knew it could be this way.\n[laughs] That's hilarious!\n[sarcastic] Oh, that's just great.\n[sighs] It's been a long day.\n[strong French accent] \"Zat's life, my friend.\"\n```\n\n**v3 Stability Settings:**\n- Creative: More expressive, prone to hallucinations\n- Natural: Balanced, closest to original\n- Robust: Stable, less responsive to tags"
    },
    {
      "title": "Webhook Security and Error Handling",
      "path": "webhook-security-errors",
      "url": "https://elevenlabs.io/docs/developers/guides/cookbooks/speech-to-text/batch/webhooks",
      "keywords": [
        "webhook",
        "security",
        "signature",
        "verification",
        "hmac",
        "error-handling",
        "retry"
      ],
      "use_cases": [
        "How to verify webhook signatures",
        "How to handle webhook errors",
        "What HTTP codes should webhooks return",
        "How to implement webhook rate limiting"
      ],
      "tags": [
        "webhooks",
        "security",
        "api-reference"
      ],
      "priority": 8,
      "content": "## Webhook Security\n\n### Signature Verification\n\n```javascript\nconst WEBHOOK_SECRET = process.env.WEBHOOK_SECRET;\n\napp.post('/webhook', (req, res) => {\n  const signature = req.headers['elevenlabs-signature'];\n  const payload = JSON.stringify(req.body);\n  \n  try {\n    const event = await elevenlabs.webhooks.constructEvent(\n      payload, \n      signature, \n      WEBHOOK_SECRET\n    );\n    // Process event...\n    res.status(200).json({ received: true });\n  } catch (error) {\n    return res.status(401).json({ error: 'Invalid signature' });\n  }\n});\n```\n\n### Required Response Codes\n\n| Status | Meaning | Retry? |\n| --- | --- | --- |\n| 200-299 | Success | No |\n| 400-499 | Client error | No |\n| 500-599 | Server error | Yes |\n\n### Rate Limiting Your Endpoint\n\n```javascript\nimport rateLimit from 'express-rate-limit';\n\nconst webhookLimiter = rateLimit({\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 100,\n  message: 'Too many webhook requests from this IP',\n});\n\napp.use('/webhook', webhookLimiter);\n```\n\n### Security Checklist\n\n- [ ] Verify signatures using `constructEvent()`\n- [ ] Use HTTPS endpoint only\n- [ ] Implement rate limiting\n- [ ] Never expose webhook secret\n- [ ] Return correct HTTP status codes\n- [ ] Log failed verifications for monitoring"
    }
  ]
}